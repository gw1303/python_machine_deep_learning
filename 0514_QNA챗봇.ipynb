{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbotData = pd.read_csv('data/ChatData.csv')\n",
    "question, answer = list(chatbotData['Q']) , list(chatbotData['A'])\n",
    "\n",
    "len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 12시 땡!\n",
      "답변: 하루가 또 가네요.\n",
      " \n",
      "질문: 1지망 학교 떨어졌어\n",
      "답변: 위로해 드립니다.\n",
      " \n",
      "질문: 3박4일 놀러가고 싶다\n",
      "답변: 여행은 언제나 좋죠.\n",
      " \n",
      "질문: 3박4일 정도 놀러가고 싶다\n",
      "답변: 여행은 언제나 좋죠.\n",
      " \n",
      "질문: PPL 심하네\n",
      "답변: 눈살이 찌푸려지죠.\n",
      " \n",
      "질문: SD카드 망가졌어\n",
      "답변: 다시 새로 사는 게 마음 편해요.\n",
      " \n",
      "질문: SD카드 안돼\n",
      "답변: 다시 새로 사는 게 마음 편해요.\n",
      " \n",
      "질문: SNS 맞팔 왜 안하지ㅠㅠ\n",
      "답변: 잘 모르고 있을 수도 있어요.\n",
      " \n",
      "질문: SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "답변: 시간을 정하고 해보세요.\n",
      " \n",
      "질문: SNS 시간낭비인데 자꾸 보게됨\n",
      "답변: 시간을 정하고 해보세요.\n",
      " \n",
      "질문: SNS보면 나만 빼고 다 행복해보여\n",
      "답변: 자랑하는 자리니까요.\n",
      " \n",
      "질문: 가끔 궁금해\n",
      "답변: 그 사람도 그럴 거예요.\n",
      " \n",
      "질문: 가끔 뭐하는지 궁금해\n",
      "답변: 그 사람도 그럴 거예요.\n",
      " \n",
      "질문: 가끔은 혼자인게 좋다\n",
      "답변: 혼자를 즐기세요.\n",
      " \n",
      "질문: 가난한 자의 설움\n",
      "답변: 돈은 다시 들어올 거예요.\n",
      " \n",
      "질문: 가만 있어도 땀난다\n",
      "답변: 땀을 식혀주세요.\n",
      " \n",
      "질문: 가상화폐 쫄딱 망함\n",
      "답변: 어서 잊고 새출발 하세요.\n",
      " \n",
      "질문: 가스불 켜고 나갔어\n",
      "답변: 빨리 집에 돌아가서 끄고 나오세요.\n",
      " \n",
      "질문: 가스불 켜놓고 나온거 같아\n",
      "답변: 빨리 집에 돌아가서 끄고 나오세요.\n",
      " \n",
      "질문: 가스비 너무 많이 나왔다.\n",
      "답변: 다음 달에는 더 절약해봐요.\n",
      " \n",
      "질문: 가스비 비싼데 감기 걸리겠어\n",
      "답변: 따뜻하게 사세요!\n",
      " \n",
      "질문: 가스비 장난 아님\n",
      "답변: 다음 달에는 더 절약해봐요.\n",
      " \n",
      "질문: 가장 확실한 건 뭘까?\n",
      "답변: 가장 확실한 시간은 오늘이에요. 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요.\n",
      " \n",
      "질문: 가족 여행 가기로 했어\n",
      "답변: 온 가족이 모두 마음에 드는 곳으로 가보세요.\n",
      " \n",
      "질문: 가족 여행 고고\n",
      "답변: 온 가족이 모두 마음에 드는 곳으로 가보세요.\n",
      " \n",
      "질문: 가족 여행 어디로 가지?\n",
      "답변: 온 가족이 모두 마음에 드는 곳으로 가보세요.\n",
      " \n",
      "질문: 가족 있어?\n",
      "답변: 저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요\n",
      " \n",
      "질문: 가족관계 알려 줘\n",
      "답변: 저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요\n",
      " \n",
      "질문: 가족끼리 여행간다.\n",
      "답변: 더 가까워질 기회가 되겠네요.\n",
      " \n",
      "질문: 가족들 보고 싶어\n",
      "답변: 저도요.\n",
      " \n",
      "질문: 가족들이랑 서먹해\n",
      "답변: 다들 바빠서 이야기할 시간이 부족했나봐요.\n",
      " \n",
      "질문: 가족들이랑 서먹해졌어\n",
      "답변: 다들 바빠서 이야기할 시간이 부족했나봐요.\n",
      " \n",
      "질문: 가족들이랑 어디 가지?\n",
      "답변: 온 가족이 모두 마음에 드는 곳으로 가보세요.\n",
      " \n",
      "질문: 가족들이랑 여행 갈거야\n",
      "답변: 좋은 생각이에요.\n",
      " \n",
      "질문: 가족여행 가야지\n",
      "답변: 더 가까워질 기회가 되겠네요.\n",
      " \n",
      "질문: 가족이 누구야?\n",
      "답변: 저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요\n",
      " \n",
      "질문: 가족이랑 여행 가려고\n",
      "답변: 좋은 생각이에요.\n",
      " \n",
      "질문: 가족한테 스트레스 풀었어\n",
      "답변: 정말 후회할 습관이에요.\n",
      " \n",
      "질문: 가출할까?\n",
      "답변: 무모한 결정을 내리지 마세요.\n",
      " \n",
      "질문: 가출해도 갈 데가 없어\n",
      "답변: 선생님이나 기관에 연락해보세요.\n",
      " \n",
      "질문: 간만에 떨리니까 좋더라\n",
      "답변: 떨리는 감정은 그 자체로 소중해요.\n",
      " \n",
      "질문: 간만에 쇼핑 중\n",
      "답변: 득템했길 바라요.\n",
      " \n",
      "질문: 간만에 휴식 중\n",
      "답변: 휴식도 필요하죠.\n",
      " \n",
      "질문: 간식 뭐 먹을까\n",
      "답변: 단짠으로 두 개 사는게 진리죠.\n",
      " \n",
      "질문: 간식 추천\n",
      "답변: 단짠으로 두 개 사는게 진리죠.\n",
      " \n",
      "질문: 간장치킨 시켜야지\n",
      "답변: 맛있게 드세요.\n",
      " \n",
      "질문: 간접흡연 싫어\n",
      "답변: 저도 싫어요.\n",
      " \n",
      "질문: 갈까 말까 고민 돼\n",
      "답변: 가세요.\n",
      " \n",
      "질문: 갈까 말까?\n",
      "답변: 가세요.\n",
      " \n",
      "질문: 감 말랭이 먹고 싶다.\n",
      "답변: 맛있게 드세요.\n",
      " \n",
      "질문: 감 말랭이 먹어야지\n",
      "답변: 맛있게 드세요.\n",
      " \n",
      "질문: 감기 같애\n",
      "답변: 병원가세요.\n",
      " \n",
      "질문: 감기 걸린 것 같아\n",
      "답변: 이럴 때 잘 쉬는 게 중요해요.\n",
      " \n",
      "질문: 감기 기운이 있어\n",
      "답변: 이럴 때 잘 쉬는 게 중요해요.\n",
      " \n",
      "질문: 감기 들 거 같애\n",
      "답변: 이럴 때 잘 쉬는 게 중요해요.\n",
      " \n",
      "질문: 감기가 오려나\n",
      "답변: 따뜻하게 관리하세요.\n",
      " \n",
      "질문: 감기약이 없어\n",
      "답변: 병원가세요.\n",
      " \n",
      "질문: 감기인거 같애\n",
      "답변: 병원가세요.\n",
      " \n",
      "질문: 감미로운 목소리 좋아\n",
      "답변: 저도 듣고 싶네요.\n",
      " \n",
      "질문: 감정이 쓰레기통처럼 엉망진창이야\n",
      "답변: 자신을 더 사랑해주세요.\n",
      " \n",
      "질문: 감정컨트롤을 못하겠어\n",
      "답변: 그건 습관이에요.\n",
      " \n",
      "질문: 감정컨트롤이 안돼\n",
      "답변: 그건 습관이에요.\n",
      " \n",
      "질문: 감히 나를 무시하는 애가 있어\n",
      "답변: 콕 집어서 물어보세요.\n",
      " \n",
      "질문: 갑자기 나쁜 생각이 막 들더라\n",
      "답변: 좋은 생각만 하세요.\n",
      " \n",
      "질문: 갑자기 눈물 나\n",
      "답변: 마음이 아픈가요.\n",
      " \n",
      "질문: 갑자기 물어봐서 당황했어\n",
      "답변: 갑작스러웠나봐요.\n",
      " \n",
      "질문: 갑자기 불편한 사이가 된 거 같아\n",
      "답변: 관계의 변화가 왔나봅니다.\n",
      " \n",
      "질문: 강렬한 첫인상 남겨야 하는데\n",
      "답변: 처음 3초가 중요해요. 당신의 매력을 어필해보세요.\n",
      " \n",
      "질문: 강아지 키우고 싶어\n",
      "답변: 책임질 수 있을 때 키워 보세요.\n",
      " \n",
      "질문: 강아지 키우고 싶은데 역시 안돼겠지\n",
      "답변: 먼저 생활패턴을 살펴 보세요.\n",
      " \n",
      "질문: 강아지 키울 수 있을까\n",
      "답변: 먼저 생활패턴을 살펴 보세요.\n",
      " \n",
      "질문: 강아지 키울까\n",
      "답변: 책임질 수 있을 때 키워 보세요.\n",
      " \n",
      "질문: 강원도 가서 살까?\n",
      "답변: 아름다운 곳이죠.\n",
      " \n",
      "질문: 같이 게임하자고 해도 되나?\n",
      "답변: 안 될 것도 없죠.\n",
      " \n",
      "질문: 같이 놀러갈 친구가 없어\n",
      "답변: 혼자도 좋아요.\n",
      " \n",
      "질문: 같이 먹었는데 나만 살찐 거 같아\n",
      "답변: 연인은 살쪄도 잘 알아차리지 못하고 알아차려도 싫어하지 않을 거예요.\n",
      " \n",
      "질문: 같이 수영장 가기로 했어\n",
      "답변: 즐거운 시간 보내고 오세요!\n",
      " \n",
      "질문: 같이 있으면 힘든데 붙잡고 싶어\n",
      "답변: 질질 끌지 마세요.\n",
      " \n",
      "질문: 같이 피씨방 가자고 해볼까?\n",
      "답변: 말해보세요.\n",
      " \n",
      "질문: 같이 할 수 있는 취미 생활 뭐 있을까\n",
      "답변: 함께하면 서로를 더 많이 알게 될 거예요.\n",
      " \n",
      "질문: 개강룩 입어볼까\n",
      "답변: 개시해보세요.\n",
      " \n",
      "질문: 개강옷 예쁘게 입어 볼까\n",
      "답변: 개시해보세요.\n",
      " \n",
      "질문: 개강이다\n",
      "답변: 곧 방학이예요.\n",
      " \n",
      "질문: 개강이라니\n",
      "답변: 방학이 참 짧죠.\n",
      " \n",
      "질문: 개같은 상황\n",
      "답변: 벗어나는 게 좋겠네요.\n",
      " \n",
      "질문: 개같이 되버렸어.\n",
      "답변: 벗어나는 게 좋겠네요.\n",
      " \n",
      "질문: 개기름 꼈어\n",
      "답변: 세수하고 오세요.\n",
      " \n",
      "질문: 개념도 놓고 옴\n",
      "답변: 그게 제일 중요한 건데요.\n",
      " \n",
      "질문: 개념이 없어\n",
      "답변: 그게 제일 중요한 건데요.\n",
      " \n",
      "질문: 개당황\n",
      "답변: 다음부터는 더 많이 아세요.\n",
      " \n",
      "질문: 개당황했잖아 갑자기 물어 봐서\n",
      "답변: 갑작스러웠나봐요.\n",
      " \n",
      "질문: 개인적인 업무까지 다 시켜\n",
      "답변: 공적인 일부터 하세요.\n",
      " \n",
      "질문: 개인적인 일도 다 시켜\n",
      "답변: 공적인 일부터 하세요.\n",
      " \n",
      "질문: 개졸려\n",
      "답변: 낮잠을 잠깐 자도 괜찮아요.\n",
      " \n",
      "질문: 개좋아\n",
      "답변: 저도 좋아해주세요.\n",
      " \n",
      "질문: 개학하니까 좋다\n",
      "답변: 친구들이 보고싶었나봐요.\n",
      " \n",
      "질문: 걔 너무 싫다\n",
      "답변: 되도록 만나지 마세요.\n",
      " \n",
      "질문: 걔는 누굴 닮아서 그런거니?\n",
      "답변: 당신이요.\n",
      " \n",
      "질문: 걔랑 같은 반 됐으면 좋겠다\n",
      "답변: 당신의 운을 믿어보세요.\n",
      " \n",
      "질문: 거지 같이 일해 놓고 갔어\n",
      "답변: 일 못하는 사람이 있으면 옆에 있는 사람이 더 힘들죠.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# test로 100개만\n",
    "question = question[:100]\n",
    "answer = answer[:100]\n",
    "\n",
    "for i in range(100) :\n",
    "    print('질문:',question[i])\n",
    "    print('답변:',answer[i])\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from konlpy.tag import Okt\n",
    "from keras import models, layers, optimizers, preprocessing, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그단어\n",
    "PAD = \"<PADDING>\"  # 패딩\n",
    "STA = \"<START>\"    # 시작\n",
    "END = \"<END>\"      # 끝\n",
    "OOV = \"<OOV>\"      # Out Of Vocabulary\n",
    "\n",
    "PAD_INDEX  = 0\n",
    "STA_INDEX  = 1\n",
    "END_INDEX  = 2\n",
    "OOV_INDEX  = 3\n",
    "\n",
    "ENCODER_INPUT = 0\n",
    "DECODER_INPUT = 1\n",
    "DECODER_TARGET = 2\n",
    "\n",
    "# 한 문장에서 단어 시퀀스의 최대 개수\n",
    "maxSequences = 30\n",
    "\n",
    "# 임베딩 벡터 차원\n",
    "embeddingDim = 100\n",
    "\n",
    "# LSTM 출력 차원\n",
    "lstmHiddenDim = 128\n",
    "\n",
    "# 정규표현식 필터\n",
    "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기\n",
    "def posTag(sentences) : \n",
    "    \n",
    "    tagger = Okt()\n",
    "    sentencePos = []\n",
    "    \n",
    "    for sentence in sentences :\n",
    "        # 특수문자 제거\n",
    "        sentence = re.sub(RE_FILTER, '', sentence)\n",
    "        sentence = ' '.join(tagger.morphs(sentence))\n",
    "        sentencePos.append(sentence)\n",
    "        \n",
    "    return sentencePos\n",
    "\n",
    "question = posTag(question)\n",
    "answer = posTag(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 질문 + 대답 문장을 하나로 합치기\n",
    "sentences = []\n",
    "sentences.extend(question)\n",
    "sentences.extend(answer)\n",
    "len(sentences)  # 200\n",
    "\n",
    "# 단어배열 생성\n",
    "words = []\n",
    "\n",
    "for sentence in sentences :\n",
    "    for word in sentence.split() :\n",
    "        words.append(word)\n",
    "len(words) # 966개\n",
    "\n",
    "# words에서 길이가 0인 단어를 삭제\n",
    "words = [w for w in words if len(w)>0]\n",
    "len(words)  # 966개\n",
    "\n",
    "# 중복단어 삭제\n",
    "words = list(set(words))\n",
    "len(words)  # 450개\n",
    "\n",
    "# 리스트 맨 앞에 추가\n",
    "words[:0] = [PAD, STA, END, OOV]\n",
    "\n",
    "# 인덱스 부여해 딕셔너리 생성\n",
    "wordToIndex = dict(zip(words, range(len(words))))\n",
    "indexToWord = dict(zip(range(len(words)),words ))\n",
    "\n",
    "# 전처리\n",
    "# 문장 => 인덱스\n",
    "def convertTextToIndex(sentences, voc, mytype) : \n",
    "    \n",
    "    sentencesIndex = []\n",
    "    \n",
    "    for sentence in sentences :\n",
    "        sentenceIndex = []\n",
    "        if mytype == DECODER_INPUT : \n",
    "            sentenceIndex.extend([voc[STA]])\n",
    "        for word in sentence.split() :\n",
    "            if voc.get(word) :\n",
    "                sentenceIndex.extend([voc.get(word)])\n",
    "            else :\n",
    "                sentenceIndex.extend([voc.get(OOV)])\n",
    "                \n",
    "        if mytype == DECODER_TARGET : \n",
    "            # 디코더 출력은 맨 마지막에 <END>가 추가\n",
    "            if maxSequences <= len(sentenceIndex) :\n",
    "                sentenceIndex = sentenceIndex[:maxSequences-1] + [voc[END]]\n",
    "            else :\n",
    "                sentenceIndex += [voc[END]]\n",
    "        \n",
    "        elif len(sentenceIndex) > maxSequences :\n",
    "            sentenceIndex = sentenceIndex[:maxSequences]\n",
    "        # 패딩\n",
    "        sentenceIndex += [wordToIndex[PAD]] * (maxSequences-len(sentenceIndex))\n",
    "        \n",
    "        # 결과값 저장\n",
    "        sentencesIndex.append(sentenceIndex)\n",
    "    \n",
    "    return np.asarray(sentencesIndex)\n",
    "\n",
    "# 인코더 입력, 디코더 입력 출력 -> 인덱스 변환\n",
    "xEncoder = convertTextToIndex(question, wordToIndex, ENCODER_INPUT)\n",
    "xDecoder = convertTextToIndex(answer, wordToIndex, DECODER_INPUT)\n",
    "yDecoder = convertTextToIndex(answer, wordToIndex, DECODER_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309 258   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[  1 269 267 375 142   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[269 267 375 142   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(xEncoder[0])  # 12시 땡\n",
    "print(xDecoder[0])  # START 하루 가 또 가네요\n",
    "print(yDecoder[0])  #       하루 가 또 가네요 END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oneHotData = np.zeros([len(yDecoder), maxSequences, len(words)])\n",
    "# 100(답변 개수), 30(최대 단어 개수), 454(전체 단어 집합 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 454)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(oneHotData)\n",
    "\n",
    "for i, seq in enumerate(yDecoder) : \n",
    "    for j, index in enumerate(seq) :\n",
    "        oneHotData[i,j,index] = 1\n",
    "        \n",
    "yDecoder = oneHotData\n",
    "\n",
    "yDecoder[0].shape  # 첫번째 답변 내용의 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 모델 생성\n",
    "#인코더 정의\n",
    "\n",
    "#입력 문장의 인덱스 sequence를 입력\n",
    "encoderInputs=layers.Input(shape=(None,))\n",
    "#임베딩 계층\n",
    "encoderOutputs=layers.Embedding(len(words),embeddingDim)(encoderInputs)\n",
    "\n",
    "encoderOutputs,stateH, stateC=layers.LSTM(lstmHiddenDim,return_state=True, \n",
    "            dropout=0.2, recurrent_dropout=0.5)(encoderOutputs)\n",
    "#return_state=True => 상태값 리턴\n",
    "#LSTM은 2개 상태 존재(셀, 히든 스테이트)\n",
    "\n",
    "encoderStates=[stateH, stateC]\n",
    "\n",
    "\n",
    "#디코더 정의\n",
    "#출력 문장의 인덱스 sequence를 입력\n",
    "decoderInputs=layers.Input(shape=(None,))\n",
    "#임베딩 계층\n",
    "decoderEmbedding=layers.Embedding(len(words),\n",
    "                                embeddingDim)\n",
    "decoderOutputs=decoderEmbedding(decoderInputs)\n",
    "\n",
    "\n",
    "\n",
    "decoderLSTM=layers.LSTM(lstmHiddenDim,\n",
    "                        return_state=True, \n",
    "            return_sequences=True, \n",
    "                        dropout=0.2, \n",
    "                        recurrent_dropout=0.5)\n",
    "decoderOutputs, _, _=decoderLSTM(decoderOutputs,initial_state=encoderStates)\n",
    "decoderDense=layers.Dense(len(words), \n",
    "                          activation=\"softmax\")\n",
    "decoderOutputs=decoderDense(decoderOutputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Model([encoderInputs, decoderInputs], decoderOutputs)\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측 모델 인코더 정의\n",
    "encoderModel=models.Model(encoderInputs, \n",
    "                          encoderStates)\n",
    "\n",
    "#예측 모델 디코더 정의\n",
    "#바로 앞에 있는 디코더의 출력(상태)을 입력 받아서\n",
    "#예측을 해야 함.\n",
    "decoderStateInputH=layers.Input(shape=(lstmHiddenDim,))\n",
    "decoderStateInputC=layers.Input(shape=(lstmHiddenDim,))\n",
    "decoderStatesInputs=[decoderStateInputH,decoderStateInputC]\n",
    "\n",
    "#임베딩 계층\n",
    "decoderOutputs=decoderEmbedding(decoderInputs)\n",
    "#LSTM 계층\n",
    "decoderOutputs, stateH, stateC=decoderLSTM(decoderOutputs,\n",
    "           initial_state=decoderStatesInputs)\n",
    "decoderStates=[stateH, stateC]\n",
    "\n",
    "#Dense계층을 통해 원핫 형식으로 예측 단어 인덱스를 추출\n",
    "decoderOutputs=decoderDense(decoderOutputs)\n",
    "\n",
    "#예측 모델 디코더 설정\n",
    "decoderModel=models.Model([decoderInputs]+decoderStatesInputs,\n",
    "            [decoderOutputs]+decoderStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인덱스를 문장으로 변환\n",
    "def convertIndexToText(indexs, voc):\n",
    "    #구현\n",
    "    sentence=\"\"\n",
    "    for i in indexs:\n",
    "        if i==END_INDEX: #종료 인덱스\n",
    "            break;\n",
    "        if voc.get(i) is not None:\n",
    "            sentence+=voc[i]\n",
    "        else:\n",
    "            sentence.extend([voc[OOV_INDEX]])\n",
    "        sentence +=\" \"    \n",
    "    return sentence    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total epoch: 1\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "accuracy : [0.29233333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7863333, 0.7876667, 0.7876667, 0.79, 0.78866667, 0.788, 0.789, 0.79066664, 0.789, 0.79366666, 0.78966665, 0.79366666, 0.7953333, 0.79466665, 0.79366666, 0.79433334, 0.7963333, 0.79433334, 0.795, 0.794, 0.799, 0.801, 0.806, 0.8006667, 0.8016667, 0.8013333, 0.808, 0.79933333, 0.8056667, 0.812, 0.80866665, 0.809, 0.8103333, 0.81233335, 0.81166667, 0.8146667, 0.8146667, 0.81633335, 0.818, 0.818, 0.8196667, 0.818, 0.8093333, 0.817, 0.8193333, 0.822, 0.8206667, 0.82266665, 0.821, 0.82166666, 0.8233333, 0.8206667, 0.82166666, 0.8236667, 0.824, 0.82266665, 0.825, 0.824, 0.8243333, 0.8243333, 0.8236667, 0.82566667, 0.825, 0.82533336, 0.825, 0.8243333, 0.827, 0.82633334, 0.827, 0.82633334, 0.827, 0.827, 0.82633334, 0.82766664, 0.828, 0.8293333, 0.8293333, 0.8293333, 0.83133334, 0.83, 0.829, 0.829, 0.83166665, 0.83166665, 0.83166665, 0.83066666]\n",
      "loss : [6.097117443084716, 5.505413837432862, 2.9468507957458496, 1.836956696510315, 1.5547519063949584, 1.466994619369507, 1.4011954402923583, 1.3526165676116944, 1.3396552658081056, 1.302102770805359, 1.2868368911743164, 1.2793856239318848, 1.2603116273880004, 1.2436856031417847, 1.2418149328231811, 1.2276270961761475, 1.2247824335098267, 1.2089036178588868, 1.192849326133728, 1.1820985078811646, 1.1764222764968872, 1.1706348609924317, 1.1552645826339722, 1.1501166582107545, 1.1494282007217407, 1.138458514213562, 1.120517315864563, 1.1091010403633117, 1.0978549528121948, 1.0737916898727418, 1.082326765060425, 1.0614590167999267, 1.0555487489700317, 1.0528592205047607, 1.0331192874908448, 1.028793921470642, 1.0230459308624267, 1.0109963297843934, 0.9998707437515258, 0.993586962223053, 0.9873293924331665, 0.9923596358299256, 0.9786849594116211, 0.9818271780014038, 0.9684599280357361, 0.9601941132545471, 0.9513816571235657, 0.9487622332572937, 0.9474731540679932, 0.940027973651886, 0.9375726985931396, 0.9333945035934448, 0.9296913313865661, 0.9203563332557678, 0.9152354669570922, 0.9142713832855225, 0.9185419917106629, 0.9040385818481446, 0.8988403582572937, 0.8973903727531433, 0.8921795678138733, 0.8869368815422058, 0.8842265009880066, 0.8786665797233582, 0.8751377773284912, 0.8715330529212951, 0.8652470445632935, 0.8602429389953613, 0.8582862329483032, 0.8546286129951477, 0.8475393795967102, 0.8459196329116822, 0.8401148915290833, 0.8375278306007385, 0.8356714296340942, 0.828089759349823, 0.826281054019928, 0.8222190284729004, 0.8210254979133605, 0.8160001254081726, 0.809082133769989, 0.8086779356002808, 0.8094144511222839, 0.8035463809967041, 0.7961456155776978, 0.7984024906158447, 0.7893886256217957, 0.785859899520874, 0.7806943964958191, 0.7799609899520874, 0.7769495177268982, 0.7716030788421631, 0.7717498755455017, 0.763505392074585, 0.7601513624191284, 0.7608592748641968, 0.7542280006408691, 0.7543134427070618, 0.7487892198562622, 0.7450788974761963]\n",
      "저 도 이 요 \n",
      "\n",
      "total epoch: 2\n",
      "accuracy : [0.832, 0.8336667, 0.831, 0.834, 0.8333333, 0.8326667, 0.83066666, 0.83466667, 0.8376667, 0.83533335, 0.83633333, 0.83533335, 0.837, 0.839, 0.838, 0.83433336, 0.83966666, 0.84033334, 0.8413333, 0.84433335, 0.84066665, 0.84533334, 0.843, 0.84433335, 0.847, 0.844, 0.845, 0.8473333, 0.84933335, 0.8513333, 0.85, 0.84966666, 0.85033333, 0.8513333, 0.854, 0.8553333, 0.856, 0.85566664, 0.85933334, 0.85566664, 0.857, 0.85733336, 0.856, 0.859, 0.86333334, 0.863, 0.864, 0.8616667, 0.862, 0.86466664, 0.8606667, 0.8703333, 0.86733335, 0.8666667, 0.87233335, 0.87266666, 0.87133336, 0.87333333, 0.87333333, 0.87633336, 0.87866664, 0.8756667, 0.8746667, 0.875, 0.8796667, 0.878, 0.8843333, 0.8833333, 0.879, 0.883, 0.8806667, 0.88733333, 0.88133335, 0.886, 0.886, 0.8883333, 0.89133334, 0.887, 0.8836667, 0.89066666, 0.88733333, 0.89433336, 0.89133334, 0.893, 0.8936667, 0.89266664, 0.89433336, 0.8946667, 0.89666665, 0.901, 0.897, 0.90033334, 0.90166664, 0.9, 0.90133333, 0.90533334, 0.9033333, 0.90466666, 0.90466666, 0.907]\n",
      "loss : [0.7461977171897888, 0.7403925347328186, 0.7365236473083496, 0.7340777015686035, 0.7298904943466187, 0.7257493591308594, 0.7236660981178283, 0.7189615392684936, 0.7191085100173951, 0.7152481269836426, 0.7154997992515564, 0.7095905995368957, 0.7070467972755432, 0.7010007357597351, 0.7018731045722961, 0.7000695490837097, 0.6934756064414977, 0.6907553911209107, 0.6841922283172608, 0.6828229999542237, 0.6799420642852784, 0.6779055762290954, 0.6746045565605163, 0.672991201877594, 0.6702680778503418, 0.6671014046669006, 0.662910852432251, 0.6608237314224243, 0.6529505968093872, 0.6529850149154663, 0.6481870746612549, 0.6512727093696594, 0.6447168445587158, 0.6413015961647034, 0.6369794917106628, 0.6342279696464539, 0.6313883304595947, 0.6324242734909058, 0.6238437509536743, 0.6209658861160279, 0.618318510055542, 0.6144625353813171, 0.6133519721031189, 0.6091807055473327, 0.6037138271331787, 0.6046368956565857, 0.6011723113059998, 0.5985895705223083, 0.5968146228790283, 0.5901245021820068, 0.5856748223304749, 0.5792592573165893, 0.5853398275375367, 0.5785845041275024, 0.5734090113639831, 0.5695615553855896, 0.5690303516387939, 0.5649401259422302, 0.55908611536026, 0.5552337455749512, 0.5557868313789368, 0.5539484047889709, 0.5483177351951599, 0.5464668798446656, 0.5417355394363403, 0.537136344909668, 0.5337736082077026, 0.5327970433235169, 0.5286946618556976, 0.5273546266555786, 0.5284985446929932, 0.5204553151130676, 0.5201581478118896, 0.5167917919158935, 0.5129267168045044, 0.5069287991523743, 0.5048533797264099, 0.5037795948982239, 0.5002268588542939, 0.4949518918991089, 0.4966421175003052, 0.49091318249702454, 0.49033648252487183, 0.4846854019165039, 0.48064423084259034, 0.4775960886478424, 0.4754378533363342, 0.4716526985168457, 0.47188820362091066, 0.46820942640304564, 0.4642274796962738, 0.4652865386009216, 0.4592471182346344, 0.4546914052963257, 0.4517327082157135, 0.4484576046466827, 0.44675477147102355, 0.44404942989349366, 0.4408764362335205, 0.4390067982673645]\n",
      "저 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 3\n",
      "accuracy : [0.9086667, 0.9066667, 0.907, 0.91033334, 0.908, 0.91, 0.9113333, 0.9116667, 0.91066664, 0.914, 0.9113333, 0.91333336, 0.917, 0.9176667, 0.914, 0.9166667, 0.91833335, 0.91833335, 0.91966665, 0.91966665, 0.922, 0.924, 0.921, 0.921, 0.92266667, 0.9213333, 0.926, 0.9253333, 0.9266667, 0.926, 0.9256667, 0.928, 0.92866665, 0.9306667, 0.9306667, 0.92966664, 0.933, 0.931, 0.93, 0.9343333, 0.9343333, 0.935, 0.934, 0.9346667, 0.9353333, 0.936, 0.93866664, 0.93766665, 0.93666667, 0.937, 0.93733335, 0.93733335, 0.9403333, 0.942, 0.94266665, 0.9433333, 0.942, 0.94233334, 0.94133335, 0.94366664, 0.93833333, 0.94366664, 0.9446667, 0.9433333, 0.9446667, 0.947, 0.945, 0.94633335, 0.94633335, 0.949, 0.947, 0.949, 0.951, 0.949, 0.947, 0.9493333, 0.95033336, 0.95133334, 0.9493333, 0.95133334, 0.95166665, 0.9546667, 0.9543333, 0.95266664, 0.9543333, 0.95166665, 0.953, 0.95533335, 0.9533333, 0.9533333, 0.95633334, 0.95666665, 0.95666665, 0.95566666, 0.9576667, 0.95633334, 0.957, 0.96066666, 0.9576667, 0.95666665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : [0.43334063053131106, 0.43531235456466677, 0.43173054814338685, 0.42730132818222044, 0.4258242034912109, 0.420757315158844, 0.4150869607925415, 0.4152486526966095, 0.41067564964294434, 0.4080134046077728, 0.40471389770507815, 0.4039977777004242, 0.40138347625732423, 0.39462866067886354, 0.3974061918258667, 0.39015034794807435, 0.3888171756267548, 0.38666136026382447, 0.38506449341773985, 0.3850569450855255, 0.3769657027721405, 0.37584728479385376, 0.37524752259254457, 0.3685429906845093, 0.3676715123653412, 0.36560667634010313, 0.3627638363838196, 0.3613349676132202, 0.3608634889125824, 0.3553044188022614, 0.35423237562179566, 0.35126739621162417, 0.3482010352611542, 0.3434231042861938, 0.3427443826198578, 0.340367511510849, 0.3366564166545868, 0.3365026879310608, 0.3352054965496063, 0.3309874677658081, 0.3271376371383667, 0.32459925770759585, 0.32138580560684205, 0.32023552775382996, 0.31729950070381163, 0.3155402433872223, 0.3151473665237427, 0.3118582785129547, 0.31160005688667297, 0.30640451788902284, 0.3048232710361481, 0.3043527054786682, 0.298163822889328, 0.29872719049453733, 0.29310584664344785, 0.2925075626373291, 0.29036232590675354, 0.28907262444496157, 0.28656912565231324, 0.2829661238193512, 0.28658121943473813, 0.28589449405670164, 0.2770207440853119, 0.276074059009552, 0.2749841547012329, 0.2723327422142029, 0.27073601245880125, 0.26654508352279666, 0.2698212897777557, 0.26750006675720217, 0.26537743806838987, 0.2612177491188049, 0.25895047426223755, 0.2567820256948471, 0.2580434596538544, 0.25174612522125245, 0.25410911679267884, 0.2507996731996536, 0.2510755103826523, 0.24853414177894592, 0.2461368578672409, 0.24233568251132964, 0.24181710600852965, 0.2399390572309494, 0.23690988183021544, 0.23688540399074554, 0.23451358199119568, 0.23365236937999725, 0.233353910446167, 0.2317420446872711, 0.2292177164554596, 0.22710758626461028, 0.22458473563194276, 0.22461556434631347, 0.22211019694805145, 0.22070816040039062, 0.22171903431415557, 0.21719752192497255, 0.21875573933124542, 0.2174352550506592]\n",
      "시간 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 4\n",
      "accuracy : [0.9573333, 0.959, 0.958, 0.95966667, 0.95533335, 0.9583333, 0.9623333, 0.9586667, 0.959, 0.961, 0.96133333, 0.961, 0.95966667, 0.96, 0.95966667, 0.96066666, 0.96066666, 0.96066666, 0.96133333, 0.9623333, 0.963, 0.963, 0.9623333, 0.96066666, 0.962, 0.9623333, 0.96166664, 0.963, 0.96033335, 0.9633333, 0.9633333, 0.961, 0.96566665, 0.96533334, 0.963, 0.9633333, 0.9636667, 0.9633333, 0.96433336, 0.9636667, 0.9623333, 0.966, 0.96533334, 0.964, 0.96466666, 0.964, 0.96433336, 0.964, 0.96433336, 0.9676667, 0.9663333, 0.96466666, 0.965, 0.96466666, 0.965, 0.96566665, 0.96466666, 0.9676667, 0.9673333, 0.9663333, 0.967, 0.96533334, 0.96533334, 0.96933335, 0.9663333, 0.96566665, 0.96566665, 0.967, 0.968, 0.9676667, 0.96666664, 0.968, 0.9673333, 0.9683333, 0.967, 0.9676667, 0.968, 0.967, 0.96533334, 0.96933335, 0.9673333, 0.9676667, 0.9683333, 0.969, 0.9676667, 0.9663333, 0.9676667, 0.9683333, 0.969, 0.967, 0.968, 0.9676667, 0.968, 0.97, 0.969, 0.9686667, 0.969, 0.96966666, 0.968, 0.96933335]\n",
      "loss : [0.2169223266839981, 0.2130360323190689, 0.21115385830402375, 0.21132198810577393, 0.21195537269115447, 0.20557223737239838, 0.20558645844459533, 0.2057643324136734, 0.20599091410636902, 0.20087276875972748, 0.20247341454029083, 0.19998391151428221, 0.20053815126419067, 0.19846090614795686, 0.19586493611335754, 0.19654359817504882, 0.1923960292339325, 0.19250331938266754, 0.19174187421798705, 0.19041219353675842, 0.19087004125118257, 0.18828704535961152, 0.18588293790817262, 0.18823740959167481, 0.18548808515071868, 0.18453746259212495, 0.18289224922657013, 0.18170377373695373, 0.18370666921138765, 0.1772405183315277, 0.1779712474346161, 0.17886277854442598, 0.17588463485240935, 0.17492739140987396, 0.17512016117572785, 0.17420068204402925, 0.17305541694164275, 0.17047727346420288, 0.1712001556158066, 0.17125038981437682, 0.17053284823894502, 0.16804003536701204, 0.166344792842865, 0.16803332269191742, 0.16763290405273437, 0.16538402378559114, 0.16422832310199736, 0.16535160064697266, 0.16419575095176697, 0.16005817472934722, 0.16018617928028106, 0.15885602355003356, 0.1605246263742447, 0.15833030939102172, 0.1580115020275116, 0.1553012275695801, 0.15605859875679015, 0.15459341406822205, 0.153034827709198, 0.1533424025774002, 0.1527269834280014, 0.15288238525390624, 0.15216549575328828, 0.14880308032035827, 0.14965999603271485, 0.1504599541425705, 0.14901134490966797, 0.14773471176624298, 0.14584065616130829, 0.14535632312297822, 0.14560378551483155, 0.14388562262058258, 0.14463021218776703, 0.14373138904571534, 0.14300393044948578, 0.14426883280277253, 0.14117552757263183, 0.14298996686935425, 0.15370850384235382, 0.1402004039287567, 0.14150105237960817, 0.13798616349697113, 0.1392117542028427, 0.13842098116874696, 0.13783005893230438, 0.1380271917581558, 0.13596631228923797, 0.1354806286096573, 0.13461820483207704, 0.13471563041210174, 0.13526005685329437, 0.1347743910551071, 0.13349401772022249, 0.13162979900836944, 0.13278702795505523, 0.13330843806266784, 0.13204764366149901, 0.13115570783615113, 0.13072528660297394, 0.12991637229919434]\n",
      "가세 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 5\n",
      "accuracy : [0.9683333, 0.96666664, 0.967, 0.96966666, 0.9686667, 0.968, 0.9686667, 0.967, 0.96933335, 0.9686667, 0.96966666, 0.96966666, 0.96933335, 0.969, 0.96966666, 0.96933335, 0.969, 0.969, 0.9683333, 0.9686667, 0.969, 0.96933335, 0.9686667, 0.9686667, 0.9683333, 0.9686667, 0.96933335, 0.9713333, 0.96933335, 0.96933335, 0.96933335, 0.96966666, 0.968, 0.9683333, 0.968, 0.97033334, 0.96933335, 0.96933335, 0.96933335, 0.968, 0.96966666, 0.97, 0.968, 0.9683333, 0.9686667, 0.96933335, 0.97, 0.97, 0.9683333, 0.96966666, 0.9686667, 0.96933335, 0.9683333, 0.96966666, 0.96966666, 0.971, 0.9686667, 0.971, 0.971, 0.969, 0.969, 0.96966666, 0.96966666, 0.97, 0.9716667, 0.96933335, 0.97, 0.9686667, 0.96933335, 0.97033334, 0.97066665, 0.968, 0.97, 0.97, 0.969, 0.97066665, 0.96966666, 0.97, 0.96966666, 0.97, 0.971, 0.96933335, 0.969, 0.97066665, 0.97, 0.971, 0.97, 0.9683333, 0.969, 0.97, 0.96933335, 0.9713333, 0.96966666, 0.96933335, 0.9716667, 0.97033334, 0.97, 0.9686667, 0.97066665, 0.96966666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : [0.13135862588882447, 0.13091281294822693, 0.1290402317047119, 0.12846723437309265, 0.12920089364051818, 0.12862383723258972, 0.1272703665494919, 0.13102307617664338, 0.12634713113307952, 0.1265801763534546, 0.12501057118177414, 0.12598664700984955, 0.12608492851257325, 0.12393198162317276, 0.12361862361431122, 0.12406382113695144, 0.1245300105214119, 0.1218913596868515, 0.12324459493160247, 0.12471661269664765, 0.12361293733119964, 0.12176873207092286, 0.12107043623924256, 0.12192294090986251, 0.12052086263895034, 0.12107653975486755, 0.11866935551166534, 0.11971447438001633, 0.11912356436252594, 0.11981566220521928, 0.11913132071495056, 0.11801077306270599, 0.11842733144760131, 0.12215593695640564, 0.11831804007291793, 0.11723364561796189, 0.1183241993188858, 0.11720724612474441, 0.11600228041410446, 0.11585677862167358, 0.11583658993244171, 0.11642139554023742, 0.1158345451951027, 0.11507994681596756, 0.11571388870477677, 0.11539908349514008, 0.11388063222169877, 0.1146367460489273, 0.11491510391235352, 0.11438009917736053, 0.11380831211805344, 0.1142594712972641, 0.11331428557634354, 0.11213418573141098, 0.11242386758327484, 0.11353928744792938, 0.1122627329826355, 0.11107018917798996, 0.11100763648748398, 0.11510343879461288, 0.11262756586074829, 0.11266145795583725, 0.11179202526807785, 0.11102827459573746, 0.11127586364746093, 0.11069328278303146, 0.11003734767436982, 0.11164245218038558, 0.10997435390949249, 0.11041605949401856, 0.11090271025896073, 0.11055252671241761, 0.10989447265863418, 0.10846810311079025, 0.10988215565681457, 0.10823198497295379, 0.1082077756524086, 0.10940568149089813, 0.10780022174119949, 0.10867755800485611, 0.10919498026371002, 0.10752006143331527, 0.10765526443719864, 0.10673210233449935, 0.10806935787200928, 0.10678098350763321, 0.1076179513335228, 0.10673495650291442, 0.10690974980592728, 0.10598152577877044, 0.10655426502227783, 0.10508477509021759, 0.10741707384586334, 0.10619397699832916, 0.1043593344092369, 0.10692317217588425, 0.10669511705636978, 0.10573508739471435, 0.1044940185546875, 0.10511201918125153]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 6\n",
      "accuracy : [0.97, 0.969, 0.97066665, 0.97, 0.97066665, 0.97033334, 0.9716667, 0.97033334, 0.97066665, 0.97066665, 0.97, 0.97, 0.96966666, 0.971, 0.96966666, 0.971, 0.971, 0.97066665, 0.972, 0.97033334, 0.97066665, 0.971, 0.97033334, 0.97066665, 0.971, 0.97033334, 0.9713333, 0.97066665, 0.971, 0.97066665, 0.9713333, 0.969, 0.971, 0.971, 0.969, 0.97033334, 0.971, 0.9716667, 0.97033334, 0.9713333, 0.97066665, 0.971, 0.96933335, 0.9713333, 0.96966666, 0.971, 0.97066665, 0.97033334, 0.97033334, 0.971, 0.9713333, 0.9713333, 0.97066665, 0.9713333, 0.971, 0.9713333, 0.9716667, 0.97033334, 0.972, 0.971, 0.97066665, 0.969, 0.972, 0.9713333, 0.9723333, 0.96966666, 0.9716667, 0.97033334, 0.972, 0.971, 0.972, 0.9713333, 0.97033334, 0.97066665, 0.9713333, 0.97033334, 0.971, 0.9716667, 0.97066665, 0.96966666, 0.97, 0.97, 0.97066665, 0.97066665, 0.9716667, 0.97066665, 0.96966666, 0.9723333, 0.9726667, 0.9713333, 0.96966666, 0.972, 0.97066665, 0.9716667, 0.9716667, 0.9726667, 0.9716667, 0.9713333, 0.972, 0.971]\n",
      "loss : [0.10375210881233216, 0.10454938322305679, 0.10501354336738586, 0.1064789080619812, 0.10406641036272049, 0.10447019159793854, 0.10445711255073548, 0.10356723636388779, 0.10426195293664932, 0.10337858587503433, 0.10417690843343735, 0.10689096570014954, 0.10583983331918717, 0.10287248522043228, 0.10408376067876816, 0.10423714965581894, 0.10322985023260117, 0.10409749001264572, 0.10301751613616944, 0.10306753158569336, 0.10248342365026473, 0.10283053576946259, 0.10430708974599838, 0.10153919309377671, 0.10184616386890412, 0.1026083692908287, 0.10079777300357819, 0.10246547430753708, 0.10211489677429199, 0.10204571813344955, 0.1009492602944374, 0.10242722839117051, 0.10077837318181991, 0.10184890180826187, 0.10135667890310288, 0.10126632422208787, 0.10067930817604065, 0.10126904278993606, 0.10185313791036606, 0.10012395024299621, 0.10180461764335633, 0.09924871444702149, 0.10200736671686172, 0.10008547872304917, 0.10119449138641358, 0.10082264453172683, 0.10055562257766723, 0.10087890714406968, 0.10134791731834411, 0.09904380410909652, 0.10088843762874604, 0.09960547864437103, 0.10033334046602249, 0.09887495279312133, 0.09863258302211761, 0.0990755507349968, 0.09995471507310867, 0.09891846269369126, 0.09907034456729889, 0.1005001774430275, 0.09789363384246826, 0.10004596143960953, 0.09774849057197571, 0.0991165891289711, 0.09892991840839387, 0.09759220987558365, 0.09693575978279113, 0.09867461711168289, 0.09730821043252945, 0.09845768928527832, 0.09805412501096726, 0.09871473580598832, 0.09824212580919266, 0.09700628221035004, 0.0973214203119278, 0.09710858374834061, 0.09777569830417633, 0.09735809475183486, 0.09701046675443649, 0.09699743241071701, 0.09818779408931733, 0.09837408691644668, 0.0977315804362297, 0.09605375528335572, 0.09571435391902923, 0.09682165145874023, 0.09719659209251404, 0.0972245568037033, 0.09622048437595368, 0.09556757271289826, 0.09962690770626068, 0.09633611172437667, 0.09540571361780166, 0.09498394161462784, 0.09626050740480423, 0.09598508387804032, 0.09611036241054535, 0.09590167194604873, 0.09453069686889648, 0.09491714775562286]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 7\n",
      "accuracy : [0.97033334, 0.97033334, 0.9723333, 0.9716667, 0.9726667, 0.971, 0.971, 0.9713333, 0.97066665, 0.971, 0.97066665, 0.9713333, 0.9716667, 0.9713333, 0.97066665, 0.9716667, 0.9716667, 0.97333336, 0.972, 0.973, 0.971, 0.9716667, 0.97033334, 0.9716667, 0.97066665, 0.9713333, 0.97066665, 0.9713333, 0.97066665, 0.972, 0.9726667, 0.97333336, 0.971, 0.9726667, 0.97, 0.9716667, 0.9716667, 0.9723333, 0.9713333, 0.9716667, 0.9723333, 0.972, 0.972, 0.971, 0.9716667, 0.97333336, 0.9713333, 0.9723333, 0.9723333, 0.9713333, 0.9723333, 0.974, 0.9723333, 0.973, 0.9716667, 0.9716667, 0.9713333, 0.97333336, 0.97333336, 0.9713333, 0.973, 0.97333336, 0.973, 0.973, 0.9726667, 0.9723333, 0.9723333, 0.974, 0.9716667, 0.9726667, 0.9726667, 0.971, 0.975, 0.9726667, 0.9713333, 0.97366667, 0.97433335, 0.97366667, 0.97333336, 0.97433335, 0.9713333, 0.9726667, 0.97333336, 0.9716667, 0.97333336, 0.97333336, 0.9723333, 0.974, 0.972, 0.97333336, 0.9716667, 0.97466666, 0.9716667, 0.974, 0.974, 0.974, 0.97366667, 0.97333336, 0.972, 0.9726667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : [0.0952977529168129, 0.09581425487995147, 0.09501499205827713, 0.09579060345888138, 0.09433328688144683, 0.09529747635126114, 0.09660229831933975, 0.09788424491882325, 0.09646736055612565, 0.09542937695980072, 0.09575795948505401, 0.09370966523885726, 0.0951089996099472, 0.09426077663898468, 0.09439306020736694, 0.09502733021974563, 0.09349779576063157, 0.09311080366373062, 0.09422494500875472, 0.09443188905715942, 0.09296837121248246, 0.09322465807199479, 0.09557798266410827, 0.09292139649391175, 0.09403116464614868, 0.09374043107032776, 0.09378198862075805, 0.0939660620689392, 0.09480705261230468, 0.09272617906332016, 0.09308503925800324, 0.09226472496986389, 0.09232019871473313, 0.09214458405971528, 0.09390623092651368, 0.09264579564332961, 0.09379966676235199, 0.09274610221385955, 0.092256338596344, 0.09165597319602967, 0.09219387620687484, 0.09176857531070709, 0.09227164506912232, 0.09161036610603332, 0.09355926781892776, 0.09100004583597184, 0.0922402560710907, 0.09236708521842957, 0.09357532024383546, 0.09270571231842041, 0.09017854928970337, 0.09054784685373306, 0.0919006410241127, 0.09187671571969985, 0.09175320148468018, 0.09284473896026611, 0.09344620436429978, 0.09025570273399353, 0.0904348361492157, 0.09103002160787582, 0.09122872024774552, 0.09110884189605713, 0.09091393798589706, 0.0902129054069519, 0.08959193170070648, 0.09029146760702134, 0.09194588869810104, 0.08890889525413513, 0.09036977976560592, 0.09081790328025818, 0.0918253442645073, 0.09364409565925598, 0.0886139115691185, 0.08970625251531601, 0.09118731111288071, 0.08875778615474701, 0.08907793939113617, 0.08850688755512237, 0.08966324359178543, 0.08897720694541932, 0.09228989958763123, 0.0894224688410759, 0.0898479089140892, 0.09181263446807861, 0.09155505150556564, 0.08949698656797409, 0.08847712635993958, 0.08791694700717927, 0.08980649262666703, 0.08834686756134033, 0.09122136443853378, 0.0881874081492424, 0.08899278461933136, 0.08746666938066483, 0.08821133255958558, 0.08879445970058442, 0.0886650374531746, 0.08802615225315094, 0.08955165654420853, 0.08802751213312149]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 8\n",
      "accuracy : [0.9713333, 0.973, 0.973, 0.97466666, 0.9723333, 0.973, 0.9723333, 0.97366667, 0.9726667, 0.9726667, 0.972, 0.9716667, 0.9726667, 0.973, 0.97366667, 0.97033334, 0.9713333, 0.973, 0.9723333, 0.97433335, 0.972, 0.9726667, 0.97433335, 0.973, 0.973, 0.9726667, 0.973, 0.97466666, 0.97366667, 0.974, 0.9723333, 0.97333336, 0.97366667, 0.9726667, 0.9723333, 0.9723333, 0.97433335, 0.9713333, 0.97333336, 0.9716667, 0.974, 0.97366667, 0.973, 0.97366667, 0.97333336, 0.97333336, 0.974, 0.97366667, 0.973, 0.97333336, 0.9723333, 0.972, 0.97366667, 0.97333336, 0.97333336, 0.973, 0.97333336, 0.97333336, 0.973, 0.97366667, 0.97433335, 0.97366667, 0.97466666, 0.9713333, 0.9716667, 0.974, 0.974, 0.975, 0.974, 0.973, 0.97433335, 0.97333336, 0.972, 0.973, 0.973, 0.972, 0.973, 0.97333336, 0.97333336, 0.97466666, 0.974, 0.97366667, 0.97333336, 0.974, 0.973, 0.97433335, 0.97466666, 0.974, 0.97433335, 0.975, 0.97333336, 0.973, 0.97433335, 0.974, 0.974, 0.97466666, 0.97366667, 0.974, 0.974, 0.97466666]\n",
      "loss : [0.08922714054584503, 0.08943526089191436, 0.08827418953180313, 0.08716131895780563, 0.09033533185720444, 0.0876055246591568, 0.08727019906044006, 0.08671753466129303, 0.08827141880989074, 0.087950841486454, 0.08897656619548798, 0.08765587389469147, 0.09022353619337081, 0.08824421584606171, 0.08716558873653411, 0.09170086622238159, 0.08880383640527725, 0.08651883095502853, 0.09095298349857331, 0.08516262948513031, 0.08773570090532302, 0.08834783762693404, 0.08863034665584564, 0.08707098335027695, 0.0862934449315071, 0.08707152217626572, 0.08634435415267944, 0.08552639126777649, 0.08599826335906982, 0.08585066616535186, 0.0877116146683693, 0.08739719152450562, 0.08874929279088974, 0.08765518754720687, 0.0885053077340126, 0.08696535527706147, 0.08475638717412949, 0.0892666208744049, 0.08662279784679412, 0.08771679103374481, 0.08409425318241119, 0.08624481707811356, 0.08807245343923568, 0.08552814930677415, 0.08574944525957108, 0.08613585412502289, 0.08600594162940979, 0.08683878928422928, 0.08678837060928345, 0.0842367872595787, 0.08820397406816483, 0.08709619790315629, 0.08493283152580261, 0.0847888696193695, 0.0851206710934639, 0.08485010474920272, 0.08641279309988022, 0.08428554892539979, 0.08632490277290344, 0.08465029418468475, 0.08428610354661942, 0.08378758311271667, 0.08434639722108841, 0.08572316199541091, 0.08760422617197036, 0.08502586096525193, 0.08497391432523728, 0.08379777133464814, 0.08470841526985168, 0.08407369077205658, 0.08303437650203704, 0.08450592428445816, 0.08752175986766815, 0.08675941497087479, 0.08648074418306351, 0.08428238689899445, 0.08493286371231079, 0.085504909157753, 0.0833380252122879, 0.08354405403137206, 0.08315095663070679, 0.08582235425710678, 0.08432741463184357, 0.08257136762142181, 0.08429530203342438, 0.08273881852626801, 0.08326321184635162, 0.08290850698947906, 0.08255172431468964, 0.08366405814886094, 0.0839944177865982, 0.08411610811948776, 0.08364779829978942, 0.08321508556604386, 0.08426333755254746, 0.0837697771191597, 0.08453653961420059, 0.08300512701272965, 0.08435087591409683, 0.08218467384576797]\n",
      "잘 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 9\n",
      "accuracy : [0.974, 0.974, 0.97333336, 0.97466666, 0.97433335, 0.97433335, 0.97466666, 0.974, 0.97433335, 0.9726667, 0.973, 0.97466666, 0.97466666, 0.973, 0.974, 0.97466666, 0.97466666, 0.97333336, 0.974, 0.97366667, 0.97466666, 0.974, 0.97333336, 0.97333336, 0.97366667, 0.974, 0.974, 0.97433335, 0.973, 0.974, 0.97433335, 0.97366667, 0.974, 0.97433335, 0.97333336, 0.974, 0.973, 0.97466666, 0.974, 0.97433335, 0.974, 0.97433335, 0.97333336, 0.97466666, 0.97466666, 0.97433335, 0.97366667, 0.97366667, 0.97433335, 0.97466666, 0.974, 0.975, 0.97433335, 0.97433335, 0.9726667, 0.97366667, 0.97333336, 0.97433335, 0.974, 0.97466666, 0.97566664, 0.97466666, 0.97533333, 0.975, 0.97366667, 0.97433335, 0.97566664, 0.97566664, 0.97566664, 0.974, 0.975, 0.975, 0.97433335, 0.97366667, 0.97366667, 0.97566664, 0.97533333, 0.975, 0.97466666, 0.97566664, 0.9726667, 0.9766667, 0.97433335, 0.97533333, 0.974, 0.976, 0.97433335, 0.97533333, 0.97466666, 0.97533333, 0.975, 0.97533333, 0.975, 0.975, 0.97433335, 0.975, 0.975, 0.974, 0.9723333, 0.9726667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : [0.0818703556060791, 0.08277353256940842, 0.08287375837564469, 0.08372716963291169, 0.08182830452919006, 0.08251799374818802, 0.08176595568656922, 0.08167889535427093, 0.08287277579307556, 0.08346825629472733, 0.08250896126031876, 0.08109280675649642, 0.08221127569675446, 0.08213051795959472, 0.08308053970336914, 0.08063996523618698, 0.08208282262086869, 0.08291386812925339, 0.08525343626737594, 0.08311809301376342, 0.0810684123635292, 0.08045109063386917, 0.08251080811023712, 0.08172654151916504, 0.08102274656295777, 0.08333559691905976, 0.0818823117017746, 0.08061903297901153, 0.08146471738815307, 0.07991370290517807, 0.08201370298862458, 0.08273517668247223, 0.0817640569806099, 0.08164283782243728, 0.08222512483596801, 0.08110116094350815, 0.0833959323167801, 0.08160387247800827, 0.0800059700012207, 0.08021575331687927, 0.081016925573349, 0.08026597291231155, 0.08120562195777893, 0.0813360235095024, 0.08072669953107833, 0.08059525609016419, 0.07913056403398513, 0.08052906394004822, 0.08042712271213531, 0.08046677708625793, 0.07988783597946167, 0.07984032154083252, 0.07971189320087432, 0.07927442252635956, 0.08272894382476807, 0.08007747977972031, 0.08277304589748383, 0.0787987071275711, 0.08021971583366394, 0.07850564748048783, 0.07966187119483947, 0.07821127116680145, 0.08106257617473603, 0.07957347184419632, 0.08128980964422226, 0.07971183329820633, 0.0781734612584114, 0.07808491080999375, 0.07875741690397263, 0.08066873639822006, 0.07749474972486496, 0.07864796787500382, 0.07802544593811035, 0.08164367109537124, 0.08234680354595185, 0.07914860069751739, 0.07953081071376801, 0.07629030585289001, 0.07895023882389068, 0.07722269594669343, 0.07796227544546128, 0.0773462873697281, 0.07841823875904083, 0.07807498842477799, 0.07808599770069122, 0.0781285884976387, 0.08095011204481124, 0.07649276912212372, 0.07826818883419037, 0.078130344748497, 0.07905410796403885, 0.07729204922914505, 0.07632151305675507, 0.0763995385169983, 0.07762212961912156, 0.08019466996192932, 0.07860584706068038, 0.07664965569972992, 0.08217031925916672, 0.0808393606543541]\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 10\n",
      "accuracy : [0.9763333, 0.97433335, 0.97466666, 0.97433335, 0.975, 0.976, 0.974, 0.974, 0.97466666, 0.97533333, 0.97533333, 0.97333336, 0.974, 0.97566664, 0.97366667, 0.974, 0.975, 0.975, 0.97466666, 0.975, 0.976, 0.975, 0.97366667, 0.97433335, 0.97433335, 0.97566664, 0.97533333, 0.97533333, 0.97533333, 0.974, 0.97333336, 0.97466666, 0.975, 0.97533333, 0.975, 0.975, 0.97433335, 0.97566664, 0.97533333, 0.97433335, 0.976, 0.975, 0.976, 0.975, 0.975, 0.97466666, 0.9766667, 0.976, 0.976, 0.97466666, 0.975, 0.973, 0.97533333, 0.97533333, 0.97533333, 0.9763333, 0.97566664, 0.97533333, 0.974, 0.977, 0.9763333, 0.97433335, 0.97566664, 0.97566664, 0.97466666, 0.975, 0.975, 0.97466666, 0.97533333, 0.975, 0.97466666, 0.975, 0.97533333, 0.97466666, 0.97566664, 0.975, 0.97466666, 0.97566664, 0.97566664, 0.97533333, 0.97533333, 0.97566664, 0.977, 0.9766667, 0.9763333, 0.9776667, 0.976, 0.974, 0.976, 0.976, 0.977, 0.975, 0.9766667, 0.97466666, 0.9763333, 0.9763333, 0.97466666, 0.9763333, 0.9763333, 0.9766667]\n",
      "loss : [0.07639401465654373, 0.07824801921844482, 0.07722939312458038, 0.07843020260334015, 0.07797265708446503, 0.07660164564847946, 0.07802184730768204, 0.07661558330059051, 0.07693500995635986, 0.07627274334430695, 0.0759765538573265, 0.07860726535320282, 0.07750417768955231, 0.07622668504714966, 0.08040383607149124, 0.07636500209569931, 0.08000224888324738, 0.07567544162273407, 0.07792990773916245, 0.07653253585100174, 0.077714364528656, 0.07606873244047165, 0.07784840315580369, 0.0768949830532074, 0.07803895950317383, 0.07540358036756516, 0.07705498993396759, 0.07585206180810929, 0.07562077850103378, 0.07710303485393524, 0.07649702042341232, 0.07544041216373444, 0.0764693221449852, 0.07703742533922195, 0.07705851286649704, 0.07890264093875884, 0.07452701538801193, 0.07358680307865142, 0.07552628308534622, 0.0767423066496849, 0.07470077246427537, 0.07777569055557251, 0.07487949728965759, 0.0761731132864952, 0.07466383635997773, 0.0755146610736847, 0.07371003538370133, 0.07351512908935547, 0.07391714364290237, 0.07588852941989899, 0.07830539852380752, 0.07751765340566635, 0.07588619083166122, 0.07499167948961258, 0.07552833527326584, 0.0738291898369789, 0.07509503155946731, 0.07496338099241256, 0.07616838067770004, 0.07317250162363052, 0.07471410095691682, 0.07481148570775986, 0.07396495401859284, 0.07338229984045029, 0.07439423382282256, 0.07441017717123032, 0.0752428138256073, 0.07564857959747315, 0.074773670732975, 0.07462179392576218, 0.07464697152376175, 0.07637287735939026, 0.07485587775707245, 0.07446456491947175, 0.07407239764928818, 0.07460038125514984, 0.07780518382787704, 0.07302291929721832, 0.0740332955121994, 0.07377714961767197, 0.07366893023252487, 0.07362382590770722, 0.07283068150281906, 0.07313453882932663, 0.07241083055734635, 0.07163093090057374, 0.07271162301301956, 0.0807125923037529, 0.07690766274929046, 0.07256057739257812, 0.0728574225306511, 0.07399792999029159, 0.07324346125125886, 0.07417033940553665, 0.07139197915792465, 0.07237280011177064, 0.07257653534412384, 0.07364858269691467, 0.07153397053480148, 0.07234908759593964]\n",
      "여행 은 언제나 좋죠 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#에폭\n",
    "for epoch in range(10):\n",
    "    print(\"total epoch:\", epoch+1)\n",
    "    history=model.fit([xEncoder,xDecoder], yDecoder,\n",
    "             epochs=100,\n",
    "             batch_size=64,\n",
    "                     verbose=0)\n",
    "    print(\"accuracy :\", history.history['accuracy'])\n",
    "    print(\"loss :\", history.history['loss'])\n",
    "    #문장 예측\n",
    "    #3박 4일 놀러 가고 싶다 -> 여행 은 언제나 좋죠\n",
    "    \n",
    "    inputEncoder=xEncoder[2].reshape(1,xEncoder[2].shape[0]) #(30,) ->(1,30)\n",
    "    inputDecoder=xDecoder[2].reshape(1,xDecoder[2].shape[0]) #(30,) ->(1,30)\n",
    "    \n",
    "    results=model.predict([inputEncoder,inputDecoder])\n",
    "    \n",
    "    #결과값에 대해서 가장 큰 값의 위치를 구함\n",
    "    index=np.argmax(results[0], 1)\n",
    "    #인덱스 -> 문장으로 변환\n",
    "    sentence=convertIndexToText(index, indexToWord)\n",
    "    print(sentence)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 입력\n",
    "def makePredictInput (sentence) :\n",
    "    \n",
    "    sentences = []\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "    sentences = posTag(sentences)\n",
    "    \n",
    "    inputSeq = convertTextToIndex(sentences, wordToIndex, ENCODER_INPUT)\n",
    "    \n",
    "    return inputSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 답변 생성\n",
    "def genereateText(inputSeq) :\n",
    "    # 입력을 인코더에 넣고, 마지막 상태 구함\n",
    "    states = encoderModel.predict(inputSeq)\n",
    "    \n",
    "    # 목표 시퀀스 초기화\n",
    "    targetSeq = np.zeros((1,1))\n",
    "    targetSeq[0,0] = STA_INDEX  # <START>시그널 인덱스 추가\n",
    "    # 인덱스 초기화\n",
    "    indexs = []\n",
    "    \n",
    "    # 디코더 반복\n",
    "    while 1 :\n",
    "        decoderOutputs, stateH, stateC = decoderModel.predict([targetSeq] + states)\n",
    "        # 결과를 원핫인코딩 형식으로 변환\n",
    "        index = np.argmax(decoderOutputs[0,0,:])\n",
    "        indexs.append(index)\n",
    "        \n",
    "        # 종료 체크\n",
    "        if index == END_INDEX or len(indexs)>=maxSequences :\n",
    "            break\n",
    "        \n",
    "        # targetSeq를 이전 출력으로 설정\n",
    "        targetSeq = np.zeros((1,1))\n",
    "        targetSeq[0,0] = index  \n",
    "\n",
    "        states = [stateH, stateC]\n",
    "    \n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convertIndexToText(indexs, indexToWord)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[415, 227,  11, 285,   4,   3,   3,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputSeq = makePredictInput('3박 4일 놀러가고 싶지않다')\n",
    "# [[320,157,...,19,0,0,0...,0]]\n",
    "inputSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'여행 은 언제나 좋죠 '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = genereateText(inputSeq)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 생성\n",
    "## 인코더 정의\n",
    "# 입력 문장의 인덱스 sequence를 입력\n",
    "encoderInputs = layers.Input(shape=(None, ))\n",
    "# 임베딩 계층          454           100\n",
    "encoderOutputs = layers.Embedding(len(words), embeddingDim)(encoderInputs)\n",
    "# LSTM\n",
    "encoderOutputs, stateH, stateC = layers.LSTM(lstmHiddenDim, return_state=True,return_sequences=False, dropout=0.2, recurrent_dropout=0.5)(encoderOutputs)\n",
    "# return_state = True => 상태값 리턴  / LSTM은 2개의 상태 존재(셀, 히든스테이트)\n",
    "encoderStates = [stateH, stateC]\n",
    "## 디코더 정의\n",
    "# 출력 문장의 인덱스 sequence를 입력\n",
    "decoderInputs = layers.Input(shape=(None, ))\n",
    "# 임베딩 계층                           454           100\n",
    "decoderEmbedding = layers.Embedding(len(words),embeddingDim)\n",
    "decoderOutputs = decoderEmbedding(decoderInputs)\n",
    "# LSTM\n",
    "decoderLSTM = layers.LSTM(lstmHiddenDim, return_state=True,return_sequences=True, dropout=0.2, recurrent_dropout=0.5)\n",
    "decoderOutputs, _, _ = decoderLSTM(decoderOutputs, initial_state=encoderStates)\n",
    "decoderDense = layers.Dense(len(words), activation='softmax')(decoderOutputs)\n",
    "\n",
    "model = models.Model([encoderInputs, decoderInputs] ,decoderOutputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-38d596a5f5e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Dense계층을 통해 원핫 형식으로 예측 단어인덱스 추출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mdecoderOutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoderDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoderOutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# 예측모델 디코더 설정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "## 예측 모델 인코더 정의\n",
    "encoderModel= models.Model(encoderInputs, encoderStates)\n",
    "\n",
    "## 예측 모델 디코더 정의\n",
    "decoderStateInputH = layers.Input(shape=(lstmHiddenDim,))\n",
    "decoderStateInputC = layers.Input(shape=(lstmHiddenDim,))\n",
    "decoderStateInputs = [decoderStateInputH, decoderStateInputC]\n",
    "\n",
    "# 임베딩 계층\n",
    "decoderOutputs = decoderEmbedding(decoderInputs)\n",
    "\n",
    "# LSTM 계층\n",
    "decoderOutputs, stateH, stateC = decoderLSTM(decoderOutputs, initial_state=decoderStateInputs)\n",
    "\n",
    "decoderStates = [stateH, stateC]\n",
    "\n",
    "# Dense계층을 통해 원핫 형식으로 예측 단어인덱스 추출\n",
    "decoderOutputs = decoderDense(decoderOutputs)\n",
    "\n",
    "# 예측모델 디코더 설정\n",
    "model = models.Model([decoderInputs]+ decoderStateInputs, [decoderOutputs]+decoderStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "############### 인코더 모델 정의\n",
    "# 입력 문장의 인덱스 sequence를 입력\n",
    "encoderInputs = layers.Input(shape=(None,))\n",
    "# 임베딩 계층\n",
    "encoderOutputs = layers.Embedding(len(words),embeddingDim)(encoderInputs)\n",
    "# LSTM cell\n",
    "encoderOutputs , stateH , stateC = layers.LSTM(lstmHiddenDim,return_state=True,return_sequences=False,dropout=0.2,recurrent_dropout=0.5)(encoderOutputs)\n",
    "encoderStates = [stateH , stateC]\n",
    "\n",
    "############### 디코더 모델 정의\n",
    "# 출력 문장의 인덱스 sequence를 입력\n",
    "decoderInputs = layers.Input(shape=(None,))\n",
    "# 임베딩 계층                           454           100\n",
    "decoderEmbedding = layers.Embedding(len(words),embeddingDim)\n",
    "decoderOutputs = decoderEmbedding(decoderInputs)\n",
    "# LSTM cell\n",
    "decoderLSTM = layers.LSTM(lstmHiddenDim,return_state=True,return_sequences=True,dropout=0.2,recurrent_dropout=0.5)\n",
    "decoderOutputs , _ , _ = decoderLSTM(decoderOutputs,initial_state=encoderStates)\n",
    "\n",
    "decoderDense = layers.Dense(len(words),activation='softmax')\n",
    "decoderOutputs = decoderDense(decoderOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측_Test Model\n",
    "\n",
    "############### 인코더 모델 정의\n",
    "encoderModel = models.Model(encoderInputs,encoderStates)\n",
    "\n",
    "############### 디코더 모델 정의 : 바로 앞에 있는 디코더의 출력(상태)을 입력받아 예측해야함\n",
    "decoderStateInputH = layers.Input(shape=(lstmHiddenDim,))\n",
    "decoderStateInputC = layers.Input(shape=(lstmHiddenDim,))\n",
    "decoderStateInputs = [decoderStateInputH , decoderStateInputC]\n",
    "# 디코더 임베딩 계층\n",
    "decoderOutputs = decoderEmbedding(decoderInputs)\n",
    "# LSTM Cell\n",
    "decoderOutputs , stateH , stateC = decoderLSTM(decoderOutputs,initial_state=decoderStateInputs)\n",
    "decoderStates = [stateH , stateC]\n",
    "# Dense 계층을 통해 원핫 형식으로 예측 단어 인덱스 추출\n",
    "decoderOutputs = decoderDense(decoderOutputs)\n",
    "\n",
    "# 예측 모델 디코더 설정\n",
    "decoderModel = models.Model(inputs=[decoderInputs]+decoderStateInputs , outputs=[decoderOutputs]+decoderStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 문장으로 변환\n",
    "def convertIndexToText(indexs, voc) :\n",
    "    # 구현\n",
    "    sentence = ''\n",
    "    \n",
    "    for i in indexs :\n",
    "        if i == END_INDEX : # 종료 인덱스\n",
    "            break\n",
    "        if voc.get(i) is not None :\n",
    "            sentence += voc[i]\n",
    "        else :\n",
    "            sentence.extend([voc[OOV_INDEX]])\n",
    "        sentence += ' '\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total epoch :  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected lstm_4 to have shape (None, 128) but got array with shape (30, 454)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1d1ab418c57d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'total epoch : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxDecoder\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myDecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected lstm_4 to have shape (None, 128) but got array with shape (30, 454)"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import tqdm_notebook_callback\n",
    "\n",
    "for epoch in range(20) :\n",
    "    print('total epoch : ', epoch+1)\n",
    "    history = model.fit([xEncoder, xDecoder], yDecoder, epochs=100, batch_size=64)         \n",
    "    print('accuracy : ', history.history['accuracy'])\n",
    "    print('loss : ', history.history['loss'])\n",
    "    \n",
    "    # 문장예측\n",
    "    # 3박 4일 놀러 가고 싶다 =? 여행 은 언제나 좋죠\n",
    "    \n",
    "    inputEncoder = xEncoder[2].reshape(1, xEncoder[2].shape[0])\n",
    "    inputDecoder = xDecoder[2].reshape(1, xDecoder[2].shape[0])\n",
    "    \n",
    "    results = model.predict([inputEncoder, inputDecoder])\n",
    "    \n",
    "    # 결과값에 대해서 가장 큰 값으 위치를 구함\n",
    "    index = np.argmax(results[0], 1)\n",
    "    # 인덱스 -> 문장으로 변환\n",
    "    sentence = convertIndexToText(index, indexToWord)\n",
    "    print(sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "me = MeCab.Tagger()\n",
    "res = me.parse('드라이브할 때 듣기 좋은 노래 들려줘')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
