{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='data/planesnet/planesnet.json' mode='r' encoding='cp949'>\n"
     ]
    }
   ],
   "source": [
    "f_plane = open('data/planesnet/planesnet.json')\n",
    "print(f_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_dataset = json.load(f_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_plane.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'labels', 'locations', 'scene_ids'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plane_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uint8은 0 ~ 255 까지 표현 가능\n",
    "plane_x = np.array(plane_dataset['data']).astype('uint8')\n",
    "plane_y = np.array(plane_dataset['labels']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 1200)\n",
      "(32000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32000, 20, 20, 3)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(plane_x.shape)\n",
    "print(plane_y.shape)\n",
    "\n",
    "plane_x = plane_x.reshape([-1,3,20,20]).transpose([0,2,3,1])\n",
    "plane_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 섞기\n",
    "shuffle_index = np.arange(32000)\n",
    "np.random.shuffle(shuffle_index)\n",
    "\n",
    "plane_x = plane_x[shuffle_index]\n",
    "plane_y = plane_y[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "plane_x = plane_x / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_classes = {0:'No Plane', 1:'Plane'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(8) :\n",
    "    plt.subplot(1,8,i+1)\n",
    "    # 축 설정\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.imshow(plane_x[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(plane_classes[plane_y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 나누기\n",
    "plane_x_train, plane_x_test, plane_y_train, plane_y_test = train_test_split(plane_x, plane_y, test_size=0.2, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(inputshape) :\n",
    "    model = tf.keras.Sequential([\n",
    "        keras.layers.Conv2D(32, (5,5), activation='relu', padding='same', input_shape=inputshape),\n",
    "        keras.layers.Conv2D(64, (5,5), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(2,2),\n",
    "        keras.layers.Dropout(0.25),\n",
    "        \n",
    "        keras.layers.Conv2D(128, (5,5), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(2,2),\n",
    "        keras.layers.Dropout(0.25),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.Dropout(0.35),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.35),\n",
    "        \n",
    "        keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 20, 20, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 587,202\n",
      "Trainable params: 587,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_plane = cnn_model((20,20,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback 객체 생성\n",
    "import os\n",
    "checkpoint_path1 = 'cp.ckpt'\n",
    "checkpoint_dir1 = os.path.dirname(checkpoint_path1)\n",
    "\n",
    "cp_callback1 = tf.keras.callbacks.ModelCheckpoint(checkpoint_path1, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "training_plane.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                       optimizer=tf.keras.optimizers.Adam(),\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x2640b6ba608>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plane_x_train.shape\n",
    "plane_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17152 samples, validate on 8448 samples\n",
      "Epoch 1/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.7485\n",
      "Epoch 00001: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 24s 1ms/sample - loss: 0.5746 - acc: 0.7481 - val_loss: 0.5194 - val_acc: 0.7493\n",
      "Epoch 2/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.3810 - acc: 0.8141\n",
      "Epoch 00002: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.3801 - acc: 0.8141 - val_loss: 0.3184 - val_acc: 0.8433\n",
      "Epoch 3/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.8945\n",
      "Epoch 00003: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.2458 - acc: 0.8954 - val_loss: 0.2194 - val_acc: 0.9147\n",
      "Epoch 4/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9232\n",
      "Epoch 00004: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.1929 - acc: 0.9231 - val_loss: 0.2308 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9400\n",
      "Epoch 00005: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 24s 1ms/sample - loss: 0.1565 - acc: 0.9401 - val_loss: 0.1243 - val_acc: 0.9503\n",
      "Epoch 6/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9504\n",
      "Epoch 00006: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.1306 - acc: 0.9506 - val_loss: 0.1398 - val_acc: 0.9419\n",
      "Epoch 7/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9555\n",
      "Epoch 00007: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.1189 - acc: 0.9555 - val_loss: 0.1078 - val_acc: 0.9582\n",
      "Epoch 8/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9631\n",
      "Epoch 00008: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0968 - acc: 0.9634 - val_loss: 0.0790 - val_acc: 0.9693\n",
      "Epoch 9/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9612\n",
      "Epoch 00009: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0991 - acc: 0.9613 - val_loss: 0.1006 - val_acc: 0.9611\n",
      "Epoch 10/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9701\n",
      "Epoch 00010: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0821 - acc: 0.9702 - val_loss: 0.0773 - val_acc: 0.9712\n",
      "Epoch 11/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9669\n",
      "Epoch 00011: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0899 - acc: 0.9670 - val_loss: 0.0842 - val_acc: 0.9685\n",
      "Epoch 12/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9736\n",
      "Epoch 00012: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0714 - acc: 0.9736 - val_loss: 0.0639 - val_acc: 0.9748\n",
      "Epoch 13/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9784\n",
      "Epoch 00013: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0582 - acc: 0.9784 - val_loss: 0.0645 - val_acc: 0.9763\n",
      "Epoch 14/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9782\n",
      "Epoch 00014: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0623 - acc: 0.9782 - val_loss: 0.0613 - val_acc: 0.9786\n",
      "Epoch 15/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9779\n",
      "Epoch 00015: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0620 - acc: 0.9777 - val_loss: 0.0636 - val_acc: 0.9775\n",
      "Epoch 16/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9777\n",
      "Epoch 00016: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0584 - acc: 0.9776 - val_loss: 0.0525 - val_acc: 0.9819\n",
      "Epoch 17/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9824\n",
      "Epoch 00017: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0486 - acc: 0.9825 - val_loss: 0.0582 - val_acc: 0.9799\n",
      "Epoch 18/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9851\n",
      "Epoch 00018: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0429 - acc: 0.9851 - val_loss: 0.0507 - val_acc: 0.9814\n",
      "Epoch 19/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9862\n",
      "Epoch 00019: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0390 - acc: 0.9863 - val_loss: 0.0579 - val_acc: 0.9793\n",
      "Epoch 20/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9847\n",
      "Epoch 00020: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 26s 1ms/sample - loss: 0.0441 - acc: 0.9845 - val_loss: 0.0512 - val_acc: 0.9815\n",
      "Epoch 21/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9856\n",
      "Epoch 00021: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 27s 2ms/sample - loss: 0.0426 - acc: 0.9856 - val_loss: 0.0650 - val_acc: 0.9772\n",
      "Epoch 22/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9851\n",
      "Epoch 00022: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 24s 1ms/sample - loss: 0.0407 - acc: 0.9851 - val_loss: 0.0727 - val_acc: 0.9721\n",
      "Epoch 23/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9846\n",
      "Epoch 00023: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0433 - acc: 0.9848 - val_loss: 0.0761 - val_acc: 0.9719\n",
      "Epoch 24/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9860\n",
      "Epoch 00024: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0392 - acc: 0.9860 - val_loss: 0.0579 - val_acc: 0.9812\n",
      "Epoch 25/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9901\n",
      "Epoch 00025: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0303 - acc: 0.9902 - val_loss: 0.0506 - val_acc: 0.9846\n",
      "Epoch 26/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9876\n",
      "Epoch 00026: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 24s 1ms/sample - loss: 0.0335 - acc: 0.9878 - val_loss: 0.0507 - val_acc: 0.9845\n",
      "Epoch 27/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9898\n",
      "Epoch 00027: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0278 - acc: 0.9897 - val_loss: 0.0646 - val_acc: 0.9790\n",
      "Epoch 28/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9859\n",
      "Epoch 00028: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0372 - acc: 0.9861 - val_loss: 0.0510 - val_acc: 0.9844\n",
      "Epoch 29/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9903\n",
      "Epoch 00029: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 23s 1ms/sample - loss: 0.0277 - acc: 0.9902 - val_loss: 0.0642 - val_acc: 0.9814\n",
      "Epoch 30/30\n",
      "16896/17152 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9892\n",
      "Epoch 00030: saving model to cp.ckpt\n",
      "17152/17152 [==============================] - 24s 1ms/sample - loss: 0.0285 - acc: 0.9893 - val_loss: 0.0559 - val_acc: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-700.6115152835846"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time_plane = time.time()\n",
    "# validation_split -> train데이터에서 일부를 검증 데이터로 사용하겠다.\n",
    "training_plane.fit(plane_x_train, plane_y_train, epochs=30, batch_size=256, validation_split=0.33, callbacks=[cp_callback1])\n",
    "\n",
    "time_plane = start_time_plane - time.time()\n",
    "time_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 2s 383us/sample - loss: 0.0552 - acc: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.055151176340732494, 0.98015624]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_plane.evaluate(plane_x_test, plane_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = training_plane.history.history['acc']\n",
    "val_accuracy = training_plane.history.history['val_acc']\n",
    "\n",
    "loss = training_plane.history.history['loss']\n",
    "val_loss = training_plane.history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(accuracy, label='acc')\n",
    "plt.plot(val_accuracy, label='val_acc')\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/sonar.csv', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:60]\n",
    "\n",
    "# 정답데이터 라벨링\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 1004\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y,test_size=0.2,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 60)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 골격을 만들어 저장\n",
    "\n",
    "base_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=[60]),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),    \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "base_model.save('base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 모델링\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import load_model\n",
    "\n",
    "sonar_model = load_model('base_model.h5')\n",
    "\n",
    "sonar_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(patience=20, monitor='val_loss')\n",
    "\n",
    "mcp = ModelCheckpoint('sonar_model/sonar_model.h5',\n",
    "               monitor='val_loss',\n",
    "               verbose=1,\n",
    "               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 50 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - 1s 12ms/step - loss: 0.2611 - accuracy: 0.4310 - val_loss: 0.2458 - val_accuracy: 0.6200\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.2479 - accuracy: 0.5431 - val_loss: 0.2484 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 0s 172us/step - loss: 0.2468 - accuracy: 0.4828 - val_loss: 0.2507 - val_accuracy: 0.4400\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.2400 - accuracy: 0.6379 - val_loss: 0.2516 - val_accuracy: 0.4400\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.2418 - accuracy: 0.5603 - val_loss: 0.2524 - val_accuracy: 0.4200\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 0s 163us/step - loss: 0.2392 - accuracy: 0.6034 - val_loss: 0.2518 - val_accuracy: 0.4400\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 0s 172us/step - loss: 0.2346 - accuracy: 0.5776 - val_loss: 0.2517 - val_accuracy: 0.4400\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.2353 - accuracy: 0.6034 - val_loss: 0.2493 - val_accuracy: 0.4800\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.2300 - accuracy: 0.6207 - val_loss: 0.2449 - val_accuracy: 0.5400\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.2350 - accuracy: 0.6207 - val_loss: 0.2385 - val_accuracy: 0.5800\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.2225 - accuracy: 0.6552 - val_loss: 0.2324 - val_accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.2162 - accuracy: 0.6983 - val_loss: 0.2281 - val_accuracy: 0.6200\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.2136 - accuracy: 0.7414 - val_loss: 0.2252 - val_accuracy: 0.6200\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.2146 - accuracy: 0.6379 - val_loss: 0.2242 - val_accuracy: 0.6000\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 0s 147us/step - loss: 0.2057 - accuracy: 0.7328 - val_loss: 0.2167 - val_accuracy: 0.6400\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.2042 - accuracy: 0.7500 - val_loss: 0.2072 - val_accuracy: 0.6400\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1978 - accuracy: 0.7500 - val_loss: 0.1990 - val_accuracy: 0.6600\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1880 - accuracy: 0.7414 - val_loss: 0.1885 - val_accuracy: 0.7400\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1753 - accuracy: 0.7845 - val_loss: 0.1799 - val_accuracy: 0.7600\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1785 - accuracy: 0.7586 - val_loss: 0.1759 - val_accuracy: 0.7400\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.1654 - accuracy: 0.8276 - val_loss: 0.1730 - val_accuracy: 0.7400\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 0s 190us/step - loss: 0.1558 - accuracy: 0.8276 - val_loss: 0.1735 - val_accuracy: 0.7000\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1579 - accuracy: 0.7931 - val_loss: 0.1595 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 0s 172us/step - loss: 0.1460 - accuracy: 0.8190 - val_loss: 0.1464 - val_accuracy: 0.8400\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.1430 - accuracy: 0.8362 - val_loss: 0.1477 - val_accuracy: 0.8200\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1354 - accuracy: 0.8276 - val_loss: 0.1635 - val_accuracy: 0.7600\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1332 - accuracy: 0.8017 - val_loss: 0.1728 - val_accuracy: 0.7000\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 0s 172us/step - loss: 0.1277 - accuracy: 0.8190 - val_loss: 0.1428 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1362 - accuracy: 0.8103 - val_loss: 0.1319 - val_accuracy: 0.8200\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.1173 - accuracy: 0.8621 - val_loss: 0.1320 - val_accuracy: 0.8200\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.1061 - accuracy: 0.8966 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.1012 - accuracy: 0.8966 - val_loss: 0.1388 - val_accuracy: 0.8200\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.1132 - accuracy: 0.8534 - val_loss: 0.1195 - val_accuracy: 0.8400\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.1172 - accuracy: 0.8534 - val_loss: 0.1158 - val_accuracy: 0.8200\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.1023 - accuracy: 0.8879 - val_loss: 0.1226 - val_accuracy: 0.8600\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0996 - accuracy: 0.8879 - val_loss: 0.1283 - val_accuracy: 0.8200\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.1014 - accuracy: 0.8448 - val_loss: 0.1119 - val_accuracy: 0.8800\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0885 - accuracy: 0.8966 - val_loss: 0.1063 - val_accuracy: 0.8600\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0860 - accuracy: 0.9052 - val_loss: 0.1142 - val_accuracy: 0.8400\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0802 - accuracy: 0.9138 - val_loss: 0.1214 - val_accuracy: 0.8400\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0830 - accuracy: 0.8966 - val_loss: 0.1184 - val_accuracy: 0.8400\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0827 - accuracy: 0.9052 - val_loss: 0.1164 - val_accuracy: 0.8200\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0765 - accuracy: 0.9224 - val_loss: 0.1159 - val_accuracy: 0.8400\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0762 - accuracy: 0.9052 - val_loss: 0.1228 - val_accuracy: 0.8200\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 0s 181us/step - loss: 0.0654 - accuracy: 0.9224 - val_loss: 0.1153 - val_accuracy: 0.8400\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 0s 172us/step - loss: 0.0652 - accuracy: 0.9224 - val_loss: 0.1115 - val_accuracy: 0.8800\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 0s 172us/step - loss: 0.0783 - accuracy: 0.9052 - val_loss: 0.1140 - val_accuracy: 0.8400\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0609 - accuracy: 0.9310 - val_loss: 0.1143 - val_accuracy: 0.8400\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0605 - accuracy: 0.9138 - val_loss: 0.1134 - val_accuracy: 0.8400\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0651 - accuracy: 0.9138 - val_loss: 0.1128 - val_accuracy: 0.8400\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0495 - accuracy: 0.9483 - val_loss: 0.1108 - val_accuracy: 0.8400\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0499 - accuracy: 0.9483 - val_loss: 0.1125 - val_accuracy: 0.8400\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0496 - accuracy: 0.9483 - val_loss: 0.1105 - val_accuracy: 0.8400\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0468 - accuracy: 0.9655 - val_loss: 0.1049 - val_accuracy: 0.8600\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0612 - accuracy: 0.9138 - val_loss: 0.1037 - val_accuracy: 0.8600\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0438 - accuracy: 0.9569 - val_loss: 0.1090 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0461 - accuracy: 0.9741 - val_loss: 0.1027 - val_accuracy: 0.8800\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0445 - accuracy: 0.9483 - val_loss: 0.1011 - val_accuracy: 0.8600\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0436 - accuracy: 0.9569 - val_loss: 0.1016 - val_accuracy: 0.8600\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0389 - accuracy: 0.9655 - val_loss: 0.1159 - val_accuracy: 0.8600\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0528 - accuracy: 0.9397 - val_loss: 0.1116 - val_accuracy: 0.8400\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0391 - accuracy: 0.9655 - val_loss: 0.1090 - val_accuracy: 0.8400\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0424 - accuracy: 0.9483 - val_loss: 0.1071 - val_accuracy: 0.8600\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 0s 147us/step - loss: 0.0396 - accuracy: 0.9569 - val_loss: 0.1053 - val_accuracy: 0.8800\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0352 - accuracy: 0.9569 - val_loss: 0.1046 - val_accuracy: 0.8800\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0342 - accuracy: 0.9741 - val_loss: 0.0970 - val_accuracy: 0.8800\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0295 - accuracy: 0.9828 - val_loss: 0.0932 - val_accuracy: 0.8800\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 0s 147us/step - loss: 0.0305 - accuracy: 0.9741 - val_loss: 0.0917 - val_accuracy: 0.9000\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 0s 147us/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.0927 - val_accuracy: 0.9000\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0325 - accuracy: 0.9741 - val_loss: 0.0933 - val_accuracy: 0.8800\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 0s 147us/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.0936 - val_accuracy: 0.8800\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0246 - accuracy: 0.9828 - val_loss: 0.0955 - val_accuracy: 0.8800\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0262 - accuracy: 0.9655 - val_loss: 0.0941 - val_accuracy: 0.8800\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0227 - accuracy: 0.9828 - val_loss: 0.0953 - val_accuracy: 0.8800\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.98 - 0s 181us/step - loss: 0.0272 - accuracy: 0.9741 - val_loss: 0.0954 - val_accuracy: 0.8800\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 0s 181us/step - loss: 0.0205 - accuracy: 0.9828 - val_loss: 0.0951 - val_accuracy: 0.8800\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 0s 173us/step - loss: 0.0179 - accuracy: 0.9828 - val_loss: 0.0960 - val_accuracy: 0.8800\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 0s 198us/step - loss: 0.0187 - accuracy: 0.9914 - val_loss: 0.0979 - val_accuracy: 0.8800\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0238 - accuracy: 0.9741 - val_loss: 0.1022 - val_accuracy: 0.9000\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0125 - accuracy: 0.9914 - val_loss: 0.0983 - val_accuracy: 0.8800\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0175 - accuracy: 0.9914 - val_loss: 0.0965 - val_accuracy: 0.8800\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 0s 164us/step - loss: 0.0161 - accuracy: 0.9914 - val_loss: 0.0966 - val_accuracy: 0.8400\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0171 - accuracy: 0.9741 - val_loss: 0.0982 - val_accuracy: 0.8800\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0163 - accuracy: 0.9914 - val_loss: 0.1057 - val_accuracy: 0.8800\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0140 - accuracy: 0.9828 - val_loss: 0.1013 - val_accuracy: 0.8800\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0173 - accuracy: 0.9741 - val_loss: 0.1013 - val_accuracy: 0.8800\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0153 - accuracy: 0.9914 - val_loss: 0.1003 - val_accuracy: 0.8800\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0144 - accuracy: 0.9914 - val_loss: 0.1006 - val_accuracy: 0.8600\n",
      "42/42 [==============================] - 0s 238us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12599345544974008, 0.8333333134651184]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_model.fit(xTrain, yTrain, epochs=200, batch_size=80, validation_split=0.3, callbacks=[es])\n",
    "\n",
    "sonar_model.evaluate(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 165 samples, validate on 43 samples\n",
      "Epoch 1/200\n",
      "165/165 [==============================] - 2s 9ms/step - loss: 0.0708 - accuracy: 0.9091 - val_loss: 0.0843 - val_accuracy: 0.8605\n",
      "Epoch 2/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.0707 - accuracy: 0.9030 - val_loss: 0.0569 - val_accuracy: 0.9302\n",
      "Epoch 3/200\n",
      "165/165 [==============================] - 0s 152us/step - loss: 0.0589 - accuracy: 0.9333 - val_loss: 0.0628 - val_accuracy: 0.9302\n",
      "Epoch 4/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0497 - accuracy: 0.9455 - val_loss: 0.0663 - val_accuracy: 0.9070\n",
      "Epoch 5/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0628 - accuracy: 0.9212 - val_loss: 0.0555 - val_accuracy: 0.9535\n",
      "Epoch 6/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.0579 - accuracy: 0.9394 - val_loss: 0.0529 - val_accuracy: 0.9302\n",
      "Epoch 7/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.0618 - accuracy: 0.9091 - val_loss: 0.0750 - val_accuracy: 0.9070\n",
      "Epoch 8/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0616 - accuracy: 0.9212 - val_loss: 0.1015 - val_accuracy: 0.8372\n",
      "Epoch 9/200\n",
      "165/165 [==============================] - 0s 133us/step - loss: 0.0784 - accuracy: 0.8909 - val_loss: 0.0698 - val_accuracy: 0.8837\n",
      "Epoch 10/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.0501 - accuracy: 0.9455 - val_loss: 0.0561 - val_accuracy: 0.9070\n",
      "Epoch 11/200\n",
      "165/165 [==============================] - 0s 133us/step - loss: 0.0661 - accuracy: 0.9152 - val_loss: 0.0601 - val_accuracy: 0.9302\n",
      "Epoch 12/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.0492 - accuracy: 0.9576 - val_loss: 0.0860 - val_accuracy: 0.8605\n",
      "Epoch 13/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.0603 - accuracy: 0.9152 - val_loss: 0.0830 - val_accuracy: 0.8605\n",
      "Epoch 14/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0489 - accuracy: 0.9394 - val_loss: 0.0672 - val_accuracy: 0.9302\n",
      "Epoch 15/200\n",
      "165/165 [==============================] - 0s 155us/step - loss: 0.0477 - accuracy: 0.9273 - val_loss: 0.0652 - val_accuracy: 0.9302\n",
      "Epoch 16/200\n",
      "165/165 [==============================] - 0s 155us/step - loss: 0.0510 - accuracy: 0.9394 - val_loss: 0.0699 - val_accuracy: 0.9302\n",
      "Epoch 17/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0410 - accuracy: 0.9697 - val_loss: 0.0868 - val_accuracy: 0.8605\n",
      "Epoch 18/200\n",
      "165/165 [==============================] - 0s 158us/step - loss: 0.0511 - accuracy: 0.9333 - val_loss: 0.0762 - val_accuracy: 0.8837\n",
      "Epoch 19/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0396 - accuracy: 0.9818 - val_loss: 0.0654 - val_accuracy: 0.9070\n",
      "Epoch 20/200\n",
      "165/165 [==============================] - 0s 133us/step - loss: 0.0436 - accuracy: 0.9697 - val_loss: 0.0742 - val_accuracy: 0.8837\n",
      "Epoch 21/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.0466 - accuracy: 0.9394 - val_loss: 0.0763 - val_accuracy: 0.8837\n",
      "Epoch 22/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0412 - accuracy: 0.9697 - val_loss: 0.0648 - val_accuracy: 0.9070\n",
      "Epoch 23/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.0497 - accuracy: 0.9455 - val_loss: 0.0662 - val_accuracy: 0.8837\n",
      "Epoch 24/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0408 - accuracy: 0.9576 - val_loss: 0.0724 - val_accuracy: 0.8837\n",
      "Epoch 25/200\n",
      "165/165 [==============================] - 0s 133us/step - loss: 0.0351 - accuracy: 0.9818 - val_loss: 0.0807 - val_accuracy: 0.8837\n",
      "Epoch 26/200\n",
      "165/165 [==============================] - 0s 145us/step - loss: 0.0390 - accuracy: 0.9697 - val_loss: 0.0702 - val_accuracy: 0.8837\n",
      "43/43 [==============================] - 0s 186us/step\n",
      "Train on 166 samples, validate on 42 samples\n",
      "Epoch 1/200\n",
      "166/166 [==============================] - 2s 10ms/step - loss: 0.0835 - accuracy: 0.8855 - val_loss: 0.0422 - val_accuracy: 0.9286\n",
      "Epoch 2/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0786 - accuracy: 0.8976 - val_loss: 0.0527 - val_accuracy: 0.9286\n",
      "Epoch 3/200\n",
      "166/166 [==============================] - 0s 151us/step - loss: 0.0717 - accuracy: 0.9217 - val_loss: 0.0493 - val_accuracy: 0.9524\n",
      "Epoch 4/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0795 - accuracy: 0.8735 - val_loss: 0.0468 - val_accuracy: 0.9524\n",
      "Epoch 5/200\n",
      "166/166 [==============================] - 0s 151us/step - loss: 0.0665 - accuracy: 0.9337 - val_loss: 0.0595 - val_accuracy: 0.9286\n",
      "Epoch 6/200\n",
      "166/166 [==============================] - 0s 145us/step - loss: 0.0767 - accuracy: 0.8976 - val_loss: 0.0675 - val_accuracy: 0.9048\n",
      "Epoch 7/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0758 - accuracy: 0.9096 - val_loss: 0.0500 - val_accuracy: 0.9286\n",
      "Epoch 8/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0556 - accuracy: 0.9458 - val_loss: 0.0725 - val_accuracy: 0.9286\n",
      "Epoch 9/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0793 - accuracy: 0.8855 - val_loss: 0.0699 - val_accuracy: 0.9286\n",
      "Epoch 10/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0732 - accuracy: 0.8855 - val_loss: 0.0581 - val_accuracy: 0.9286\n",
      "Epoch 11/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0825 - accuracy: 0.8916 - val_loss: 0.0693 - val_accuracy: 0.9048\n",
      "Epoch 12/200\n",
      "166/166 [==============================] - 0s 133us/step - loss: 0.0656 - accuracy: 0.9337 - val_loss: 0.0532 - val_accuracy: 0.9286\n",
      "Epoch 13/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0577 - accuracy: 0.9398 - val_loss: 0.0587 - val_accuracy: 0.9524\n",
      "Epoch 14/200\n",
      "166/166 [==============================] - 0s 151us/step - loss: 0.0687 - accuracy: 0.8916 - val_loss: 0.0532 - val_accuracy: 0.9524\n",
      "Epoch 15/200\n",
      "166/166 [==============================] - 0s 145us/step - loss: 0.0496 - accuracy: 0.9518 - val_loss: 0.0529 - val_accuracy: 0.9286\n",
      "Epoch 16/200\n",
      "166/166 [==============================] - 0s 145us/step - loss: 0.0544 - accuracy: 0.9518 - val_loss: 0.0534 - val_accuracy: 0.9286\n",
      "Epoch 17/200\n",
      "166/166 [==============================] - 0s 133us/step - loss: 0.0511 - accuracy: 0.9518 - val_loss: 0.0538 - val_accuracy: 0.9286\n",
      "Epoch 18/200\n",
      "166/166 [==============================] - 0s 139us/step - loss: 0.0482 - accuracy: 0.9458 - val_loss: 0.0574 - val_accuracy: 0.9524\n",
      "Epoch 19/200\n",
      "166/166 [==============================] - 0s 133us/step - loss: 0.0557 - accuracy: 0.9398 - val_loss: 0.0540 - val_accuracy: 0.9286\n",
      "Epoch 20/200\n",
      "166/166 [==============================] - 0s 133us/step - loss: 0.0473 - accuracy: 0.9518 - val_loss: 0.0659 - val_accuracy: 0.9286\n",
      "Epoch 21/200\n",
      "166/166 [==============================] - 0s 151us/step - loss: 0.0586 - accuracy: 0.9398 - val_loss: 0.0612 - val_accuracy: 0.9286\n",
      "42/42 [==============================] - 0s 190us/step\n",
      "Train on 167 samples, validate on 41 samples\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 2s 10ms/step - loss: 0.0748 - accuracy: 0.8982 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0689 - accuracy: 0.8982 - val_loss: 0.0338 - val_accuracy: 0.9756\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0761 - accuracy: 0.8862 - val_loss: 0.0435 - val_accuracy: 0.9024\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0723 - accuracy: 0.9042 - val_loss: 0.0441 - val_accuracy: 0.9512\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0935 - accuracy: 0.8802 - val_loss: 0.0583 - val_accuracy: 0.9024\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0749 - accuracy: 0.9042 - val_loss: 0.0291 - val_accuracy: 0.9512\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0658 - accuracy: 0.9102 - val_loss: 0.0509 - val_accuracy: 0.9268\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 0s 168us/step - loss: 0.0789 - accuracy: 0.9042 - val_loss: 0.0343 - val_accuracy: 0.9512\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0797 - accuracy: 0.8862 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0706 - accuracy: 0.9162 - val_loss: 0.0419 - val_accuracy: 0.9512\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0641 - accuracy: 0.9102 - val_loss: 0.0306 - val_accuracy: 0.9756\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0551 - accuracy: 0.9401 - val_loss: 0.0350 - val_accuracy: 0.9756\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0460 - accuracy: 0.9461 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0613 - accuracy: 0.9281 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0558 - accuracy: 0.9222 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0545 - accuracy: 0.9341 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0525 - accuracy: 0.9281 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 0s 168us/step - loss: 0.0491 - accuracy: 0.9341 - val_loss: 0.0237 - val_accuracy: 0.9756\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0461 - accuracy: 0.9461 - val_loss: 0.0300 - val_accuracy: 0.9756\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0455 - accuracy: 0.9521 - val_loss: 0.0272 - val_accuracy: 0.9756\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 0s 162us/step - loss: 0.0462 - accuracy: 0.9461 - val_loss: 0.0274 - val_accuracy: 0.9756\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 0s 198us/step - loss: 0.0462 - accuracy: 0.9401 - val_loss: 0.0272 - val_accuracy: 0.9756\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0453 - accuracy: 0.9581 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0469 - accuracy: 0.9521 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0424 - accuracy: 0.9581 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0406 - accuracy: 0.9641 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0411 - accuracy: 0.9521 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0477 - accuracy: 0.9461 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0446 - accuracy: 0.9341 - val_loss: 0.0346 - val_accuracy: 0.9756\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0502 - accuracy: 0.9401 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 0s 132us/step - loss: 0.0383 - accuracy: 0.9581 - val_loss: 0.0323 - val_accuracy: 0.9756\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0433 - accuracy: 0.9281 - val_loss: 0.0363 - val_accuracy: 0.9512\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 0s 132us/step - loss: 0.0338 - accuracy: 0.9581 - val_loss: 0.0295 - val_accuracy: 0.9756\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0384 - accuracy: 0.9461 - val_loss: 0.0327 - val_accuracy: 0.9756\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0306 - accuracy: 0.9701 - val_loss: 0.0311 - val_accuracy: 0.9756\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0443 - accuracy: 0.9461 - val_loss: 0.0363 - val_accuracy: 0.9756\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0351 - accuracy: 0.9521 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "41/41 [==============================] - 0s 219us/step\n",
      "Train on 167 samples, validate on 41 samples\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0595 - accuracy: 0.9401 - val_loss: 0.0956 - val_accuracy: 0.9024\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 0s 168us/step - loss: 0.0508 - accuracy: 0.9461 - val_loss: 0.1130 - val_accuracy: 0.8293\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0566 - accuracy: 0.9341 - val_loss: 0.1060 - val_accuracy: 0.9024\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0485 - accuracy: 0.9521 - val_loss: 0.1114 - val_accuracy: 0.8537\n",
      "Epoch 5/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0465 - accuracy: 0.9461 - val_loss: 0.1239 - val_accuracy: 0.8049\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0404 - accuracy: 0.9581 - val_loss: 0.1093 - val_accuracy: 0.9024\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 0s 138us/step - loss: 0.0477 - accuracy: 0.9461 - val_loss: 0.1092 - val_accuracy: 0.9024\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0441 - accuracy: 0.9581 - val_loss: 0.1339 - val_accuracy: 0.7561\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0521 - accuracy: 0.9222 - val_loss: 0.1179 - val_accuracy: 0.8537\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0325 - accuracy: 0.9641 - val_loss: 0.1308 - val_accuracy: 0.8293\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0691 - accuracy: 0.8982 - val_loss: 0.1180 - val_accuracy: 0.8293\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0431 - accuracy: 0.9521 - val_loss: 0.1485 - val_accuracy: 0.7317\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0676 - accuracy: 0.9042 - val_loss: 0.1701 - val_accuracy: 0.7561\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0695 - accuracy: 0.9102 - val_loss: 0.1279 - val_accuracy: 0.8293\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0361 - accuracy: 0.9581 - val_loss: 0.1167 - val_accuracy: 0.8537\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0466 - accuracy: 0.9281 - val_loss: 0.1331 - val_accuracy: 0.8293\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0596 - accuracy: 0.9162 - val_loss: 0.1173 - val_accuracy: 0.8537\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0363 - accuracy: 0.9641 - val_loss: 0.1363 - val_accuracy: 0.7805\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0438 - accuracy: 0.9461 - val_loss: 0.1442 - val_accuracy: 0.7561\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0417 - accuracy: 0.9641 - val_loss: 0.1180 - val_accuracy: 0.8780\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0255 - accuracy: 0.9760 - val_loss: 0.1160 - val_accuracy: 0.8537\n",
      "41/41 [==============================] - 0s 195us/step\n",
      "Train on 167 samples, validate on 41 samples\n",
      "Epoch 1/200\n",
      "167/167 [==============================] - 2s 11ms/step - loss: 0.0661 - accuracy: 0.9162 - val_loss: 0.0869 - val_accuracy: 0.8537\n",
      "Epoch 2/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0616 - accuracy: 0.9222 - val_loss: 0.1015 - val_accuracy: 0.8537\n",
      "Epoch 3/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0688 - accuracy: 0.9222 - val_loss: 0.0792 - val_accuracy: 0.9268\n",
      "Epoch 4/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0550 - accuracy: 0.9401 - val_loss: 0.0916 - val_accuracy: 0.8537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "167/167 [==============================] - 0s 161us/step - loss: 0.0604 - accuracy: 0.9281 - val_loss: 0.0974 - val_accuracy: 0.8293\n",
      "Epoch 6/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0604 - accuracy: 0.9281 - val_loss: 0.0970 - val_accuracy: 0.8293\n",
      "Epoch 7/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0518 - accuracy: 0.9521 - val_loss: 0.0931 - val_accuracy: 0.8780\n",
      "Epoch 8/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0487 - accuracy: 0.9461 - val_loss: 0.0893 - val_accuracy: 0.9024\n",
      "Epoch 9/200\n",
      "167/167 [==============================] - 0s 144us/step - loss: 0.0435 - accuracy: 0.9641 - val_loss: 0.0848 - val_accuracy: 0.8780\n",
      "Epoch 10/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0442 - accuracy: 0.9461 - val_loss: 0.0855 - val_accuracy: 0.8780\n",
      "Epoch 11/200\n",
      "167/167 [==============================] - 0s 162us/step - loss: 0.0491 - accuracy: 0.9461 - val_loss: 0.0816 - val_accuracy: 0.9512\n",
      "Epoch 12/200\n",
      "167/167 [==============================] - 0s 167us/step - loss: 0.0504 - accuracy: 0.9461 - val_loss: 0.0861 - val_accuracy: 0.9268\n",
      "Epoch 13/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0428 - accuracy: 0.9521 - val_loss: 0.1023 - val_accuracy: 0.8537\n",
      "Epoch 14/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0511 - accuracy: 0.9401 - val_loss: 0.1188 - val_accuracy: 0.8049\n",
      "Epoch 15/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0416 - accuracy: 0.9521 - val_loss: 0.1129 - val_accuracy: 0.8293\n",
      "Epoch 16/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0499 - accuracy: 0.9401 - val_loss: 0.1232 - val_accuracy: 0.8049\n",
      "Epoch 17/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0476 - accuracy: 0.9401 - val_loss: 0.1047 - val_accuracy: 0.8537\n",
      "Epoch 18/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0387 - accuracy: 0.9581 - val_loss: 0.0880 - val_accuracy: 0.8780\n",
      "Epoch 19/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0393 - accuracy: 0.9581 - val_loss: 0.0777 - val_accuracy: 0.9268\n",
      "Epoch 20/200\n",
      "167/167 [==============================] - 0s 155us/step - loss: 0.0392 - accuracy: 0.9581 - val_loss: 0.0735 - val_accuracy: 0.9512\n",
      "Epoch 21/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0444 - accuracy: 0.9581 - val_loss: 0.0755 - val_accuracy: 0.9512\n",
      "Epoch 22/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0345 - accuracy: 0.9701 - val_loss: 0.0794 - val_accuracy: 0.9512\n",
      "Epoch 23/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0389 - accuracy: 0.9581 - val_loss: 0.0867 - val_accuracy: 0.9268\n",
      "Epoch 24/200\n",
      "167/167 [==============================] - 0s 162us/step - loss: 0.0348 - accuracy: 0.9641 - val_loss: 0.0992 - val_accuracy: 0.8537\n",
      "Epoch 25/200\n",
      "167/167 [==============================] - 0s 155us/step - loss: 0.0354 - accuracy: 0.9581 - val_loss: 0.1083 - val_accuracy: 0.8780\n",
      "Epoch 26/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0356 - accuracy: 0.9581 - val_loss: 0.1211 - val_accuracy: 0.8293\n",
      "Epoch 27/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0427 - accuracy: 0.9401 - val_loss: 0.1302 - val_accuracy: 0.8049\n",
      "Epoch 28/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0389 - accuracy: 0.9641 - val_loss: 0.1251 - val_accuracy: 0.8049\n",
      "Epoch 29/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0319 - accuracy: 0.9581 - val_loss: 0.1052 - val_accuracy: 0.9024\n",
      "Epoch 30/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0260 - accuracy: 0.9641 - val_loss: 0.0999 - val_accuracy: 0.8780\n",
      "Epoch 31/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0262 - accuracy: 0.9701 - val_loss: 0.0941 - val_accuracy: 0.9024\n",
      "Epoch 32/200\n",
      "167/167 [==============================] - 0s 150us/step - loss: 0.0237 - accuracy: 0.9880 - val_loss: 0.0960 - val_accuracy: 0.8780\n",
      "Epoch 33/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0223 - accuracy: 0.9820 - val_loss: 0.0928 - val_accuracy: 0.8780\n",
      "Epoch 34/200\n",
      "167/167 [==============================] - 0s 162us/step - loss: 0.0231 - accuracy: 0.9760 - val_loss: 0.0939 - val_accuracy: 0.9024\n",
      "Epoch 35/200\n",
      "167/167 [==============================] - 0s 162us/step - loss: 0.0225 - accuracy: 0.9701 - val_loss: 0.0951 - val_accuracy: 0.9024\n",
      "Epoch 36/200\n",
      "167/167 [==============================] - 0s 155us/step - loss: 0.0184 - accuracy: 0.9880 - val_loss: 0.0951 - val_accuracy: 0.8780\n",
      "Epoch 37/200\n",
      "167/167 [==============================] - 0s 156us/step - loss: 0.0209 - accuracy: 0.9880 - val_loss: 0.1077 - val_accuracy: 0.8293\n",
      "Epoch 38/200\n",
      "167/167 [==============================] - 0s 168us/step - loss: 0.0239 - accuracy: 0.9760 - val_loss: 0.1176 - val_accuracy: 0.8049\n",
      "Epoch 39/200\n",
      "167/167 [==============================] - 0s 174us/step - loss: 0.0244 - accuracy: 0.9760 - val_loss: 0.1233 - val_accuracy: 0.8537\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - 0s 174us/step - loss: 0.0200 - accuracy: 0.9880 - val_loss: 0.1347 - val_accuracy: 0.7805\n",
      "41/41 [==============================] - 0s 293us/step\n",
      "교차검증 Acc :  0.8892877340316773\n"
     ]
    }
   ],
   "source": [
    "# k-fold 교차검증 (k=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed) \n",
    "\n",
    "score = []\n",
    "\n",
    "for train, test in kfold.split(x,y) :\n",
    "    \n",
    "    sonar_model = load_model('sonar_model/sonar_model(0.88).h5')\n",
    "\n",
    "    sonar_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    sonar_model.fit(x.iloc[train,:], y[train], epochs=200, batch_size=80,\n",
    "                    validation_data=[x.iloc[test,:],y[test]], callbacks=[es])\n",
    "\n",
    "    score.append(sonar_model.evaluate(x.iloc[test,:], y[test])[1])\n",
    "\n",
    "print('교차검증 Acc : ',np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
