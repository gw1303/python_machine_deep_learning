[TensorFlow와 Keras 라이브러리를 활용한 딥러닝]
1. 케라스로 신경망 설계시 Seqential 및 Dense 클래스 용법에 대해 설명하시오.
    Seqential이란 keras.model에 있는 클래스로 keras 모델을 선언할 때 사용한다. 라이브러리를 불러오기 위해선 from keras.models import Sequential을 import하고 Sequential 클래스 객체를 생성한다.
    Dense는 keras.layers에 있는 클래스로 뉴럴네트워크 레이블을 만들 때 사용한다. Dense layer는 fully-connected layer로 모든 노드가 연결되어 가중치가 계산된다. 라이브러리를 불러오기 위해선 from keras.layers import Dense로 import하고 Sequential객체에 add메서드로 추가한다.
2. 다음 코드를 설명하시오.
코드 : sess.run(train_step,feed_dict={x:batch_xs,t:batch_ts,keep_prob:0.5})
: tensorflow Session에서 노드를 실행할 때 쓰는 문장으로 'train_step'노드를 실행하고, 실행에 필요한 데이터 값으로 x값에 batch_xs를 y값에 batch_ts를 전달한다. 또, 가중치를 계산할 때 Dropout을 50%만큼 하라는 의미의 코드이다.



[강화학습 기법을 활용한 인공지능 고급구현]
1. 모델 피팅(fitting)에 대해 정의하고, 피팅 종류를 나열하시오.
    모델에서 fitting이란 우리말로 모델 학습이고 loss가 적어지도록 weight를 조정해가는 것을 의미한다. fitting을 할 때에는 학습이 제대로 되지 않은 under fitting과 해당 데이터에 대해서만 과도하게 최적화 학습이 된 over fitting이 있다. over fitting과 under fitting 모두 학습결과를 망치므로 적당히 학습시켜야한다.

2. 정규화 및 표준화에대해 설명하시오.
    정규화는 0~1 사이의 값으로 변환하는 작업으로 모든 값들을 x-최소값 / 최대값-최소값 으로 변환한다.
    표준화는 값들을 평균을 기준으로 얼마나 떨어져 있는지를 나타내기위한 방법으로 x-평균/표준편차 로 변환한다.



[CNN과 GAN을 활용한 이미지데이터 모델링]
1. 다음 코드는 A,B 두 문서가 주어졌을 때, 두 문서간 코사인 유사도를 구하는 함수의 일부이다. 밑줄친 부분에 들어가야 할 코드를 작성하시오.
from numpy import dot
from numpy.linalg import norm
import numpy as np
def cosSim(A,B):
    return np.dot(X,Y)/((norm(X)*norm(Y))+1e-7)

2. CNN알고리즘에서 stride를 계산하는 수식을 기술하시오.
    strinde는 cnn알고리즘에서 filter를 옮겨가는 보폭을 의미한다. 일반적으로 stride는 1을 준다.
  
  stride와 pool이 들어갔을 때 layer의 출력 크기는 ((입력크기 + 2*패딩크기 -필터크기)/스트라이드값) +1) 이다.
  
3. pooling 레이어의 동작에 대해 설명하시오.
     pooling 레이어는 특징값을 추출해 차원을 줄이는 의미이다. maxpooling, meanpooling등의 방법이 있는데 poolsize에서 max값을 추출해 변환하는 Maxpooling이 가장 일반적이다. 예를들어 2x2 pooling 레이어를 통과시시면 2x2 이미지 안에서 가장 큰 픽셀의 값으로 변환해 이미지의 크기를 줄인다.        



[RNN을 활용한 챗봇 시스템 구축]
텍스트 전처리는 토큰화 ->정제 및 정규화 ->어간 추출 -> 불용어 제거 -> 정규표현식 ->인코딩 -> 단어 분리 과정을 거치게 된다. 각 과정에 대한 간단한 설명 및 예시 코드를 작성하시오. (R / Python 중 선택)

1. 토큰화 : 문장이 입력됐을 때 특정 단위로 쪼개는 것을 의미한다. 일반적으로 단어 토큰화를 사용 nltk나 konlp 등의 라이브러리를 이용해 토큰화 함수를 호출해 문장을 토큰화한다.

from nltk.tokenize import WordPunctTokenizer
WordPunctTokenizer().tokenize('I am kiwook')
-> ['I', 'am', 'kiwook']



2. 정제 및 정규화 : 문장을 단어로 토큰화 했을 때 같은 의미의 단어일지라도 인칭이나 위치에 따라 형태가 다르므로 다른 토큰처럼 인식된다. 그래서 이 문제를 해결하기 위해 전처리 과정을 거치는데 대소문자를 통일하거나 필요 없는 단어는 삭제하는 방법을 이용한다. 



3. 어간 추출 : 정규화 기법 중 하나로 의미가 같으나 형태가 다른 단어들을 원형으로 변환해주는 작업을 의미한다.

from nltk.stem import WordNetLemmatizer
n=WordNetLemmatizer()
n.lemmatize('has', 'v')  # have
n.lemmatize('am', 'v')   # be



4. 불용어 제거 : 문장에서 분석에 필요없는 단어들을 제거하는 것을 의미한다. 불용어 사전을 만들어 단어를 제거하던가 이미 만들어진 불용어사전을 불러와 토큰화 된 단어가 불용어 사전에 포함돼 있다면 제거하는 방식으로 사용한다.

from nltk.corpus import stopwords  
stopwords.words('english')



5. 정규표현식 : 텍스트를 처리할 때 많이 사용되는 것으로 특정 패턴의 텍스트를 찾아낼 때 이용한다. 파이썬에서는 주로 re 라이브러리를 이용해 정규표현식을 작성한다.

import re
re.compile, re.match, re.search 등등을 이용한다.



6. 인코딩 : 컴퓨터는 텍스트를 바로바로 이해할 수 없기 때문에 컴퓨터가 이해가능한 숫자로 텍스트를 변환해서 이용해야한다. 인코딩 방법에는 정수인코딩과 원핫인코딩이 있다.
정수인코딩은 토큰화 된 단어에 인덱스를 부여해 단어에 숫자 인덱스를 매핑하는 방법이다. 원핫인코딩은 정수인코딩 된 단어들을 벡터화 하는 것으로 모든 단어들의 집합 길이만큼 0벡터를 만들고 해당 단어의 인덱스 위치에 1값을 주어 벡터화하는 것을 의미힌다.
정수인코딩 : {'I':1, 'am':2, 'kiwook':3}
원핫인코딩 : [[1,0,0] , [0,1,0], [0,0,1]]



7. 단어 분리 : 컴퓨터에 학습시키지 않은 단어가 입력되었을 때 발생하는 OOV문제를 해결하기 위한 방법으로 단어사전에 들어있는 단어들을 최소 단위로 쪼개 새로운 단어 사전을 만드는 것을 의미한다. 쪼개진 단어 사전에서 가장 많은 빈도수를 가진 것 끼리 결합해 단어사전을 추가하고 최종적으로 본래의 단어가 될 때 까지 작업해 단어사전을 구성한다. 그러면 새로운 단어가 들어오더라도 여러 개로 쪼개진 단어 사전에 포함되어 있는 단어가 들어온다면 그 단어를 결합해 인코딩해서 OOV문제가 일어나지 않는다.

l o w : 5,  l o w e r : 2,  n e w e s t : 6,  w i d e s t : 3
->
l, o, w, e, r, n, w, s, t, i, d, es, est, lo, low, ne, new, newest, wi, wid, widest