{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mnist 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터셋 생성\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain.shape  # (60000, 28, 28)\n",
    "\n",
    "xTrain = xTrain.reshape(60000,784).astype('float32')/255.0\n",
    "xTest = xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain.shape  # (60000,)\n",
    "yTrain\n",
    "\n",
    "# one-hot 인코딩\n",
    "yTrain = np_utils.to_categorical(yTrain)\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 구성\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2207 - accuracy: 0.9376\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2056 - accuracy: 0.9421\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1923 - accuracy: 0.9453\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1809 - accuracy: 0.9487\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1708 - accuracy: 0.9518\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습\n",
    "hist = model.fit(xTrain, yTrain, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22072278389732042, 0.20555209121902784, 0.1923094036291043, 0.18086360019048056, 0.1708080348610878]\n",
      "[0.93763334, 0.9421, 0.9453167, 0.9487333, 0.95176667]\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 검정\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17036081341356038, 0.9506000280380249]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 모델 평가\n",
    "\n",
    "res = model.evaluate(xTest, yTest, batch_size=32)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.2015282e-04 4.9709882e-07 9.7006012e-04 3.0119361e-03 6.0482586e-07\n",
      "  1.7250094e-04 1.5895347e-08 9.9510044e-01 2.6840064e-05 2.9702345e-04]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 예측\n",
    "xhat = xTest[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal = xTrain[50000:]\n",
    "yVal = yTrain[50000:]\n",
    "\n",
    "xTrain = xTrain[:50000]\n",
    "yTrain = yTrain[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(50000,784).astype('float32')/255.0\n",
    "xVal = xVal.reshape(10000,784).astype('float32')/255.0\n",
    "xTest = xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 검증 데이터 선택\n",
    "tri = np.random.choice(50000,700)\n",
    "vri = np.random.choice(10000,300)\n",
    "\n",
    "# 훈련셋과 검증셋 분할\n",
    "xTrain = xTrain[tri]  # 700\n",
    "yTrain = yTrain[tri] \n",
    "\n",
    "xVal = xVal[vri]  # 300\n",
    "yVal = yVal[vri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터 원핫인코딩\n",
    "yTrain = np_utils.to_categorical(yTrain)\n",
    "yVal = np_utils.to_categorical(yVal)\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(input_dim=28*28, units=2, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_crossentropy은 softmax 함수의 값과 실제값의 차이를 구해 loss를 구하는 함수\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 2.2187 - accuracy: 0.2286 - val_loss: 2.1772 - val_accuracy: 0.2333\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 2.1231 - accuracy: 0.2557 - val_loss: 2.0782 - val_accuracy: 0.2400\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 2.0429 - accuracy: 0.2700 - val_loss: 2.0148 - val_accuracy: 0.2567\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.9832 - accuracy: 0.2643 - val_loss: 1.9672 - val_accuracy: 0.2667\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.9349 - accuracy: 0.3214 - val_loss: 1.9310 - val_accuracy: 0.2800\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.8909 - accuracy: 0.3400 - val_loss: 1.8998 - val_accuracy: 0.2967\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.8564 - accuracy: 0.3443 - val_loss: 1.8749 - val_accuracy: 0.2933\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.8239 - accuracy: 0.3543 - val_loss: 1.8498 - val_accuracy: 0.2867\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7927 - accuracy: 0.3614 - val_loss: 1.8294 - val_accuracy: 0.2967\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7642 - accuracy: 0.3686 - val_loss: 1.8087 - val_accuracy: 0.2900\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.7386 - accuracy: 0.3700 - val_loss: 1.7891 - val_accuracy: 0.3033\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7149 - accuracy: 0.3757 - val_loss: 1.7741 - val_accuracy: 0.2933\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 224us/step - loss: 1.6939 - accuracy: 0.3843 - val_loss: 1.7589 - val_accuracy: 0.3100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.6728 - accuracy: 0.3886 - val_loss: 1.7410 - val_accuracy: 0.3133\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6532 - accuracy: 0.3943 - val_loss: 1.7282 - val_accuracy: 0.3167\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6326 - accuracy: 0.4071 - val_loss: 1.7149 - val_accuracy: 0.3167\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6155 - accuracy: 0.4100 - val_loss: 1.7039 - val_accuracy: 0.3100\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5980 - accuracy: 0.4043 - val_loss: 1.6906 - val_accuracy: 0.3200\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5817 - accuracy: 0.4143 - val_loss: 1.6762 - val_accuracy: 0.3333\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5646 - accuracy: 0.4186 - val_loss: 1.6655 - val_accuracy: 0.3367\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5506 - accuracy: 0.4257 - val_loss: 1.6526 - val_accuracy: 0.3433\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5372 - accuracy: 0.4286 - val_loss: 1.6433 - val_accuracy: 0.3400\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5228 - accuracy: 0.4300 - val_loss: 1.6297 - val_accuracy: 0.3400\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5110 - accuracy: 0.4357 - val_loss: 1.6227 - val_accuracy: 0.3467\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4970 - accuracy: 0.4343 - val_loss: 1.6128 - val_accuracy: 0.3567\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4837 - accuracy: 0.4429 - val_loss: 1.6019 - val_accuracy: 0.3333\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4714 - accuracy: 0.4329 - val_loss: 1.6064 - val_accuracy: 0.3633\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4606 - accuracy: 0.4429 - val_loss: 1.5902 - val_accuracy: 0.3733\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4491 - accuracy: 0.4586 - val_loss: 1.5785 - val_accuracy: 0.3667\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4378 - accuracy: 0.4529 - val_loss: 1.5683 - val_accuracy: 0.3733\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4267 - accuracy: 0.4700 - val_loss: 1.5645 - val_accuracy: 0.3667\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4166 - accuracy: 0.4757 - val_loss: 1.5477 - val_accuracy: 0.3667\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4063 - accuracy: 0.4686 - val_loss: 1.5573 - val_accuracy: 0.3733\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3973 - accuracy: 0.4700 - val_loss: 1.5412 - val_accuracy: 0.3867\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3867 - accuracy: 0.4900 - val_loss: 1.5287 - val_accuracy: 0.3867\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3784 - accuracy: 0.4829 - val_loss: 1.5176 - val_accuracy: 0.3900\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3687 - accuracy: 0.4843 - val_loss: 1.5200 - val_accuracy: 0.4033\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3599 - accuracy: 0.5086 - val_loss: 1.5056 - val_accuracy: 0.4067\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3488 - accuracy: 0.5043 - val_loss: 1.5104 - val_accuracy: 0.4033\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3402 - accuracy: 0.5086 - val_loss: 1.4912 - val_accuracy: 0.4300\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3290 - accuracy: 0.5257 - val_loss: 1.4825 - val_accuracy: 0.4233\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3199 - accuracy: 0.5214 - val_loss: 1.4780 - val_accuracy: 0.4333\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3122 - accuracy: 0.5229 - val_loss: 1.4689 - val_accuracy: 0.4333\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3046 - accuracy: 0.5257 - val_loss: 1.4616 - val_accuracy: 0.4467\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2955 - accuracy: 0.5371 - val_loss: 1.4525 - val_accuracy: 0.4333\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2858 - accuracy: 0.5243 - val_loss: 1.4475 - val_accuracy: 0.4400\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2767 - accuracy: 0.5357 - val_loss: 1.4429 - val_accuracy: 0.4467\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2680 - accuracy: 0.5457 - val_loss: 1.4371 - val_accuracy: 0.4567\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2587 - accuracy: 0.5471 - val_loss: 1.4387 - val_accuracy: 0.4467\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2530 - accuracy: 0.5486 - val_loss: 1.4201 - val_accuracy: 0.4667\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2445 - accuracy: 0.5514 - val_loss: 1.4161 - val_accuracy: 0.4567\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2372 - accuracy: 0.5514 - val_loss: 1.4078 - val_accuracy: 0.4500\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2285 - accuracy: 0.5543 - val_loss: 1.4062 - val_accuracy: 0.4567\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2211 - accuracy: 0.5686 - val_loss: 1.4006 - val_accuracy: 0.4500\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.2146 - accuracy: 0.5600 - val_loss: 1.3906 - val_accuracy: 0.4567\n",
      "Epoch 56/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 1.2074 - accuracy: 0.5629 - val_loss: 1.3889 - val_accuracy: 0.4567\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1986 - accuracy: 0.5800 - val_loss: 1.3903 - val_accuracy: 0.4533\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1935 - accuracy: 0.5614 - val_loss: 1.3749 - val_accuracy: 0.4667\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1881 - accuracy: 0.5814 - val_loss: 1.3730 - val_accuracy: 0.4633\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.1809 - accuracy: 0.5757 - val_loss: 1.3707 - val_accuracy: 0.4600\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1726 - accuracy: 0.5800 - val_loss: 1.3595 - val_accuracy: 0.4800\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1680 - accuracy: 0.5914 - val_loss: 1.3590 - val_accuracy: 0.4767\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1633 - accuracy: 0.5900 - val_loss: 1.3615 - val_accuracy: 0.4567\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.1565 - accuracy: 0.5843 - val_loss: 1.3518 - val_accuracy: 0.4733\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1504 - accuracy: 0.5943 - val_loss: 1.3561 - val_accuracy: 0.4700\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1445 - accuracy: 0.5929 - val_loss: 1.3541 - val_accuracy: 0.4667\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.1410 - accuracy: 0.5914 - val_loss: 1.3418 - val_accuracy: 0.4733\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.1343 - accuracy: 0.5957 - val_loss: 1.3393 - val_accuracy: 0.4867\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.1290 - accuracy: 0.6100 - val_loss: 1.3350 - val_accuracy: 0.4833\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.1255 - accuracy: 0.6057 - val_loss: 1.3404 - val_accuracy: 0.4700\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1181 - accuracy: 0.6086 - val_loss: 1.3338 - val_accuracy: 0.4833\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1123 - accuracy: 0.6086 - val_loss: 1.3283 - val_accuracy: 0.4733\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.1085 - accuracy: 0.6157 - val_loss: 1.3288 - val_accuracy: 0.4733\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.1061 - accuracy: 0.6071 - val_loss: 1.3222 - val_accuracy: 0.4867\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1007 - accuracy: 0.6129 - val_loss: 1.3259 - val_accuracy: 0.4767\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0947 - accuracy: 0.6086 - val_loss: 1.3185 - val_accuracy: 0.4967\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.0875 - accuracy: 0.6143 - val_loss: 1.3389 - val_accuracy: 0.4667\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0873 - accuracy: 0.6186 - val_loss: 1.3162 - val_accuracy: 0.4867\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0825 - accuracy: 0.6143 - val_loss: 1.3168 - val_accuracy: 0.4967\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0774 - accuracy: 0.6357 - val_loss: 1.3201 - val_accuracy: 0.4833\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.0745 - accuracy: 0.6143 - val_loss: 1.3139 - val_accuracy: 0.4900\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0696 - accuracy: 0.6157 - val_loss: 1.3057 - val_accuracy: 0.5067\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.0635 - accuracy: 0.6243 - val_loss: 1.3240 - val_accuracy: 0.4867\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.0600 - accuracy: 0.6243 - val_loss: 1.3049 - val_accuracy: 0.5033\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0575 - accuracy: 0.6371 - val_loss: 1.3057 - val_accuracy: 0.5000\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.0516 - accuracy: 0.6457 - val_loss: 1.3034 - val_accuracy: 0.5000\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0492 - accuracy: 0.6371 - val_loss: 1.3072 - val_accuracy: 0.4967\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0442 - accuracy: 0.6214 - val_loss: 1.3139 - val_accuracy: 0.4900\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.0390 - accuracy: 0.6300 - val_loss: 1.2953 - val_accuracy: 0.5033\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0390 - accuracy: 0.6343 - val_loss: 1.2970 - val_accuracy: 0.5067\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.0333 - accuracy: 0.6314 - val_loss: 1.2949 - val_accuracy: 0.5033\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.0303 - accuracy: 0.6471 - val_loss: 1.3035 - val_accuracy: 0.5133\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0260 - accuracy: 0.6400 - val_loss: 1.2964 - val_accuracy: 0.5033\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0238 - accuracy: 0.6329 - val_loss: 1.2953 - val_accuracy: 0.5033\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.0167 - accuracy: 0.6500 - val_loss: 1.3049 - val_accuracy: 0.5000\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.0133 - accuracy: 0.6443 - val_loss: 1.3028 - val_accuracy: 0.5133\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0120 - accuracy: 0.6429 - val_loss: 1.2894 - val_accuracy: 0.5033\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.0074 - accuracy: 0.6500 - val_loss: 1.2873 - val_accuracy: 0.4967\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0025 - accuracy: 0.6529 - val_loss: 1.2927 - val_accuracy: 0.5133\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0014 - accuracy: 0.6500 - val_loss: 1.2915 - val_accuracy: 0.5000\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9992 - accuracy: 0.6543 - val_loss: 1.2979 - val_accuracy: 0.5167\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9943 - accuracy: 0.6586 - val_loss: 1.2924 - val_accuracy: 0.5100\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9894 - accuracy: 0.6600 - val_loss: 1.2882 - val_accuracy: 0.5133\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.9878 - accuracy: 0.6529 - val_loss: 1.2879 - val_accuracy: 0.5067\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9863 - accuracy: 0.6671 - val_loss: 1.2954 - val_accuracy: 0.5100\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9812 - accuracy: 0.6614 - val_loss: 1.3000 - val_accuracy: 0.5200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9780 - accuracy: 0.6571 - val_loss: 1.2870 - val_accuracy: 0.4967\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9751 - accuracy: 0.6686 - val_loss: 1.2842 - val_accuracy: 0.5000\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9723 - accuracy: 0.6800 - val_loss: 1.2912 - val_accuracy: 0.5000\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9700 - accuracy: 0.6614 - val_loss: 1.2913 - val_accuracy: 0.5067\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9657 - accuracy: 0.6657 - val_loss: 1.2887 - val_accuracy: 0.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9603 - accuracy: 0.6657 - val_loss: 1.2991 - val_accuracy: 0.5167\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.9600 - accuracy: 0.6729 - val_loss: 1.2898 - val_accuracy: 0.5100\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9582 - accuracy: 0.6786 - val_loss: 1.2904 - val_accuracy: 0.4967\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9529 - accuracy: 0.6771 - val_loss: 1.2824 - val_accuracy: 0.5067\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9507 - accuracy: 0.6686 - val_loss: 1.2808 - val_accuracy: 0.4967\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9474 - accuracy: 0.6757 - val_loss: 1.2790 - val_accuracy: 0.5033\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9469 - accuracy: 0.6857 - val_loss: 1.2860 - val_accuracy: 0.5067\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9411 - accuracy: 0.6714 - val_loss: 1.2904 - val_accuracy: 0.5133\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9395 - accuracy: 0.6700 - val_loss: 1.2833 - val_accuracy: 0.5033\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.9384 - accuracy: 0.6814 - val_loss: 1.2821 - val_accuracy: 0.5000\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9338 - accuracy: 0.6886 - val_loss: 1.2919 - val_accuracy: 0.5133\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9334 - accuracy: 0.6829 - val_loss: 1.2843 - val_accuracy: 0.5067\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.9286 - accuracy: 0.6871 - val_loss: 1.2773 - val_accuracy: 0.5033\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9266 - accuracy: 0.6829 - val_loss: 1.2817 - val_accuracy: 0.5067\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.9252 - accuracy: 0.6914 - val_loss: 1.2783 - val_accuracy: 0.4933\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9234 - accuracy: 0.6900 - val_loss: 1.2800 - val_accuracy: 0.4933\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9197 - accuracy: 0.6929 - val_loss: 1.2782 - val_accuracy: 0.5067\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9170 - accuracy: 0.6843 - val_loss: 1.2852 - val_accuracy: 0.5167\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9155 - accuracy: 0.6914 - val_loss: 1.2849 - val_accuracy: 0.5200\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.9110 - accuracy: 0.6957 - val_loss: 1.2883 - val_accuracy: 0.5100\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9080 - accuracy: 0.6957 - val_loss: 1.2811 - val_accuracy: 0.5067\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9079 - accuracy: 0.6843 - val_loss: 1.2899 - val_accuracy: 0.5200\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9034 - accuracy: 0.7000 - val_loss: 1.2830 - val_accuracy: 0.5067\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9023 - accuracy: 0.6857 - val_loss: 1.2799 - val_accuracy: 0.5067\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8996 - accuracy: 0.6900 - val_loss: 1.2880 - val_accuracy: 0.5200\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.8955 - accuracy: 0.7029 - val_loss: 1.2886 - val_accuracy: 0.5200\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8937 - accuracy: 0.6943 - val_loss: 1.2879 - val_accuracy: 0.5133\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8902 - accuracy: 0.7100 - val_loss: 1.2847 - val_accuracy: 0.5067\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.8883 - accuracy: 0.7014 - val_loss: 1.2859 - val_accuracy: 0.5233\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8877 - accuracy: 0.7000 - val_loss: 1.2833 - val_accuracy: 0.5100\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8844 - accuracy: 0.6914 - val_loss: 1.2902 - val_accuracy: 0.5267\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8837 - accuracy: 0.6943 - val_loss: 1.2899 - val_accuracy: 0.5200\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8807 - accuracy: 0.6929 - val_loss: 1.2897 - val_accuracy: 0.5167\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8803 - accuracy: 0.7114 - val_loss: 1.2881 - val_accuracy: 0.5067\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.8775 - accuracy: 0.69 - 0s 110us/step - loss: 0.8763 - accuracy: 0.6957 - val_loss: 1.2878 - val_accuracy: 0.5033\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8752 - accuracy: 0.6971 - val_loss: 1.2920 - val_accuracy: 0.5067\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8675 - accuracy: 0.7114 - val_loss: 1.2962 - val_accuracy: 0.5100\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8687 - accuracy: 0.7014 - val_loss: 1.2929 - val_accuracy: 0.5133\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8687 - accuracy: 0.7043 - val_loss: 1.2878 - val_accuracy: 0.4967\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.8658 - accuracy: 0.7100 - val_loss: 1.2883 - val_accuracy: 0.5233\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8636 - accuracy: 0.7086 - val_loss: 1.2838 - val_accuracy: 0.4967\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8610 - accuracy: 0.6986 - val_loss: 1.2891 - val_accuracy: 0.5300\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8583 - accuracy: 0.6986 - val_loss: 1.2858 - val_accuracy: 0.5133\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8575 - accuracy: 0.7057 - val_loss: 1.2911 - val_accuracy: 0.5100\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8529 - accuracy: 0.7000 - val_loss: 1.3056 - val_accuracy: 0.5300\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8514 - accuracy: 0.7186 - val_loss: 1.2897 - val_accuracy: 0.5000\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8492 - accuracy: 0.7000 - val_loss: 1.2992 - val_accuracy: 0.5300\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8443 - accuracy: 0.7086 - val_loss: 1.3172 - val_accuracy: 0.5233\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8463 - accuracy: 0.7086 - val_loss: 1.2987 - val_accuracy: 0.5367\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8433 - accuracy: 0.6986 - val_loss: 1.2911 - val_accuracy: 0.4933\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8425 - accuracy: 0.7100 - val_loss: 1.2896 - val_accuracy: 0.5133\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8380 - accuracy: 0.7100 - val_loss: 1.2943 - val_accuracy: 0.5133\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8378 - accuracy: 0.7143 - val_loss: 1.3012 - val_accuracy: 0.5333\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.8369 - accuracy: 0.7057 - val_loss: 1.2997 - val_accuracy: 0.5200\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.8339 - accuracy: 0.7086 - val_loss: 1.2934 - val_accuracy: 0.5100\n",
      "Epoch 167/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.8315 - accuracy: 0.7129 - val_loss: 1.3008 - val_accuracy: 0.5300\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8289 - accuracy: 0.7171 - val_loss: 1.2978 - val_accuracy: 0.5067\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8270 - accuracy: 0.7114 - val_loss: 1.2963 - val_accuracy: 0.5167\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.8266 - accuracy: 0.7129 - val_loss: 1.2978 - val_accuracy: 0.5233\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.8248 - accuracy: 0.7086 - val_loss: 1.2975 - val_accuracy: 0.5200\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.8209 - accuracy: 0.7086 - val_loss: 1.2998 - val_accuracy: 0.5333\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8190 - accuracy: 0.7229 - val_loss: 1.3050 - val_accuracy: 0.5167\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8182 - accuracy: 0.7143 - val_loss: 1.2974 - val_accuracy: 0.5300\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8161 - accuracy: 0.7200 - val_loss: 1.3015 - val_accuracy: 0.5367\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.8168 - accuracy: 0.7200 - val_loss: 1.2998 - val_accuracy: 0.5100\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.8137 - accuracy: 0.7186 - val_loss: 1.2999 - val_accuracy: 0.5233\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.8119 - accuracy: 0.7114 - val_loss: 1.3046 - val_accuracy: 0.5333\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8105 - accuracy: 0.7129 - val_loss: 1.3085 - val_accuracy: 0.5300\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8075 - accuracy: 0.7186 - val_loss: 1.3041 - val_accuracy: 0.5167\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8051 - accuracy: 0.7143 - val_loss: 1.3125 - val_accuracy: 0.5167\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8038 - accuracy: 0.7200 - val_loss: 1.3226 - val_accuracy: 0.5233\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8032 - accuracy: 0.7257 - val_loss: 1.3082 - val_accuracy: 0.5267\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8035 - accuracy: 0.7157 - val_loss: 1.3101 - val_accuracy: 0.5367\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7991 - accuracy: 0.7186 - val_loss: 1.3113 - val_accuracy: 0.5200\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7994 - accuracy: 0.7186 - val_loss: 1.3096 - val_accuracy: 0.5233\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7972 - accuracy: 0.7243 - val_loss: 1.3153 - val_accuracy: 0.5267\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7939 - accuracy: 0.7329 - val_loss: 1.3101 - val_accuracy: 0.5367\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7918 - accuracy: 0.7200 - val_loss: 1.3135 - val_accuracy: 0.5233\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7927 - accuracy: 0.7271 - val_loss: 1.3142 - val_accuracy: 0.5167\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7903 - accuracy: 0.7229 - val_loss: 1.3154 - val_accuracy: 0.5267\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7889 - accuracy: 0.7300 - val_loss: 1.3202 - val_accuracy: 0.5333\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7871 - accuracy: 0.7243 - val_loss: 1.3191 - val_accuracy: 0.5267\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7847 - accuracy: 0.7214 - val_loss: 1.3156 - val_accuracy: 0.5467\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7818 - accuracy: 0.7243 - val_loss: 1.3144 - val_accuracy: 0.5200\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7839 - accuracy: 0.7371 - val_loss: 1.3182 - val_accuracy: 0.5233\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7834 - accuracy: 0.7329 - val_loss: 1.3186 - val_accuracy: 0.5367\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.7910 - accuracy: 0.72 - 0s 109us/step - loss: 0.7803 - accuracy: 0.7314 - val_loss: 1.3220 - val_accuracy: 0.5333\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7771 - accuracy: 0.7257 - val_loss: 1.3238 - val_accuracy: 0.5167\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7764 - accuracy: 0.7386 - val_loss: 1.3211 - val_accuracy: 0.5367\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7768 - accuracy: 0.7343 - val_loss: 1.3201 - val_accuracy: 0.5167\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7744 - accuracy: 0.7343 - val_loss: 1.3211 - val_accuracy: 0.5233\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7701 - accuracy: 0.7386 - val_loss: 1.3238 - val_accuracy: 0.5400\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7708 - accuracy: 0.7371 - val_loss: 1.3245 - val_accuracy: 0.5433\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7690 - accuracy: 0.7271 - val_loss: 1.3403 - val_accuracy: 0.5267\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7695 - accuracy: 0.7329 - val_loss: 1.3323 - val_accuracy: 0.5167\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7662 - accuracy: 0.7386 - val_loss: 1.3283 - val_accuracy: 0.5233\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7662 - accuracy: 0.7314 - val_loss: 1.3361 - val_accuracy: 0.5367\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7613 - accuracy: 0.7371 - val_loss: 1.3375 - val_accuracy: 0.5367\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7657 - accuracy: 0.7271 - val_loss: 1.3346 - val_accuracy: 0.5333\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7623 - accuracy: 0.7314 - val_loss: 1.3434 - val_accuracy: 0.5267\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7597 - accuracy: 0.7414 - val_loss: 1.3359 - val_accuracy: 0.5267\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.7577 - accuracy: 0.7343 - val_loss: 1.3506 - val_accuracy: 0.5133\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7582 - accuracy: 0.7314 - val_loss: 1.3418 - val_accuracy: 0.5300\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7564 - accuracy: 0.7314 - val_loss: 1.3364 - val_accuracy: 0.5233\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7538 - accuracy: 0.7357 - val_loss: 1.3512 - val_accuracy: 0.5233\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7535 - accuracy: 0.7386 - val_loss: 1.3422 - val_accuracy: 0.5300\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.7512 - accuracy: 0.7443 - val_loss: 1.3447 - val_accuracy: 0.5300\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7513 - accuracy: 0.7414 - val_loss: 1.3402 - val_accuracy: 0.5367\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7505 - accuracy: 0.7343 - val_loss: 1.3421 - val_accuracy: 0.5267\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7484 - accuracy: 0.7400 - val_loss: 1.3444 - val_accuracy: 0.5233\n",
      "Epoch 222/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 99us/step - loss: 0.7458 - accuracy: 0.7386 - val_loss: 1.3584 - val_accuracy: 0.5267\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7471 - accuracy: 0.7429 - val_loss: 1.3489 - val_accuracy: 0.5267\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7433 - accuracy: 0.7429 - val_loss: 1.3491 - val_accuracy: 0.5200\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7431 - accuracy: 0.7429 - val_loss: 1.3582 - val_accuracy: 0.5300\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7430 - accuracy: 0.7400 - val_loss: 1.3536 - val_accuracy: 0.5067\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7417 - accuracy: 0.7414 - val_loss: 1.3599 - val_accuracy: 0.5267\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7408 - accuracy: 0.7414 - val_loss: 1.3543 - val_accuracy: 0.5067\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7388 - accuracy: 0.7414 - val_loss: 1.3523 - val_accuracy: 0.5200\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7385 - accuracy: 0.7457 - val_loss: 1.3543 - val_accuracy: 0.5367\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7370 - accuracy: 0.7514 - val_loss: 1.3575 - val_accuracy: 0.5300\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7342 - accuracy: 0.7486 - val_loss: 1.3639 - val_accuracy: 0.5333\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7337 - accuracy: 0.7529 - val_loss: 1.3607 - val_accuracy: 0.5167\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7336 - accuracy: 0.7543 - val_loss: 1.3575 - val_accuracy: 0.5300\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7324 - accuracy: 0.7529 - val_loss: 1.3616 - val_accuracy: 0.5367\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7298 - accuracy: 0.7457 - val_loss: 1.3784 - val_accuracy: 0.5233\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7288 - accuracy: 0.7443 - val_loss: 1.3673 - val_accuracy: 0.5267\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7278 - accuracy: 0.7486 - val_loss: 1.3640 - val_accuracy: 0.5233\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7273 - accuracy: 0.7357 - val_loss: 1.3650 - val_accuracy: 0.5300\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.7266 - accuracy: 0.7400 - val_loss: 1.3650 - val_accuracy: 0.5300\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.7250 - accuracy: 0.7500 - val_loss: 1.3714 - val_accuracy: 0.5267\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7212 - accuracy: 0.7529 - val_loss: 1.3717 - val_accuracy: 0.5200\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7211 - accuracy: 0.7471 - val_loss: 1.3732 - val_accuracy: 0.5333\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7218 - accuracy: 0.7486 - val_loss: 1.3696 - val_accuracy: 0.5200\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7194 - accuracy: 0.7400 - val_loss: 1.3786 - val_accuracy: 0.5267\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7181 - accuracy: 0.7529 - val_loss: 1.3794 - val_accuracy: 0.5167\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7203 - accuracy: 0.7557 - val_loss: 1.3820 - val_accuracy: 0.5233\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7173 - accuracy: 0.7457 - val_loss: 1.3788 - val_accuracy: 0.5300\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7157 - accuracy: 0.7514 - val_loss: 1.3829 - val_accuracy: 0.5233\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7153 - accuracy: 0.7471 - val_loss: 1.3779 - val_accuracy: 0.5167\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7116 - accuracy: 0.7600 - val_loss: 1.3805 - val_accuracy: 0.5267\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7139 - accuracy: 0.7500 - val_loss: 1.3797 - val_accuracy: 0.5300\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7103 - accuracy: 0.7543 - val_loss: 1.3858 - val_accuracy: 0.5100\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7104 - accuracy: 0.7400 - val_loss: 1.3804 - val_accuracy: 0.5200\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7092 - accuracy: 0.7657 - val_loss: 1.3903 - val_accuracy: 0.5233\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7085 - accuracy: 0.7457 - val_loss: 1.3856 - val_accuracy: 0.5167\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.7073 - accuracy: 0.7571 - val_loss: 1.3961 - val_accuracy: 0.5267\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.7070 - accuracy: 0.7600 - val_loss: 1.3906 - val_accuracy: 0.5167\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7048 - accuracy: 0.7600 - val_loss: 1.3933 - val_accuracy: 0.5267\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.7043 - accuracy: 0.7586 - val_loss: 1.3962 - val_accuracy: 0.5267\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7014 - accuracy: 0.7500 - val_loss: 1.3947 - val_accuracy: 0.5100\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.7015 - accuracy: 0.7557 - val_loss: 1.3993 - val_accuracy: 0.5200\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6995 - accuracy: 0.7643 - val_loss: 1.3958 - val_accuracy: 0.5267\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7004 - accuracy: 0.7571 - val_loss: 1.3968 - val_accuracy: 0.5200\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6979 - accuracy: 0.7529 - val_loss: 1.3967 - val_accuracy: 0.5067\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6973 - accuracy: 0.7600 - val_loss: 1.4004 - val_accuracy: 0.5200\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6972 - accuracy: 0.7657 - val_loss: 1.4049 - val_accuracy: 0.5200\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6966 - accuracy: 0.7657 - val_loss: 1.4061 - val_accuracy: 0.5200\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6946 - accuracy: 0.7614 - val_loss: 1.4059 - val_accuracy: 0.5233\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6921 - accuracy: 0.7657 - val_loss: 1.4048 - val_accuracy: 0.5033\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6931 - accuracy: 0.7600 - val_loss: 1.4093 - val_accuracy: 0.5100\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6919 - accuracy: 0.7686 - val_loss: 1.4144 - val_accuracy: 0.5200\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.6896 - accuracy: 0.7743 - val_loss: 1.4037 - val_accuracy: 0.5267\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6878 - accuracy: 0.7600 - val_loss: 1.4074 - val_accuracy: 0.5233\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6891 - accuracy: 0.7500 - val_loss: 1.4093 - val_accuracy: 0.5233\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6872 - accuracy: 0.7629 - val_loss: 1.4195 - val_accuracy: 0.5167\n",
      "Epoch 277/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.6848 - accuracy: 0.7714 - val_loss: 1.4128 - val_accuracy: 0.5200\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6835 - accuracy: 0.7671 - val_loss: 1.4146 - val_accuracy: 0.5133\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6839 - accuracy: 0.7614 - val_loss: 1.4176 - val_accuracy: 0.5233\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6817 - accuracy: 0.7686 - val_loss: 1.4129 - val_accuracy: 0.5200\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6821 - accuracy: 0.7686 - val_loss: 1.4216 - val_accuracy: 0.5200\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6792 - accuracy: 0.7657 - val_loss: 1.4150 - val_accuracy: 0.5000\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6816 - accuracy: 0.7600 - val_loss: 1.4243 - val_accuracy: 0.5167\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6792 - accuracy: 0.7743 - val_loss: 1.4260 - val_accuracy: 0.5267\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6773 - accuracy: 0.7614 - val_loss: 1.4295 - val_accuracy: 0.5200\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6788 - accuracy: 0.7557 - val_loss: 1.4271 - val_accuracy: 0.5233\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6745 - accuracy: 0.7700 - val_loss: 1.4349 - val_accuracy: 0.5333\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6758 - accuracy: 0.7671 - val_loss: 1.4393 - val_accuracy: 0.5300\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6742 - accuracy: 0.7814 - val_loss: 1.4387 - val_accuracy: 0.5167\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6689 - accuracy: 0.7600 - val_loss: 1.4354 - val_accuracy: 0.5267\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6728 - accuracy: 0.7671 - val_loss: 1.4409 - val_accuracy: 0.5267\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6705 - accuracy: 0.7643 - val_loss: 1.4390 - val_accuracy: 0.5200\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6686 - accuracy: 0.7657 - val_loss: 1.4379 - val_accuracy: 0.5233\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6678 - accuracy: 0.7671 - val_loss: 1.4392 - val_accuracy: 0.5267\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6649 - accuracy: 0.7771 - val_loss: 1.4427 - val_accuracy: 0.5067\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6649 - accuracy: 0.7729 - val_loss: 1.4407 - val_accuracy: 0.5100\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.76 - 0s 104us/step - loss: 0.6661 - accuracy: 0.7614 - val_loss: 1.4481 - val_accuracy: 0.5233\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6643 - accuracy: 0.7743 - val_loss: 1.4535 - val_accuracy: 0.5333\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.6646 - accuracy: 0.7629 - val_loss: 1.4495 - val_accuracy: 0.5233\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6641 - accuracy: 0.7643 - val_loss: 1.4459 - val_accuracy: 0.5133\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6615 - accuracy: 0.7629 - val_loss: 1.4457 - val_accuracy: 0.5367\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.6605 - accuracy: 0.7686 - val_loss: 1.4554 - val_accuracy: 0.5167\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6607 - accuracy: 0.7786 - val_loss: 1.4562 - val_accuracy: 0.5100\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6604 - accuracy: 0.7743 - val_loss: 1.4605 - val_accuracy: 0.5267\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6589 - accuracy: 0.7686 - val_loss: 1.4554 - val_accuracy: 0.5333\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6573 - accuracy: 0.7771 - val_loss: 1.4605 - val_accuracy: 0.5300\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.6553 - accuracy: 0.7743 - val_loss: 1.4699 - val_accuracy: 0.5133\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6567 - accuracy: 0.7743 - val_loss: 1.4569 - val_accuracy: 0.5233\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6552 - accuracy: 0.7657 - val_loss: 1.4632 - val_accuracy: 0.5200\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6503 - accuracy: 0.7786 - val_loss: 1.4726 - val_accuracy: 0.5267\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6542 - accuracy: 0.7686 - val_loss: 1.4627 - val_accuracy: 0.5300\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6520 - accuracy: 0.7843 - val_loss: 1.4638 - val_accuracy: 0.5300\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6507 - accuracy: 0.7743 - val_loss: 1.4705 - val_accuracy: 0.5333\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6516 - accuracy: 0.7743 - val_loss: 1.4718 - val_accuracy: 0.5300\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6491 - accuracy: 0.7757 - val_loss: 1.4664 - val_accuracy: 0.5300\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6479 - accuracy: 0.7857 - val_loss: 1.4741 - val_accuracy: 0.5267\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6466 - accuracy: 0.7814 - val_loss: 1.4744 - val_accuracy: 0.5200\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6476 - accuracy: 0.7786 - val_loss: 1.4750 - val_accuracy: 0.5233\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6450 - accuracy: 0.7843 - val_loss: 1.4793 - val_accuracy: 0.5200\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6451 - accuracy: 0.7757 - val_loss: 1.4654 - val_accuracy: 0.5267\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6435 - accuracy: 0.7843 - val_loss: 1.4777 - val_accuracy: 0.5300\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6439 - accuracy: 0.7886 - val_loss: 1.4739 - val_accuracy: 0.5233\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6418 - accuracy: 0.7814 - val_loss: 1.4748 - val_accuracy: 0.5200\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6392 - accuracy: 0.7714 - val_loss: 1.4799 - val_accuracy: 0.5133\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6398 - accuracy: 0.7871 - val_loss: 1.4822 - val_accuracy: 0.5300\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6400 - accuracy: 0.7771 - val_loss: 1.4858 - val_accuracy: 0.5300\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6389 - accuracy: 0.7843 - val_loss: 1.4881 - val_accuracy: 0.5267\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6366 - accuracy: 0.7871 - val_loss: 1.4848 - val_accuracy: 0.5267\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.6370 - accuracy: 0.7857 - val_loss: 1.4893 - val_accuracy: 0.5200\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6369 - accuracy: 0.7743 - val_loss: 1.4961 - val_accuracy: 0.5267\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6345 - accuracy: 0.7900 - val_loss: 1.4871 - val_accuracy: 0.5233\n",
      "Epoch 332/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 0.6352 - accuracy: 0.7800 - val_loss: 1.4891 - val_accuracy: 0.5233\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6340 - accuracy: 0.7843 - val_loss: 1.4905 - val_accuracy: 0.5300\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6338 - accuracy: 0.7800 - val_loss: 1.5008 - val_accuracy: 0.5233\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6317 - accuracy: 0.7943 - val_loss: 1.4944 - val_accuracy: 0.5100\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6334 - accuracy: 0.7857 - val_loss: 1.5037 - val_accuracy: 0.5333\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6301 - accuracy: 0.7886 - val_loss: 1.5058 - val_accuracy: 0.5300\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6303 - accuracy: 0.7800 - val_loss: 1.5098 - val_accuracy: 0.5267\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.6303 - accuracy: 0.7914 - val_loss: 1.5010 - val_accuracy: 0.5200\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6262 - accuracy: 0.7886 - val_loss: 1.4982 - val_accuracy: 0.5333\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6275 - accuracy: 0.7871 - val_loss: 1.5037 - val_accuracy: 0.5300\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6259 - accuracy: 0.7843 - val_loss: 1.5083 - val_accuracy: 0.5267\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6263 - accuracy: 0.7914 - val_loss: 1.5119 - val_accuracy: 0.5300\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6243 - accuracy: 0.7786 - val_loss: 1.5174 - val_accuracy: 0.5167\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6252 - accuracy: 0.7886 - val_loss: 1.5079 - val_accuracy: 0.5200\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6224 - accuracy: 0.7871 - val_loss: 1.5124 - val_accuracy: 0.5267\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6233 - accuracy: 0.7971 - val_loss: 1.5235 - val_accuracy: 0.5300\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6218 - accuracy: 0.7943 - val_loss: 1.5055 - val_accuracy: 0.5267\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6207 - accuracy: 0.7886 - val_loss: 1.5168 - val_accuracy: 0.5400\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6206 - accuracy: 0.7871 - val_loss: 1.5128 - val_accuracy: 0.5267\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6201 - accuracy: 0.7857 - val_loss: 1.5150 - val_accuracy: 0.5333\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6181 - accuracy: 0.7900 - val_loss: 1.5161 - val_accuracy: 0.5333\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6189 - accuracy: 0.7929 - val_loss: 1.5283 - val_accuracy: 0.5367\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6175 - accuracy: 0.7843 - val_loss: 1.5274 - val_accuracy: 0.5300\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.6169 - accuracy: 0.7971 - val_loss: 1.5207 - val_accuracy: 0.5267\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6154 - accuracy: 0.7957 - val_loss: 1.5329 - val_accuracy: 0.5300\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6145 - accuracy: 0.7914 - val_loss: 1.5142 - val_accuracy: 0.5333\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.6158 - accuracy: 0.7971 - val_loss: 1.5277 - val_accuracy: 0.5267\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6159 - accuracy: 0.7886 - val_loss: 1.5276 - val_accuracy: 0.5400\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6133 - accuracy: 0.8014 - val_loss: 1.5353 - val_accuracy: 0.5300\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6114 - accuracy: 0.7943 - val_loss: 1.5456 - val_accuracy: 0.5300\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6096 - accuracy: 0.8029 - val_loss: 1.5309 - val_accuracy: 0.5200\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6105 - accuracy: 0.7986 - val_loss: 1.5343 - val_accuracy: 0.5267\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6089 - accuracy: 0.7943 - val_loss: 1.5502 - val_accuracy: 0.5267\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6098 - accuracy: 0.7971 - val_loss: 1.5388 - val_accuracy: 0.5300\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6091 - accuracy: 0.7914 - val_loss: 1.5483 - val_accuracy: 0.5400\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6088 - accuracy: 0.7929 - val_loss: 1.5379 - val_accuracy: 0.5300\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6063 - accuracy: 0.8043 - val_loss: 1.5412 - val_accuracy: 0.5400\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6064 - accuracy: 0.7914 - val_loss: 1.5609 - val_accuracy: 0.5267\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6050 - accuracy: 0.7957 - val_loss: 1.5489 - val_accuracy: 0.5367\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6036 - accuracy: 0.7957 - val_loss: 1.5598 - val_accuracy: 0.5300\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6052 - accuracy: 0.7943 - val_loss: 1.5557 - val_accuracy: 0.5333\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6056 - accuracy: 0.7943 - val_loss: 1.5476 - val_accuracy: 0.5300\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6030 - accuracy: 0.8071 - val_loss: 1.5543 - val_accuracy: 0.5233\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6026 - accuracy: 0.8043 - val_loss: 1.5596 - val_accuracy: 0.5333\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6006 - accuracy: 0.7914 - val_loss: 1.5498 - val_accuracy: 0.5367\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6008 - accuracy: 0.8000 - val_loss: 1.5557 - val_accuracy: 0.5367\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6008 - accuracy: 0.8029 - val_loss: 1.5562 - val_accuracy: 0.5233\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5989 - accuracy: 0.7943 - val_loss: 1.5711 - val_accuracy: 0.5333\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5991 - accuracy: 0.7986 - val_loss: 1.5560 - val_accuracy: 0.5233\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.5993 - accuracy: 0.8057 - val_loss: 1.5637 - val_accuracy: 0.5367\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5961 - accuracy: 0.7943 - val_loss: 1.5538 - val_accuracy: 0.5267\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5967 - accuracy: 0.8043 - val_loss: 1.5790 - val_accuracy: 0.5300\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5972 - accuracy: 0.7986 - val_loss: 1.5667 - val_accuracy: 0.5300\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5941 - accuracy: 0.7943 - val_loss: 1.5636 - val_accuracy: 0.5367\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5956 - accuracy: 0.8071 - val_loss: 1.5731 - val_accuracy: 0.5367\n",
      "Epoch 387/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.5951 - accuracy: 0.8000 - val_loss: 1.5755 - val_accuracy: 0.5300\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5921 - accuracy: 0.8071 - val_loss: 1.5688 - val_accuracy: 0.5133\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5930 - accuracy: 0.8043 - val_loss: 1.5734 - val_accuracy: 0.5400\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5926 - accuracy: 0.7971 - val_loss: 1.5698 - val_accuracy: 0.5300\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5896 - accuracy: 0.8029 - val_loss: 1.5782 - val_accuracy: 0.5267\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5895 - accuracy: 0.8029 - val_loss: 1.5693 - val_accuracy: 0.5267\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5884 - accuracy: 0.8071 - val_loss: 1.5789 - val_accuracy: 0.5333\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5899 - accuracy: 0.8014 - val_loss: 1.5856 - val_accuracy: 0.5267\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5880 - accuracy: 0.8071 - val_loss: 1.5914 - val_accuracy: 0.5333\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5879 - accuracy: 0.8043 - val_loss: 1.5916 - val_accuracy: 0.5367\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5887 - accuracy: 0.8000 - val_loss: 1.5871 - val_accuracy: 0.5400\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5864 - accuracy: 0.7971 - val_loss: 1.5929 - val_accuracy: 0.5367\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5879 - accuracy: 0.8014 - val_loss: 1.5877 - val_accuracy: 0.5433\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5860 - accuracy: 0.8043 - val_loss: 1.5979 - val_accuracy: 0.5367\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5848 - accuracy: 0.8043 - val_loss: 1.5920 - val_accuracy: 0.5333\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5838 - accuracy: 0.8086 - val_loss: 1.5916 - val_accuracy: 0.5167\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5818 - accuracy: 0.8029 - val_loss: 1.5987 - val_accuracy: 0.5333\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5830 - accuracy: 0.8171 - val_loss: 1.5975 - val_accuracy: 0.5367\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5806 - accuracy: 0.8114 - val_loss: 1.5962 - val_accuracy: 0.5300\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5820 - accuracy: 0.8086 - val_loss: 1.5937 - val_accuracy: 0.5300\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5794 - accuracy: 0.8043 - val_loss: 1.5948 - val_accuracy: 0.5367\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5808 - accuracy: 0.8086 - val_loss: 1.5967 - val_accuracy: 0.5367\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5809 - accuracy: 0.8086 - val_loss: 1.5885 - val_accuracy: 0.5333\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5776 - accuracy: 0.8143 - val_loss: 1.6071 - val_accuracy: 0.5333\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5770 - accuracy: 0.8114 - val_loss: 1.6031 - val_accuracy: 0.5367\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5770 - accuracy: 0.8114 - val_loss: 1.6010 - val_accuracy: 0.5333\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5772 - accuracy: 0.8100 - val_loss: 1.6107 - val_accuracy: 0.5200\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5752 - accuracy: 0.8071 - val_loss: 1.6168 - val_accuracy: 0.5400\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5777 - accuracy: 0.8057 - val_loss: 1.6070 - val_accuracy: 0.5433\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.5749 - accuracy: 0.8057 - val_loss: 1.6090 - val_accuracy: 0.5333\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5751 - accuracy: 0.8157 - val_loss: 1.6073 - val_accuracy: 0.5367\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5733 - accuracy: 0.8100 - val_loss: 1.6140 - val_accuracy: 0.5333\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5720 - accuracy: 0.8057 - val_loss: 1.6264 - val_accuracy: 0.5300\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5732 - accuracy: 0.8114 - val_loss: 1.6127 - val_accuracy: 0.5300\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5714 - accuracy: 0.8071 - val_loss: 1.6155 - val_accuracy: 0.5333\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.5718 - accuracy: 0.8143 - val_loss: 1.6328 - val_accuracy: 0.5300\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5704 - accuracy: 0.8129 - val_loss: 1.6212 - val_accuracy: 0.5167\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5707 - accuracy: 0.8171 - val_loss: 1.6098 - val_accuracy: 0.5333\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5674 - accuracy: 0.8100 - val_loss: 1.6106 - val_accuracy: 0.5233\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5670 - accuracy: 0.8071 - val_loss: 1.6321 - val_accuracy: 0.5400\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5694 - accuracy: 0.8086 - val_loss: 1.6206 - val_accuracy: 0.5400\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5679 - accuracy: 0.8114 - val_loss: 1.6122 - val_accuracy: 0.5333\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5662 - accuracy: 0.8186 - val_loss: 1.6408 - val_accuracy: 0.5333\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5669 - accuracy: 0.8114 - val_loss: 1.6246 - val_accuracy: 0.5400\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5652 - accuracy: 0.8114 - val_loss: 1.6206 - val_accuracy: 0.5300\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5633 - accuracy: 0.8143 - val_loss: 1.6582 - val_accuracy: 0.5367\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5648 - accuracy: 0.8171 - val_loss: 1.6277 - val_accuracy: 0.5200\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5643 - accuracy: 0.8143 - val_loss: 1.6328 - val_accuracy: 0.5333\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5635 - accuracy: 0.8171 - val_loss: 1.6441 - val_accuracy: 0.5367\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5620 - accuracy: 0.8143 - val_loss: 1.6313 - val_accuracy: 0.5333\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5630 - accuracy: 0.8071 - val_loss: 1.6330 - val_accuracy: 0.5367\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5635 - accuracy: 0.8157 - val_loss: 1.6339 - val_accuracy: 0.5200\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.5593 - accuracy: 0.8171 - val_loss: 1.6403 - val_accuracy: 0.5233\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.5619 - accuracy: 0.8100 - val_loss: 1.6301 - val_accuracy: 0.5133\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.5592 - accuracy: 0.8329 - val_loss: 1.6346 - val_accuracy: 0.5267\n",
      "Epoch 442/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 0.5608 - accuracy: 0.8143 - val_loss: 1.6452 - val_accuracy: 0.5433\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5581 - accuracy: 0.8157 - val_loss: 1.6519 - val_accuracy: 0.5233\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5565 - accuracy: 0.8257 - val_loss: 1.6619 - val_accuracy: 0.5367\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5581 - accuracy: 0.8171 - val_loss: 1.6409 - val_accuracy: 0.5333\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5578 - accuracy: 0.8214 - val_loss: 1.6394 - val_accuracy: 0.5233\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5549 - accuracy: 0.8171 - val_loss: 1.6575 - val_accuracy: 0.5333\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5550 - accuracy: 0.8200 - val_loss: 1.6478 - val_accuracy: 0.5133\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5549 - accuracy: 0.8243 - val_loss: 1.6547 - val_accuracy: 0.5333\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5552 - accuracy: 0.8186 - val_loss: 1.6534 - val_accuracy: 0.5367\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5528 - accuracy: 0.8157 - val_loss: 1.6542 - val_accuracy: 0.5333\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5540 - accuracy: 0.8214 - val_loss: 1.6597 - val_accuracy: 0.5300\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5511 - accuracy: 0.8171 - val_loss: 1.6568 - val_accuracy: 0.5133\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5524 - accuracy: 0.8186 - val_loss: 1.6631 - val_accuracy: 0.5300\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5518 - accuracy: 0.8200 - val_loss: 1.6554 - val_accuracy: 0.5400\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5512 - accuracy: 0.8286 - val_loss: 1.6666 - val_accuracy: 0.5400\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5513 - accuracy: 0.8229 - val_loss: 1.6631 - val_accuracy: 0.5367\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5514 - accuracy: 0.8157 - val_loss: 1.6702 - val_accuracy: 0.5333\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5513 - accuracy: 0.8243 - val_loss: 1.6627 - val_accuracy: 0.5333\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5498 - accuracy: 0.8229 - val_loss: 1.6773 - val_accuracy: 0.5367\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5492 - accuracy: 0.8243 - val_loss: 1.6714 - val_accuracy: 0.5300\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.5470 - accuracy: 0.8257 - val_loss: 1.6686 - val_accuracy: 0.5167\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5469 - accuracy: 0.8271 - val_loss: 1.6721 - val_accuracy: 0.5300\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5465 - accuracy: 0.8229 - val_loss: 1.6851 - val_accuracy: 0.5400\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5468 - accuracy: 0.8229 - val_loss: 1.6865 - val_accuracy: 0.5433\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5470 - accuracy: 0.8200 - val_loss: 1.6787 - val_accuracy: 0.5433\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5436 - accuracy: 0.8214 - val_loss: 1.6815 - val_accuracy: 0.5267\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5442 - accuracy: 0.8271 - val_loss: 1.6718 - val_accuracy: 0.5400\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5438 - accuracy: 0.8200 - val_loss: 1.6649 - val_accuracy: 0.5433\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5417 - accuracy: 0.8229 - val_loss: 1.7030 - val_accuracy: 0.5433\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5440 - accuracy: 0.8243 - val_loss: 1.6720 - val_accuracy: 0.5400\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5416 - accuracy: 0.8243 - val_loss: 1.6732 - val_accuracy: 0.5433\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5381 - accuracy: 0.8271 - val_loss: 1.6917 - val_accuracy: 0.5467\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5411 - accuracy: 0.8157 - val_loss: 1.6803 - val_accuracy: 0.5200\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5388 - accuracy: 0.8257 - val_loss: 1.6879 - val_accuracy: 0.5400\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5388 - accuracy: 0.8171 - val_loss: 1.6954 - val_accuracy: 0.5367\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5383 - accuracy: 0.8200 - val_loss: 1.6943 - val_accuracy: 0.5300\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5383 - accuracy: 0.8214 - val_loss: 1.6900 - val_accuracy: 0.5300\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.5388 - accuracy: 0.8286 - val_loss: 1.6973 - val_accuracy: 0.5267\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5357 - accuracy: 0.8271 - val_loss: 1.6978 - val_accuracy: 0.5367\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5366 - accuracy: 0.8271 - val_loss: 1.6952 - val_accuracy: 0.5433\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5366 - accuracy: 0.8229 - val_loss: 1.7006 - val_accuracy: 0.5400\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5337 - accuracy: 0.8243 - val_loss: 1.6896 - val_accuracy: 0.5367\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5346 - accuracy: 0.8286 - val_loss: 1.7262 - val_accuracy: 0.5333\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5336 - accuracy: 0.8257 - val_loss: 1.6979 - val_accuracy: 0.5367\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5340 - accuracy: 0.8186 - val_loss: 1.7092 - val_accuracy: 0.5267\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5335 - accuracy: 0.8271 - val_loss: 1.7092 - val_accuracy: 0.5300\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.5327 - accuracy: 0.8243 - val_loss: 1.7008 - val_accuracy: 0.5267\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5322 - accuracy: 0.8314 - val_loss: 1.7003 - val_accuracy: 0.5400\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5307 - accuracy: 0.8300 - val_loss: 1.7093 - val_accuracy: 0.5300\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5296 - accuracy: 0.8229 - val_loss: 1.7048 - val_accuracy: 0.5333\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5306 - accuracy: 0.8300 - val_loss: 1.7148 - val_accuracy: 0.5400\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5294 - accuracy: 0.8186 - val_loss: 1.7101 - val_accuracy: 0.5400\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5275 - accuracy: 0.8286 - val_loss: 1.7203 - val_accuracy: 0.5333\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5291 - accuracy: 0.8271 - val_loss: 1.7127 - val_accuracy: 0.5300\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5261 - accuracy: 0.8314 - val_loss: 1.7309 - val_accuracy: 0.5500\n",
      "Epoch 497/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.5265 - accuracy: 0.8343 - val_loss: 1.7168 - val_accuracy: 0.5267\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5279 - accuracy: 0.8329 - val_loss: 1.7096 - val_accuracy: 0.5300\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5259 - accuracy: 0.8386 - val_loss: 1.7292 - val_accuracy: 0.5267\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5268 - accuracy: 0.8300 - val_loss: 1.7156 - val_accuracy: 0.5367\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5244 - accuracy: 0.8300 - val_loss: 1.7302 - val_accuracy: 0.5267\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5241 - accuracy: 0.8400 - val_loss: 1.7243 - val_accuracy: 0.5333\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.5249 - accuracy: 0.8314 - val_loss: 1.7303 - val_accuracy: 0.5367\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5236 - accuracy: 0.8300 - val_loss: 1.7413 - val_accuracy: 0.5233\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5232 - accuracy: 0.8414 - val_loss: 1.7284 - val_accuracy: 0.5267\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5238 - accuracy: 0.8371 - val_loss: 1.7448 - val_accuracy: 0.5467\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5227 - accuracy: 0.8343 - val_loss: 1.7412 - val_accuracy: 0.5367\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5213 - accuracy: 0.8443 - val_loss: 1.7352 - val_accuracy: 0.5367\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5225 - accuracy: 0.8286 - val_loss: 1.7350 - val_accuracy: 0.5367\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5203 - accuracy: 0.8286 - val_loss: 1.7377 - val_accuracy: 0.5300\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5192 - accuracy: 0.8371 - val_loss: 1.7523 - val_accuracy: 0.5300\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5198 - accuracy: 0.8343 - val_loss: 1.7330 - val_accuracy: 0.5333\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5187 - accuracy: 0.8357 - val_loss: 1.7447 - val_accuracy: 0.5467\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5190 - accuracy: 0.8329 - val_loss: 1.7511 - val_accuracy: 0.5233\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5177 - accuracy: 0.8371 - val_loss: 1.7554 - val_accuracy: 0.5267\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5169 - accuracy: 0.8343 - val_loss: 1.7398 - val_accuracy: 0.5267\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5152 - accuracy: 0.8400 - val_loss: 1.7464 - val_accuracy: 0.5233\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5155 - accuracy: 0.8414 - val_loss: 1.7567 - val_accuracy: 0.5433\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5134 - accuracy: 0.8443 - val_loss: 1.7531 - val_accuracy: 0.5333\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5143 - accuracy: 0.8429 - val_loss: 1.7528 - val_accuracy: 0.5400\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5134 - accuracy: 0.8400 - val_loss: 1.7568 - val_accuracy: 0.5367\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5126 - accuracy: 0.8386 - val_loss: 1.7557 - val_accuracy: 0.5400\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5114 - accuracy: 0.8429 - val_loss: 1.7569 - val_accuracy: 0.5400\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5112 - accuracy: 0.8386 - val_loss: 1.7620 - val_accuracy: 0.5433\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5103 - accuracy: 0.8429 - val_loss: 1.7576 - val_accuracy: 0.5500\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5122 - accuracy: 0.8386 - val_loss: 1.7674 - val_accuracy: 0.5433\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5106 - accuracy: 0.8329 - val_loss: 1.7674 - val_accuracy: 0.5433\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5101 - accuracy: 0.8386 - val_loss: 1.7637 - val_accuracy: 0.5400\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5103 - accuracy: 0.8443 - val_loss: 1.7565 - val_accuracy: 0.5400\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5076 - accuracy: 0.8400 - val_loss: 1.7694 - val_accuracy: 0.5367\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5071 - accuracy: 0.8429 - val_loss: 1.7660 - val_accuracy: 0.5300\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5068 - accuracy: 0.8429 - val_loss: 1.7632 - val_accuracy: 0.5467\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5068 - accuracy: 0.8429 - val_loss: 1.7628 - val_accuracy: 0.5267\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5080 - accuracy: 0.8429 - val_loss: 1.7667 - val_accuracy: 0.5400\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5039 - accuracy: 0.8471 - val_loss: 1.7749 - val_accuracy: 0.5167\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5078 - accuracy: 0.8443 - val_loss: 1.7754 - val_accuracy: 0.5500\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5043 - accuracy: 0.8457 - val_loss: 1.7675 - val_accuracy: 0.5367\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5037 - accuracy: 0.8414 - val_loss: 1.7770 - val_accuracy: 0.5300\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5030 - accuracy: 0.8443 - val_loss: 1.7692 - val_accuracy: 0.5467\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5027 - accuracy: 0.8514 - val_loss: 1.7723 - val_accuracy: 0.5500\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5032 - accuracy: 0.8486 - val_loss: 1.7770 - val_accuracy: 0.5300\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5040 - accuracy: 0.8371 - val_loss: 1.7790 - val_accuracy: 0.5433\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5023 - accuracy: 0.8486 - val_loss: 1.7804 - val_accuracy: 0.5400\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.5025 - accuracy: 0.8457 - val_loss: 1.7747 - val_accuracy: 0.5433\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4999 - accuracy: 0.8429 - val_loss: 1.7742 - val_accuracy: 0.5400\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4997 - accuracy: 0.8443 - val_loss: 1.7918 - val_accuracy: 0.5400\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5013 - accuracy: 0.8457 - val_loss: 1.7886 - val_accuracy: 0.5367\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5007 - accuracy: 0.8443 - val_loss: 1.7853 - val_accuracy: 0.5433\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4986 - accuracy: 0.8414 - val_loss: 1.7928 - val_accuracy: 0.5233\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4979 - accuracy: 0.8429 - val_loss: 1.7860 - val_accuracy: 0.5500\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.84 - 0s 104us/step - loss: 0.4981 - accuracy: 0.8514 - val_loss: 1.7857 - val_accuracy: 0.5433\n",
      "Epoch 552/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 0.4977 - accuracy: 0.8514 - val_loss: 1.7979 - val_accuracy: 0.5467\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4986 - accuracy: 0.8471 - val_loss: 1.7910 - val_accuracy: 0.5433\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4973 - accuracy: 0.8429 - val_loss: 1.7992 - val_accuracy: 0.5400\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4957 - accuracy: 0.8500 - val_loss: 1.8135 - val_accuracy: 0.5467\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4972 - accuracy: 0.8514 - val_loss: 1.8057 - val_accuracy: 0.5467\n",
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4950 - accuracy: 0.8543 - val_loss: 1.8129 - val_accuracy: 0.5400\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4930 - accuracy: 0.8486 - val_loss: 1.8076 - val_accuracy: 0.5467\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4949 - accuracy: 0.8500 - val_loss: 1.8110 - val_accuracy: 0.5433\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4928 - accuracy: 0.8514 - val_loss: 1.8174 - val_accuracy: 0.5433\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4926 - accuracy: 0.8500 - val_loss: 1.8129 - val_accuracy: 0.5333\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4937 - accuracy: 0.8471 - val_loss: 1.8111 - val_accuracy: 0.5433\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4926 - accuracy: 0.8557 - val_loss: 1.8087 - val_accuracy: 0.5267\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4912 - accuracy: 0.8471 - val_loss: 1.8245 - val_accuracy: 0.5433\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4935 - accuracy: 0.8443 - val_loss: 1.8096 - val_accuracy: 0.5367\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4920 - accuracy: 0.8557 - val_loss: 1.8274 - val_accuracy: 0.5433\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.4906 - accuracy: 0.8571 - val_loss: 1.8171 - val_accuracy: 0.5367\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4903 - accuracy: 0.8557 - val_loss: 1.8163 - val_accuracy: 0.5367\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4894 - accuracy: 0.8557 - val_loss: 1.8142 - val_accuracy: 0.5367\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4898 - accuracy: 0.8486 - val_loss: 1.8115 - val_accuracy: 0.5400\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4905 - accuracy: 0.8543 - val_loss: 1.8162 - val_accuracy: 0.5400\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.4872 - accuracy: 0.8557 - val_loss: 1.8079 - val_accuracy: 0.5367\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4898 - accuracy: 0.8486 - val_loss: 1.8333 - val_accuracy: 0.5400\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4869 - accuracy: 0.8471 - val_loss: 1.8460 - val_accuracy: 0.5300\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4878 - accuracy: 0.8500 - val_loss: 1.8303 - val_accuracy: 0.5367\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4884 - accuracy: 0.8543 - val_loss: 1.8292 - val_accuracy: 0.5367\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4858 - accuracy: 0.8471 - val_loss: 1.8372 - val_accuracy: 0.5267\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4849 - accuracy: 0.8529 - val_loss: 1.8532 - val_accuracy: 0.5167\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4855 - accuracy: 0.8557 - val_loss: 1.8287 - val_accuracy: 0.5333\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4859 - accuracy: 0.8514 - val_loss: 1.8455 - val_accuracy: 0.5400\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4851 - accuracy: 0.8557 - val_loss: 1.8349 - val_accuracy: 0.5467\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4838 - accuracy: 0.8586 - val_loss: 1.8318 - val_accuracy: 0.5300\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.4838 - accuracy: 0.8571 - val_loss: 1.8420 - val_accuracy: 0.5367\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.4835 - accuracy: 0.8614 - val_loss: 1.8531 - val_accuracy: 0.5367\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.4815 - accuracy: 0.8543 - val_loss: 1.8604 - val_accuracy: 0.5267\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4813 - accuracy: 0.8529 - val_loss: 1.8456 - val_accuracy: 0.5367\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4822 - accuracy: 0.8543 - val_loss: 1.8508 - val_accuracy: 0.5367\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4808 - accuracy: 0.8557 - val_loss: 1.8506 - val_accuracy: 0.5333\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4821 - accuracy: 0.8529 - val_loss: 1.8598 - val_accuracy: 0.5333\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4811 - accuracy: 0.8557 - val_loss: 1.8491 - val_accuracy: 0.5367\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4798 - accuracy: 0.8614 - val_loss: 1.8457 - val_accuracy: 0.5333\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4811 - accuracy: 0.8500 - val_loss: 1.8582 - val_accuracy: 0.5400\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4790 - accuracy: 0.8557 - val_loss: 1.8491 - val_accuracy: 0.5333\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4793 - accuracy: 0.8614 - val_loss: 1.8655 - val_accuracy: 0.5400\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4784 - accuracy: 0.8586 - val_loss: 1.8590 - val_accuracy: 0.5367\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4790 - accuracy: 0.8543 - val_loss: 1.8666 - val_accuracy: 0.5333\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4790 - accuracy: 0.8557 - val_loss: 1.8637 - val_accuracy: 0.5333\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4770 - accuracy: 0.8600 - val_loss: 1.8566 - val_accuracy: 0.5433\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4763 - accuracy: 0.8486 - val_loss: 1.8776 - val_accuracy: 0.5333\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.4761 - accuracy: 0.8543 - val_loss: 1.8572 - val_accuracy: 0.5333\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.4766 - accuracy: 0.8586 - val_loss: 1.8720 - val_accuracy: 0.5333\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4752 - accuracy: 0.8629 - val_loss: 1.8553 - val_accuracy: 0.5367\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4756 - accuracy: 0.8600 - val_loss: 1.8696 - val_accuracy: 0.5300\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4755 - accuracy: 0.8586 - val_loss: 1.8754 - val_accuracy: 0.5433\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4748 - accuracy: 0.8586 - val_loss: 1.8683 - val_accuracy: 0.5333\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4738 - accuracy: 0.8557 - val_loss: 1.8670 - val_accuracy: 0.5400\n",
      "Epoch 607/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 0.4748 - accuracy: 0.8557 - val_loss: 1.8650 - val_accuracy: 0.5367\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4733 - accuracy: 0.8557 - val_loss: 1.8664 - val_accuracy: 0.5333\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4735 - accuracy: 0.8571 - val_loss: 1.8774 - val_accuracy: 0.5333\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4728 - accuracy: 0.8571 - val_loss: 1.8660 - val_accuracy: 0.5367\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4724 - accuracy: 0.8514 - val_loss: 1.8834 - val_accuracy: 0.5333\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4719 - accuracy: 0.8571 - val_loss: 1.8812 - val_accuracy: 0.5333\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4718 - accuracy: 0.8571 - val_loss: 1.8805 - val_accuracy: 0.5367\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4718 - accuracy: 0.8600 - val_loss: 1.8891 - val_accuracy: 0.5333\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4695 - accuracy: 0.8557 - val_loss: 1.8923 - val_accuracy: 0.5367\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4704 - accuracy: 0.8600 - val_loss: 1.9044 - val_accuracy: 0.5400\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.4709 - accuracy: 0.8543 - val_loss: 1.9019 - val_accuracy: 0.5367\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.4690 - accuracy: 0.8629 - val_loss: 1.9028 - val_accuracy: 0.5367\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.4680 - accuracy: 0.8543 - val_loss: 1.9031 - val_accuracy: 0.5367\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.4681 - accuracy: 0.8657 - val_loss: 1.8917 - val_accuracy: 0.5367\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.4680 - accuracy: 0.8657 - val_loss: 1.9002 - val_accuracy: 0.5300\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.4670 - accuracy: 0.8571 - val_loss: 1.9188 - val_accuracy: 0.5367\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4668 - accuracy: 0.8600 - val_loss: 1.9018 - val_accuracy: 0.5267\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.4675 - accuracy: 0.8600 - val_loss: 1.8934 - val_accuracy: 0.5300\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.4665 - accuracy: 0.8600 - val_loss: 1.9043 - val_accuracy: 0.5300\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.4668 - accuracy: 0.8600 - val_loss: 1.9037 - val_accuracy: 0.5233\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4671 - accuracy: 0.8586 - val_loss: 1.9069 - val_accuracy: 0.5267\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4650 - accuracy: 0.8671 - val_loss: 1.9122 - val_accuracy: 0.5133\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4641 - accuracy: 0.8571 - val_loss: 1.9248 - val_accuracy: 0.5300\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4631 - accuracy: 0.8543 - val_loss: 1.9021 - val_accuracy: 0.5300\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4631 - accuracy: 0.8643 - val_loss: 1.9139 - val_accuracy: 0.5267\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4635 - accuracy: 0.8629 - val_loss: 1.9107 - val_accuracy: 0.5200\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4622 - accuracy: 0.8629 - val_loss: 1.9291 - val_accuracy: 0.5233\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4622 - accuracy: 0.8614 - val_loss: 1.9174 - val_accuracy: 0.5333\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4615 - accuracy: 0.8614 - val_loss: 1.9142 - val_accuracy: 0.5367\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.4615 - accuracy: 0.8657 - val_loss: 1.9143 - val_accuracy: 0.5233\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4609 - accuracy: 0.8643 - val_loss: 1.9238 - val_accuracy: 0.5400\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4595 - accuracy: 0.8671 - val_loss: 1.9410 - val_accuracy: 0.5167\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4603 - accuracy: 0.8571 - val_loss: 1.9306 - val_accuracy: 0.5333\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4599 - accuracy: 0.8629 - val_loss: 1.9157 - val_accuracy: 0.5167\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4593 - accuracy: 0.8629 - val_loss: 1.9251 - val_accuracy: 0.5167\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4581 - accuracy: 0.8686 - val_loss: 1.9340 - val_accuracy: 0.5367\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4572 - accuracy: 0.8657 - val_loss: 1.9338 - val_accuracy: 0.5267\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4572 - accuracy: 0.8671 - val_loss: 1.9303 - val_accuracy: 0.5233\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4570 - accuracy: 0.8600 - val_loss: 1.9273 - val_accuracy: 0.5200\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4579 - accuracy: 0.8643 - val_loss: 1.9358 - val_accuracy: 0.5333\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4550 - accuracy: 0.8657 - val_loss: 1.9317 - val_accuracy: 0.5300\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4558 - accuracy: 0.8643 - val_loss: 1.9525 - val_accuracy: 0.5200\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4564 - accuracy: 0.8614 - val_loss: 1.9413 - val_accuracy: 0.5300\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4552 - accuracy: 0.8629 - val_loss: 1.9414 - val_accuracy: 0.5200\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4549 - accuracy: 0.8671 - val_loss: 1.9409 - val_accuracy: 0.5367\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.4552 - accuracy: 0.8671 - val_loss: 1.9423 - val_accuracy: 0.5333\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4535 - accuracy: 0.8629 - val_loss: 1.9523 - val_accuracy: 0.5233\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4516 - accuracy: 0.8657 - val_loss: 1.9620 - val_accuracy: 0.5167\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4531 - accuracy: 0.8671 - val_loss: 1.9599 - val_accuracy: 0.5233\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4528 - accuracy: 0.8629 - val_loss: 1.9460 - val_accuracy: 0.5233\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4528 - accuracy: 0.8686 - val_loss: 1.9613 - val_accuracy: 0.5333\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4528 - accuracy: 0.8643 - val_loss: 1.9614 - val_accuracy: 0.5133\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4523 - accuracy: 0.8700 - val_loss: 1.9575 - val_accuracy: 0.5233\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4519 - accuracy: 0.8657 - val_loss: 1.9622 - val_accuracy: 0.5333\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4514 - accuracy: 0.8700 - val_loss: 1.9618 - val_accuracy: 0.5167\n",
      "Epoch 662/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.4500 - accuracy: 0.8657 - val_loss: 1.9537 - val_accuracy: 0.5200\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4497 - accuracy: 0.8671 - val_loss: 1.9662 - val_accuracy: 0.5133\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4514 - accuracy: 0.8614 - val_loss: 1.9703 - val_accuracy: 0.5200\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.4496 - accuracy: 0.8600 - val_loss: 1.9605 - val_accuracy: 0.5233\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4486 - accuracy: 0.8686 - val_loss: 1.9527 - val_accuracy: 0.5167\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4489 - accuracy: 0.8686 - val_loss: 1.9646 - val_accuracy: 0.5267\n",
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4485 - accuracy: 0.8686 - val_loss: 1.9595 - val_accuracy: 0.5367\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4473 - accuracy: 0.8700 - val_loss: 1.9809 - val_accuracy: 0.5300\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4461 - accuracy: 0.8657 - val_loss: 1.9750 - val_accuracy: 0.5167\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4479 - accuracy: 0.8714 - val_loss: 1.9812 - val_accuracy: 0.5333\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4458 - accuracy: 0.8700 - val_loss: 1.9823 - val_accuracy: 0.5167\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4467 - accuracy: 0.8686 - val_loss: 1.9764 - val_accuracy: 0.5100\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4464 - accuracy: 0.8671 - val_loss: 1.9827 - val_accuracy: 0.5167\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4444 - accuracy: 0.8729 - val_loss: 1.9944 - val_accuracy: 0.5133\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4450 - accuracy: 0.8657 - val_loss: 1.9755 - val_accuracy: 0.5333\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4456 - accuracy: 0.8657 - val_loss: 1.9821 - val_accuracy: 0.5067\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4457 - accuracy: 0.8686 - val_loss: 1.9949 - val_accuracy: 0.5300\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4444 - accuracy: 0.8643 - val_loss: 1.9960 - val_accuracy: 0.5300\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4431 - accuracy: 0.8686 - val_loss: 1.9929 - val_accuracy: 0.5367\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4440 - accuracy: 0.8629 - val_loss: 1.9837 - val_accuracy: 0.5200\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4418 - accuracy: 0.8743 - val_loss: 1.9840 - val_accuracy: 0.5133\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4430 - accuracy: 0.8743 - val_loss: 1.9833 - val_accuracy: 0.5267\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4437 - accuracy: 0.8700 - val_loss: 1.9787 - val_accuracy: 0.5133\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4423 - accuracy: 0.8729 - val_loss: 1.9809 - val_accuracy: 0.5100\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4417 - accuracy: 0.8743 - val_loss: 1.9951 - val_accuracy: 0.5300\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4421 - accuracy: 0.8671 - val_loss: 1.9937 - val_accuracy: 0.5067\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4410 - accuracy: 0.8657 - val_loss: 1.9944 - val_accuracy: 0.5200\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4412 - accuracy: 0.8729 - val_loss: 1.9957 - val_accuracy: 0.5167\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4401 - accuracy: 0.8714 - val_loss: 1.9860 - val_accuracy: 0.5200\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4408 - accuracy: 0.8657 - val_loss: 2.0089 - val_accuracy: 0.5133\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4400 - accuracy: 0.8729 - val_loss: 2.0220 - val_accuracy: 0.5300\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4408 - accuracy: 0.8671 - val_loss: 2.0147 - val_accuracy: 0.5267\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4388 - accuracy: 0.8700 - val_loss: 2.0185 - val_accuracy: 0.5333\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4394 - accuracy: 0.8729 - val_loss: 2.0121 - val_accuracy: 0.5167\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4383 - accuracy: 0.8743 - val_loss: 2.0097 - val_accuracy: 0.5133\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4377 - accuracy: 0.8757 - val_loss: 2.0162 - val_accuracy: 0.5233\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4387 - accuracy: 0.8771 - val_loss: 2.0117 - val_accuracy: 0.5167\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4377 - accuracy: 0.8686 - val_loss: 2.0283 - val_accuracy: 0.5167\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4371 - accuracy: 0.8714 - val_loss: 2.0302 - val_accuracy: 0.5233\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4363 - accuracy: 0.8743 - val_loss: 2.0191 - val_accuracy: 0.5367\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4368 - accuracy: 0.8700 - val_loss: 2.0205 - val_accuracy: 0.5300\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4355 - accuracy: 0.8800 - val_loss: 2.0179 - val_accuracy: 0.5133\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4359 - accuracy: 0.8729 - val_loss: 2.0144 - val_accuracy: 0.5367\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4357 - accuracy: 0.8743 - val_loss: 2.0183 - val_accuracy: 0.5367\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.4358 - accuracy: 0.8771 - val_loss: 2.0246 - val_accuracy: 0.5233\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4343 - accuracy: 0.8729 - val_loss: 2.0098 - val_accuracy: 0.5100\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4354 - accuracy: 0.8757 - val_loss: 2.0263 - val_accuracy: 0.5200\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4340 - accuracy: 0.8729 - val_loss: 2.0473 - val_accuracy: 0.5167\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4332 - accuracy: 0.8800 - val_loss: 2.0258 - val_accuracy: 0.5300\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4323 - accuracy: 0.8814 - val_loss: 2.0282 - val_accuracy: 0.5333\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4332 - accuracy: 0.8714 - val_loss: 2.0371 - val_accuracy: 0.5133\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4316 - accuracy: 0.8700 - val_loss: 2.0374 - val_accuracy: 0.5267\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4317 - accuracy: 0.8743 - val_loss: 2.0416 - val_accuracy: 0.5200\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4321 - accuracy: 0.8714 - val_loss: 2.0322 - val_accuracy: 0.5133\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4324 - accuracy: 0.8729 - val_loss: 2.0429 - val_accuracy: 0.5133\n",
      "Epoch 717/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 0.4321 - accuracy: 0.8729 - val_loss: 2.0348 - val_accuracy: 0.5333\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4297 - accuracy: 0.8771 - val_loss: 2.0345 - val_accuracy: 0.5100\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4302 - accuracy: 0.8729 - val_loss: 2.0404 - val_accuracy: 0.5133\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4296 - accuracy: 0.8771 - val_loss: 2.0566 - val_accuracy: 0.5067\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4321 - accuracy: 0.8786 - val_loss: 2.0419 - val_accuracy: 0.5167\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4297 - accuracy: 0.8786 - val_loss: 2.0421 - val_accuracy: 0.5400\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4291 - accuracy: 0.8771 - val_loss: 2.0461 - val_accuracy: 0.5233\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4296 - accuracy: 0.8771 - val_loss: 2.0668 - val_accuracy: 0.5333\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4292 - accuracy: 0.8743 - val_loss: 2.0686 - val_accuracy: 0.5233\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4287 - accuracy: 0.8743 - val_loss: 2.0545 - val_accuracy: 0.5300\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4284 - accuracy: 0.8800 - val_loss: 2.0626 - val_accuracy: 0.5300\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4274 - accuracy: 0.8829 - val_loss: 2.0547 - val_accuracy: 0.5300\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4271 - accuracy: 0.8771 - val_loss: 2.0706 - val_accuracy: 0.5267\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4269 - accuracy: 0.8729 - val_loss: 2.0553 - val_accuracy: 0.5300\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4277 - accuracy: 0.8757 - val_loss: 2.0739 - val_accuracy: 0.5167\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4264 - accuracy: 0.8729 - val_loss: 2.0556 - val_accuracy: 0.5167\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4251 - accuracy: 0.8757 - val_loss: 2.0829 - val_accuracy: 0.5200\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4267 - accuracy: 0.8771 - val_loss: 2.0773 - val_accuracy: 0.5133\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4272 - accuracy: 0.8757 - val_loss: 2.0593 - val_accuracy: 0.5233\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4259 - accuracy: 0.8771 - val_loss: 2.0605 - val_accuracy: 0.5300\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4253 - accuracy: 0.8843 - val_loss: 2.0691 - val_accuracy: 0.5300\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4239 - accuracy: 0.8829 - val_loss: 2.0851 - val_accuracy: 0.5133\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4232 - accuracy: 0.8800 - val_loss: 2.0782 - val_accuracy: 0.5133\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4243 - accuracy: 0.8786 - val_loss: 2.0659 - val_accuracy: 0.5233\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4232 - accuracy: 0.8800 - val_loss: 2.0783 - val_accuracy: 0.5167\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4242 - accuracy: 0.8743 - val_loss: 2.0823 - val_accuracy: 0.5233\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4230 - accuracy: 0.8771 - val_loss: 2.0847 - val_accuracy: 0.5133\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4231 - accuracy: 0.8814 - val_loss: 2.0756 - val_accuracy: 0.5233\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4229 - accuracy: 0.8829 - val_loss: 2.0819 - val_accuracy: 0.5233\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4216 - accuracy: 0.8786 - val_loss: 2.0709 - val_accuracy: 0.5167\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.4234 - accuracy: 0.8814 - val_loss: 2.0963 - val_accuracy: 0.5167\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.4221 - accuracy: 0.8829 - val_loss: 2.0852 - val_accuracy: 0.5100\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4203 - accuracy: 0.8871 - val_loss: 2.0853 - val_accuracy: 0.5267\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4213 - accuracy: 0.8800 - val_loss: 2.0939 - val_accuracy: 0.5300\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4210 - accuracy: 0.8829 - val_loss: 2.1064 - val_accuracy: 0.5300\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4207 - accuracy: 0.8771 - val_loss: 2.0967 - val_accuracy: 0.5200\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4197 - accuracy: 0.8814 - val_loss: 2.0927 - val_accuracy: 0.5100\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4201 - accuracy: 0.8871 - val_loss: 2.0996 - val_accuracy: 0.5233\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4183 - accuracy: 0.8829 - val_loss: 2.1039 - val_accuracy: 0.5200\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4195 - accuracy: 0.8814 - val_loss: 2.1009 - val_accuracy: 0.5133\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4184 - accuracy: 0.8843 - val_loss: 2.0996 - val_accuracy: 0.5167\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4196 - accuracy: 0.8829 - val_loss: 2.1074 - val_accuracy: 0.5300\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4176 - accuracy: 0.8814 - val_loss: 2.0989 - val_accuracy: 0.5133\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4179 - accuracy: 0.8829 - val_loss: 2.1045 - val_accuracy: 0.5200\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4175 - accuracy: 0.8843 - val_loss: 2.0909 - val_accuracy: 0.5233\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4185 - accuracy: 0.8829 - val_loss: 2.0981 - val_accuracy: 0.5133\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4169 - accuracy: 0.8886 - val_loss: 2.1027 - val_accuracy: 0.5200\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4165 - accuracy: 0.8843 - val_loss: 2.1106 - val_accuracy: 0.5133\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4174 - accuracy: 0.8743 - val_loss: 2.1128 - val_accuracy: 0.5033\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4166 - accuracy: 0.8757 - val_loss: 2.1270 - val_accuracy: 0.5300\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4155 - accuracy: 0.8843 - val_loss: 2.1150 - val_accuracy: 0.5200\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4156 - accuracy: 0.8771 - val_loss: 2.1115 - val_accuracy: 0.5267\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4155 - accuracy: 0.8871 - val_loss: 2.1390 - val_accuracy: 0.5200\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4155 - accuracy: 0.8829 - val_loss: 2.1204 - val_accuracy: 0.5233\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4136 - accuracy: 0.8829 - val_loss: 2.1093 - val_accuracy: 0.5233\n",
      "Epoch 772/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 0.4129 - accuracy: 0.8900 - val_loss: 2.1239 - val_accuracy: 0.4967\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4150 - accuracy: 0.8871 - val_loss: 2.1329 - val_accuracy: 0.5033\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4138 - accuracy: 0.8814 - val_loss: 2.1467 - val_accuracy: 0.5167\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4132 - accuracy: 0.8886 - val_loss: 2.1229 - val_accuracy: 0.5067\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4132 - accuracy: 0.8857 - val_loss: 2.1230 - val_accuracy: 0.5167\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4113 - accuracy: 0.8871 - val_loss: 2.1311 - val_accuracy: 0.5100\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4123 - accuracy: 0.8871 - val_loss: 2.1514 - val_accuracy: 0.5167\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4133 - accuracy: 0.8871 - val_loss: 2.1302 - val_accuracy: 0.5200\n",
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4121 - accuracy: 0.8829 - val_loss: 2.1377 - val_accuracy: 0.5133\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4116 - accuracy: 0.8829 - val_loss: 2.1352 - val_accuracy: 0.5200\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4107 - accuracy: 0.8929 - val_loss: 2.1137 - val_accuracy: 0.5167\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4115 - accuracy: 0.8914 - val_loss: 2.1358 - val_accuracy: 0.5133\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4107 - accuracy: 0.8857 - val_loss: 2.1448 - val_accuracy: 0.5167\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4103 - accuracy: 0.8843 - val_loss: 2.1410 - val_accuracy: 0.5167\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4119 - accuracy: 0.8900 - val_loss: 2.1567 - val_accuracy: 0.5067\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4104 - accuracy: 0.8871 - val_loss: 2.1544 - val_accuracy: 0.5100\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4106 - accuracy: 0.8886 - val_loss: 2.1554 - val_accuracy: 0.5267\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.4091 - accuracy: 0.8871 - val_loss: 2.1557 - val_accuracy: 0.5233\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4096 - accuracy: 0.8929 - val_loss: 2.1562 - val_accuracy: 0.5100\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4082 - accuracy: 0.8871 - val_loss: 2.1420 - val_accuracy: 0.5133\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4082 - accuracy: 0.8886 - val_loss: 2.1490 - val_accuracy: 0.5167\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4074 - accuracy: 0.8871 - val_loss: 2.1616 - val_accuracy: 0.5167\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4071 - accuracy: 0.8957 - val_loss: 2.1492 - val_accuracy: 0.5033\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4075 - accuracy: 0.8914 - val_loss: 2.1706 - val_accuracy: 0.5133\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.4074 - accuracy: 0.8900 - val_loss: 2.1513 - val_accuracy: 0.5100\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4066 - accuracy: 0.8957 - val_loss: 2.1807 - val_accuracy: 0.5100\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4065 - accuracy: 0.8843 - val_loss: 2.1656 - val_accuracy: 0.5133\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4064 - accuracy: 0.8929 - val_loss: 2.1817 - val_accuracy: 0.5233\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4065 - accuracy: 0.8843 - val_loss: 2.1720 - val_accuracy: 0.5267\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4050 - accuracy: 0.8857 - val_loss: 2.1549 - val_accuracy: 0.5067\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4048 - accuracy: 0.8929 - val_loss: 2.1620 - val_accuracy: 0.5167\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4048 - accuracy: 0.8914 - val_loss: 2.1778 - val_accuracy: 0.4967\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4048 - accuracy: 0.8914 - val_loss: 2.1792 - val_accuracy: 0.5200\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.4036 - accuracy: 0.8886 - val_loss: 2.1568 - val_accuracy: 0.5100\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4050 - accuracy: 0.8929 - val_loss: 2.1738 - val_accuracy: 0.5000\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 0.4039 - accuracy: 0.8871 - val_loss: 2.1917 - val_accuracy: 0.5167\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.4036 - accuracy: 0.8914 - val_loss: 2.1753 - val_accuracy: 0.5200\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4029 - accuracy: 0.8886 - val_loss: 2.1845 - val_accuracy: 0.5067\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4035 - accuracy: 0.8943 - val_loss: 2.1819 - val_accuracy: 0.5133\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4031 - accuracy: 0.8943 - val_loss: 2.1708 - val_accuracy: 0.5167\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4018 - accuracy: 0.8929 - val_loss: 2.1822 - val_accuracy: 0.5267\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.4020 - accuracy: 0.9000 - val_loss: 2.1864 - val_accuracy: 0.5233\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.4018 - accuracy: 0.8971 - val_loss: 2.1947 - val_accuracy: 0.5133\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.4019 - accuracy: 0.8871 - val_loss: 2.1961 - val_accuracy: 0.5167\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.4015 - accuracy: 0.8943 - val_loss: 2.2113 - val_accuracy: 0.5100\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.4018 - accuracy: 0.8900 - val_loss: 2.2072 - val_accuracy: 0.5167\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.4013 - accuracy: 0.8929 - val_loss: 2.2018 - val_accuracy: 0.5100\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3997 - accuracy: 0.8886 - val_loss: 2.2055 - val_accuracy: 0.5200\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 0.4007 - accuracy: 0.8914 - val_loss: 2.2019 - val_accuracy: 0.5067\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3996 - accuracy: 0.8914 - val_loss: 2.1911 - val_accuracy: 0.5067\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3994 - accuracy: 0.8943 - val_loss: 2.1995 - val_accuracy: 0.5100\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3983 - accuracy: 0.8886 - val_loss: 2.2347 - val_accuracy: 0.5233\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.4003 - accuracy: 0.8986 - val_loss: 2.2278 - val_accuracy: 0.5133\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3988 - accuracy: 0.8929 - val_loss: 2.2044 - val_accuracy: 0.5133\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 0.3989 - accuracy: 0.8986 - val_loss: 2.2004 - val_accuracy: 0.5133\n",
      "Epoch 827/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 137us/step - loss: 0.3973 - accuracy: 0.8986 - val_loss: 2.2049 - val_accuracy: 0.5133\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3986 - accuracy: 0.8914 - val_loss: 2.2052 - val_accuracy: 0.5200\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.3969 - accuracy: 0.8986 - val_loss: 2.2022 - val_accuracy: 0.5100\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 0.3969 - accuracy: 0.9014 - val_loss: 2.2344 - val_accuracy: 0.5200\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 0.3980 - accuracy: 0.8886 - val_loss: 2.2137 - val_accuracy: 0.5167\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3967 - accuracy: 0.8971 - val_loss: 2.2057 - val_accuracy: 0.5067\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3966 - accuracy: 0.8943 - val_loss: 2.2086 - val_accuracy: 0.5167\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3972 - accuracy: 0.8900 - val_loss: 2.2086 - val_accuracy: 0.5067\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3958 - accuracy: 0.9000 - val_loss: 2.2136 - val_accuracy: 0.5067\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3957 - accuracy: 0.8971 - val_loss: 2.2169 - val_accuracy: 0.5067\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3957 - accuracy: 0.8986 - val_loss: 2.2376 - val_accuracy: 0.5200\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3963 - accuracy: 0.8900 - val_loss: 2.2195 - val_accuracy: 0.5133\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3951 - accuracy: 0.8900 - val_loss: 2.2277 - val_accuracy: 0.5133\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3942 - accuracy: 0.8971 - val_loss: 2.2347 - val_accuracy: 0.5167\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3959 - accuracy: 0.8929 - val_loss: 2.2279 - val_accuracy: 0.5167\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3951 - accuracy: 0.8971 - val_loss: 2.2210 - val_accuracy: 0.5167\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3943 - accuracy: 0.8971 - val_loss: 2.2379 - val_accuracy: 0.5133\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3934 - accuracy: 0.9014 - val_loss: 2.2375 - val_accuracy: 0.5167\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3934 - accuracy: 0.8929 - val_loss: 2.2380 - val_accuracy: 0.5200\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3928 - accuracy: 0.9000 - val_loss: 2.2395 - val_accuracy: 0.5200\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3928 - accuracy: 0.8914 - val_loss: 2.2427 - val_accuracy: 0.5167\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 187us/step - loss: 0.3934 - accuracy: 0.8929 - val_loss: 2.2420 - val_accuracy: 0.5133\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 0.3923 - accuracy: 0.8986 - val_loss: 2.2447 - val_accuracy: 0.5200\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3918 - accuracy: 0.9000 - val_loss: 2.2356 - val_accuracy: 0.5167\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3927 - accuracy: 0.8929 - val_loss: 2.2407 - val_accuracy: 0.5100\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3923 - accuracy: 0.9014 - val_loss: 2.2500 - val_accuracy: 0.5100\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3916 - accuracy: 0.8943 - val_loss: 2.2242 - val_accuracy: 0.5100\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3913 - accuracy: 0.9014 - val_loss: 2.2570 - val_accuracy: 0.5200\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3910 - accuracy: 0.8971 - val_loss: 2.2567 - val_accuracy: 0.5133\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3919 - accuracy: 0.8971 - val_loss: 2.2433 - val_accuracy: 0.5167\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3904 - accuracy: 0.8986 - val_loss: 2.2557 - val_accuracy: 0.5200\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3917 - accuracy: 0.8943 - val_loss: 2.2462 - val_accuracy: 0.5167\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3901 - accuracy: 0.8957 - val_loss: 2.2537 - val_accuracy: 0.5133\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3891 - accuracy: 0.9043 - val_loss: 2.2597 - val_accuracy: 0.5067\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.90 - 0s 111us/step - loss: 0.3892 - accuracy: 0.9057 - val_loss: 2.2508 - val_accuracy: 0.5167\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3900 - accuracy: 0.8971 - val_loss: 2.2550 - val_accuracy: 0.5100\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3900 - accuracy: 0.8929 - val_loss: 2.2638 - val_accuracy: 0.5100\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 0.3878 - accuracy: 0.9000 - val_loss: 2.2574 - val_accuracy: 0.5100\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3888 - accuracy: 0.9029 - val_loss: 2.2799 - val_accuracy: 0.5267\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3882 - accuracy: 0.9029 - val_loss: 2.2782 - val_accuracy: 0.5133\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3884 - accuracy: 0.9000 - val_loss: 2.2581 - val_accuracy: 0.5133\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3874 - accuracy: 0.9000 - val_loss: 2.2775 - val_accuracy: 0.5167\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3885 - accuracy: 0.9043 - val_loss: 2.2647 - val_accuracy: 0.5133\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3863 - accuracy: 0.9029 - val_loss: 2.2881 - val_accuracy: 0.5233\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3868 - accuracy: 0.9029 - val_loss: 2.2820 - val_accuracy: 0.5133\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3869 - accuracy: 0.8971 - val_loss: 2.2826 - val_accuracy: 0.5100\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3865 - accuracy: 0.9014 - val_loss: 2.2786 - val_accuracy: 0.5100\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3873 - accuracy: 0.8971 - val_loss: 2.2787 - val_accuracy: 0.5100\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3867 - accuracy: 0.8971 - val_loss: 2.2802 - val_accuracy: 0.5067\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3862 - accuracy: 0.8986 - val_loss: 2.2768 - val_accuracy: 0.5100\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3869 - accuracy: 0.9029 - val_loss: 2.2825 - val_accuracy: 0.5067\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3854 - accuracy: 0.9014 - val_loss: 2.2896 - val_accuracy: 0.5100\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3850 - accuracy: 0.9000 - val_loss: 2.2940 - val_accuracy: 0.5067\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3856 - accuracy: 0.8971 - val_loss: 2.2970 - val_accuracy: 0.5167\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3837 - accuracy: 0.9014 - val_loss: 2.2860 - val_accuracy: 0.5000\n",
      "Epoch 882/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.3855 - accuracy: 0.8971 - val_loss: 2.2911 - val_accuracy: 0.5100\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3832 - accuracy: 0.9057 - val_loss: 2.2903 - val_accuracy: 0.5067\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3841 - accuracy: 0.8971 - val_loss: 2.2789 - val_accuracy: 0.5167\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3835 - accuracy: 0.8986 - val_loss: 2.2910 - val_accuracy: 0.5067\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3846 - accuracy: 0.9086 - val_loss: 2.2909 - val_accuracy: 0.5067\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3828 - accuracy: 0.9000 - val_loss: 2.2955 - val_accuracy: 0.5100\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3833 - accuracy: 0.8971 - val_loss: 2.3041 - val_accuracy: 0.5100\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3825 - accuracy: 0.8986 - val_loss: 2.3030 - val_accuracy: 0.5067\n",
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3829 - accuracy: 0.9043 - val_loss: 2.2966 - val_accuracy: 0.5133\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3817 - accuracy: 0.9029 - val_loss: 2.2907 - val_accuracy: 0.5133\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3819 - accuracy: 0.9071 - val_loss: 2.2945 - val_accuracy: 0.5167\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3821 - accuracy: 0.9014 - val_loss: 2.3124 - val_accuracy: 0.5167\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3802 - accuracy: 0.9043 - val_loss: 2.3183 - val_accuracy: 0.5100\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 0.3803 - accuracy: 0.9057 - val_loss: 2.3119 - val_accuracy: 0.5100\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.3803 - accuracy: 0.9057 - val_loss: 2.3072 - val_accuracy: 0.5067\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3811 - accuracy: 0.8986 - val_loss: 2.3125 - val_accuracy: 0.5067\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.3810 - accuracy: 0.9029 - val_loss: 2.3184 - val_accuracy: 0.5067\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3803 - accuracy: 0.9043 - val_loss: 2.3142 - val_accuracy: 0.5067\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3810 - accuracy: 0.9014 - val_loss: 2.3159 - val_accuracy: 0.5033\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3800 - accuracy: 0.9071 - val_loss: 2.3400 - val_accuracy: 0.5100\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3803 - accuracy: 0.8971 - val_loss: 2.3163 - val_accuracy: 0.5067\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3804 - accuracy: 0.9014 - val_loss: 2.3249 - val_accuracy: 0.5100\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3794 - accuracy: 0.9057 - val_loss: 2.3110 - val_accuracy: 0.5133\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3794 - accuracy: 0.9014 - val_loss: 2.3200 - val_accuracy: 0.5033\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3787 - accuracy: 0.8986 - val_loss: 2.3195 - val_accuracy: 0.5133\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3785 - accuracy: 0.9043 - val_loss: 2.3305 - val_accuracy: 0.5033\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3778 - accuracy: 0.9057 - val_loss: 2.3313 - val_accuracy: 0.5100\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3778 - accuracy: 0.9043 - val_loss: 2.3264 - val_accuracy: 0.5033\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3787 - accuracy: 0.9029 - val_loss: 2.3285 - val_accuracy: 0.5133\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3770 - accuracy: 0.9029 - val_loss: 2.3337 - val_accuracy: 0.5033\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3759 - accuracy: 0.9057 - val_loss: 2.3477 - val_accuracy: 0.5133\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3769 - accuracy: 0.9000 - val_loss: 2.3411 - val_accuracy: 0.5100\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3766 - accuracy: 0.9129 - val_loss: 2.3336 - val_accuracy: 0.5133\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3765 - accuracy: 0.9071 - val_loss: 2.3341 - val_accuracy: 0.5067\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3767 - accuracy: 0.9014 - val_loss: 2.3500 - val_accuracy: 0.5067\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3753 - accuracy: 0.9100 - val_loss: 2.3519 - val_accuracy: 0.5133\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3767 - accuracy: 0.9014 - val_loss: 2.3526 - val_accuracy: 0.5100\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3756 - accuracy: 0.9071 - val_loss: 2.3343 - val_accuracy: 0.5033\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3756 - accuracy: 0.9029 - val_loss: 2.3582 - val_accuracy: 0.5067\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3753 - accuracy: 0.9086 - val_loss: 2.3649 - val_accuracy: 0.5133\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3755 - accuracy: 0.9071 - val_loss: 2.3498 - val_accuracy: 0.5033\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3738 - accuracy: 0.9029 - val_loss: 2.3458 - val_accuracy: 0.5000\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3737 - accuracy: 0.9043 - val_loss: 2.3594 - val_accuracy: 0.5100\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3743 - accuracy: 0.9029 - val_loss: 2.3450 - val_accuracy: 0.5067\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3739 - accuracy: 0.9114 - val_loss: 2.3505 - val_accuracy: 0.5100\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3742 - accuracy: 0.9057 - val_loss: 2.3503 - val_accuracy: 0.5067\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3737 - accuracy: 0.9029 - val_loss: 2.3520 - val_accuracy: 0.5100\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3725 - accuracy: 0.9057 - val_loss: 2.3382 - val_accuracy: 0.5067\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3732 - accuracy: 0.9029 - val_loss: 2.3860 - val_accuracy: 0.5100\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3731 - accuracy: 0.9043 - val_loss: 2.3623 - val_accuracy: 0.5067\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3734 - accuracy: 0.9043 - val_loss: 2.3765 - val_accuracy: 0.5000\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3731 - accuracy: 0.9100 - val_loss: 2.3679 - val_accuracy: 0.5100\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3721 - accuracy: 0.9086 - val_loss: 2.3716 - val_accuracy: 0.5067\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3709 - accuracy: 0.9086 - val_loss: 2.3617 - val_accuracy: 0.5067\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3720 - accuracy: 0.9057 - val_loss: 2.3730 - val_accuracy: 0.5100\n",
      "Epoch 937/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.3719 - accuracy: 0.9129 - val_loss: 2.3723 - val_accuracy: 0.5100\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3711 - accuracy: 0.9071 - val_loss: 2.3666 - val_accuracy: 0.5100\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3714 - accuracy: 0.9157 - val_loss: 2.3776 - val_accuracy: 0.5133\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3699 - accuracy: 0.9086 - val_loss: 2.3877 - val_accuracy: 0.5100\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3708 - accuracy: 0.9071 - val_loss: 2.3607 - val_accuracy: 0.5067\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3713 - accuracy: 0.9086 - val_loss: 2.3815 - val_accuracy: 0.5167\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3708 - accuracy: 0.9100 - val_loss: 2.3776 - val_accuracy: 0.5100\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3699 - accuracy: 0.9057 - val_loss: 2.3973 - val_accuracy: 0.5067\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3694 - accuracy: 0.9114 - val_loss: 2.3788 - val_accuracy: 0.5033\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3704 - accuracy: 0.9071 - val_loss: 2.4156 - val_accuracy: 0.5100\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3703 - accuracy: 0.9100 - val_loss: 2.3904 - val_accuracy: 0.5100\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3688 - accuracy: 0.9100 - val_loss: 2.3897 - val_accuracy: 0.5100\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3686 - accuracy: 0.9100 - val_loss: 2.3905 - val_accuracy: 0.5000\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3697 - accuracy: 0.9129 - val_loss: 2.3834 - val_accuracy: 0.5100\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3697 - accuracy: 0.9114 - val_loss: 2.3914 - val_accuracy: 0.5100\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3677 - accuracy: 0.9086 - val_loss: 2.4091 - val_accuracy: 0.5067\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3681 - accuracy: 0.9086 - val_loss: 2.3925 - val_accuracy: 0.5033\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3684 - accuracy: 0.9100 - val_loss: 2.4132 - val_accuracy: 0.5067\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3677 - accuracy: 0.9086 - val_loss: 2.4158 - val_accuracy: 0.5067\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3679 - accuracy: 0.9100 - val_loss: 2.4043 - val_accuracy: 0.5067\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3677 - accuracy: 0.9071 - val_loss: 2.4029 - val_accuracy: 0.5000\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3672 - accuracy: 0.9157 - val_loss: 2.4055 - val_accuracy: 0.5067\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3664 - accuracy: 0.9114 - val_loss: 2.3993 - val_accuracy: 0.5067\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3666 - accuracy: 0.9129 - val_loss: 2.4158 - val_accuracy: 0.5067\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3662 - accuracy: 0.9086 - val_loss: 2.4194 - val_accuracy: 0.5067\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3668 - accuracy: 0.9100 - val_loss: 2.4198 - val_accuracy: 0.5067\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3668 - accuracy: 0.9143 - val_loss: 2.4042 - val_accuracy: 0.5067\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3668 - accuracy: 0.9100 - val_loss: 2.4054 - val_accuracy: 0.5100\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3649 - accuracy: 0.9157 - val_loss: 2.4036 - val_accuracy: 0.5033\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3657 - accuracy: 0.9100 - val_loss: 2.4068 - val_accuracy: 0.5033\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3652 - accuracy: 0.9129 - val_loss: 2.4115 - val_accuracy: 0.5133\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3644 - accuracy: 0.9114 - val_loss: 2.4263 - val_accuracy: 0.5133\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3641 - accuracy: 0.9100 - val_loss: 2.4214 - val_accuracy: 0.5067\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3651 - accuracy: 0.9057 - val_loss: 2.4064 - val_accuracy: 0.5000\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3648 - accuracy: 0.9086 - val_loss: 2.4285 - val_accuracy: 0.5100\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3640 - accuracy: 0.9129 - val_loss: 2.4433 - val_accuracy: 0.5133\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3641 - accuracy: 0.9129 - val_loss: 2.4579 - val_accuracy: 0.4967\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3642 - accuracy: 0.9086 - val_loss: 2.4205 - val_accuracy: 0.5067\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3637 - accuracy: 0.9129 - val_loss: 2.4225 - val_accuracy: 0.5033\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3635 - accuracy: 0.9100 - val_loss: 2.4348 - val_accuracy: 0.5133\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3628 - accuracy: 0.9171 - val_loss: 2.4260 - val_accuracy: 0.5133\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3620 - accuracy: 0.9100 - val_loss: 2.4424 - val_accuracy: 0.5067\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3621 - accuracy: 0.9071 - val_loss: 2.4418 - val_accuracy: 0.5100\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3627 - accuracy: 0.9100 - val_loss: 2.4293 - val_accuracy: 0.5067\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3623 - accuracy: 0.9157 - val_loss: 2.4250 - val_accuracy: 0.5033\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3621 - accuracy: 0.9129 - val_loss: 2.4595 - val_accuracy: 0.4967\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3611 - accuracy: 0.9200 - val_loss: 2.4756 - val_accuracy: 0.5033\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3611 - accuracy: 0.9129 - val_loss: 2.4444 - val_accuracy: 0.5000\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3597 - accuracy: 0.9086 - val_loss: 2.4361 - val_accuracy: 0.5033\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3598 - accuracy: 0.9200 - val_loss: 2.4315 - val_accuracy: 0.5033\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3604 - accuracy: 0.9129 - val_loss: 2.4441 - val_accuracy: 0.5100\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3595 - accuracy: 0.9043 - val_loss: 2.4459 - val_accuracy: 0.5067\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3586 - accuracy: 0.9129 - val_loss: 2.4473 - val_accuracy: 0.5100\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3591 - accuracy: 0.9129 - val_loss: 2.4469 - val_accuracy: 0.5133\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3586 - accuracy: 0.9100 - val_loss: 2.4695 - val_accuracy: 0.5033\n",
      "Epoch 992/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 0.3579 - accuracy: 0.9171 - val_loss: 2.4477 - val_accuracy: 0.5033\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3576 - accuracy: 0.9100 - val_loss: 2.4560 - val_accuracy: 0.5067\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3575 - accuracy: 0.9143 - val_loss: 2.4631 - val_accuracy: 0.5033\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3576 - accuracy: 0.9157 - val_loss: 2.4502 - val_accuracy: 0.5033\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3568 - accuracy: 0.9157 - val_loss: 2.4703 - val_accuracy: 0.5067\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3575 - accuracy: 0.9071 - val_loss: 2.4690 - val_accuracy: 0.5067\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3556 - accuracy: 0.9171 - val_loss: 2.4617 - val_accuracy: 0.5033\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3564 - accuracy: 0.9200 - val_loss: 2.4585 - val_accuracy: 0.5067\n",
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3559 - accuracy: 0.9157 - val_loss: 2.4593 - val_accuracy: 0.5133\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3563 - accuracy: 0.9143 - val_loss: 2.4729 - val_accuracy: 0.5100\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3554 - accuracy: 0.9129 - val_loss: 2.4730 - val_accuracy: 0.4967\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3548 - accuracy: 0.9157 - val_loss: 2.4818 - val_accuracy: 0.5100\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3556 - accuracy: 0.9114 - val_loss: 2.4761 - val_accuracy: 0.5067\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3560 - accuracy: 0.9157 - val_loss: 2.4785 - val_accuracy: 0.5033\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3545 - accuracy: 0.9186 - val_loss: 2.4851 - val_accuracy: 0.5067\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3546 - accuracy: 0.9186 - val_loss: 2.4852 - val_accuracy: 0.5000\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3542 - accuracy: 0.9157 - val_loss: 2.4759 - val_accuracy: 0.5133\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3538 - accuracy: 0.9143 - val_loss: 2.4747 - val_accuracy: 0.5100\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3539 - accuracy: 0.9129 - val_loss: 2.4878 - val_accuracy: 0.5167\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3530 - accuracy: 0.9157 - val_loss: 2.4916 - val_accuracy: 0.5133\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3532 - accuracy: 0.9200 - val_loss: 2.4731 - val_accuracy: 0.5067\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3514 - accuracy: 0.9157 - val_loss: 2.4786 - val_accuracy: 0.5167\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3536 - accuracy: 0.9157 - val_loss: 2.4944 - val_accuracy: 0.5000\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3532 - accuracy: 0.9157 - val_loss: 2.4903 - val_accuracy: 0.5200\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3526 - accuracy: 0.9143 - val_loss: 2.4872 - val_accuracy: 0.5067\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3529 - accuracy: 0.9186 - val_loss: 2.5014 - val_accuracy: 0.5100\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3515 - accuracy: 0.9186 - val_loss: 2.4878 - val_accuracy: 0.4967\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3516 - accuracy: 0.9186 - val_loss: 2.5110 - val_accuracy: 0.5033\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3509 - accuracy: 0.9157 - val_loss: 2.4927 - val_accuracy: 0.5100\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3511 - accuracy: 0.9171 - val_loss: 2.5000 - val_accuracy: 0.5100\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3513 - accuracy: 0.9171 - val_loss: 2.5031 - val_accuracy: 0.5100\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3512 - accuracy: 0.9229 - val_loss: 2.5077 - val_accuracy: 0.5133\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3502 - accuracy: 0.9114 - val_loss: 2.4963 - val_accuracy: 0.5133\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3515 - accuracy: 0.9171 - val_loss: 2.4996 - val_accuracy: 0.5067\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3498 - accuracy: 0.9186 - val_loss: 2.5191 - val_accuracy: 0.5000\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3493 - accuracy: 0.9243 - val_loss: 2.5114 - val_accuracy: 0.5133\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3494 - accuracy: 0.9257 - val_loss: 2.5050 - val_accuracy: 0.5133\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3493 - accuracy: 0.9171 - val_loss: 2.5298 - val_accuracy: 0.5133\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3498 - accuracy: 0.9186 - val_loss: 2.4997 - val_accuracy: 0.5133\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3495 - accuracy: 0.9200 - val_loss: 2.5198 - val_accuracy: 0.5033\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3486 - accuracy: 0.9186 - val_loss: 2.5140 - val_accuracy: 0.5167\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3486 - accuracy: 0.9257 - val_loss: 2.5188 - val_accuracy: 0.5167\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3488 - accuracy: 0.9143 - val_loss: 2.5264 - val_accuracy: 0.5167\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3478 - accuracy: 0.9171 - val_loss: 2.5156 - val_accuracy: 0.5133\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3471 - accuracy: 0.9214 - val_loss: 2.5340 - val_accuracy: 0.5133\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3490 - accuracy: 0.9200 - val_loss: 2.5299 - val_accuracy: 0.4967\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3477 - accuracy: 0.9257 - val_loss: 2.5320 - val_accuracy: 0.5100\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3467 - accuracy: 0.9186 - val_loss: 2.5396 - val_accuracy: 0.5067\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3470 - accuracy: 0.9186 - val_loss: 2.5249 - val_accuracy: 0.5100\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3481 - accuracy: 0.9171 - val_loss: 2.5110 - val_accuracy: 0.5167\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3463 - accuracy: 0.9157 - val_loss: 2.5252 - val_accuracy: 0.5167\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3474 - accuracy: 0.9200 - val_loss: 2.5440 - val_accuracy: 0.5033\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3474 - accuracy: 0.9200 - val_loss: 2.5377 - val_accuracy: 0.4967\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3456 - accuracy: 0.9257 - val_loss: 2.5293 - val_accuracy: 0.5100\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3466 - accuracy: 0.9186 - val_loss: 2.5498 - val_accuracy: 0.5067\n",
      "Epoch 1047/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 0.3464 - accuracy: 0.9171 - val_loss: 2.5550 - val_accuracy: 0.5033\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3457 - accuracy: 0.9186 - val_loss: 2.5356 - val_accuracy: 0.5067\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 0.3457 - accuracy: 0.9200 - val_loss: 2.5437 - val_accuracy: 0.5200\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3453 - accuracy: 0.9214 - val_loss: 2.5566 - val_accuracy: 0.5067\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3447 - accuracy: 0.9200 - val_loss: 2.5520 - val_accuracy: 0.5133\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3455 - accuracy: 0.9229 - val_loss: 2.5440 - val_accuracy: 0.5100\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3445 - accuracy: 0.9200 - val_loss: 2.5604 - val_accuracy: 0.5033\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3447 - accuracy: 0.9200 - val_loss: 2.5433 - val_accuracy: 0.5133\n",
      "Epoch 1055/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3451 - accuracy: 0.9229 - val_loss: 2.5419 - val_accuracy: 0.5100\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3442 - accuracy: 0.9214 - val_loss: 2.5609 - val_accuracy: 0.5033\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3443 - accuracy: 0.9143 - val_loss: 2.5612 - val_accuracy: 0.5200\n",
      "Epoch 1058/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3435 - accuracy: 0.9243 - val_loss: 2.5523 - val_accuracy: 0.5133\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3429 - accuracy: 0.9214 - val_loss: 2.5616 - val_accuracy: 0.5133\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3430 - accuracy: 0.9157 - val_loss: 2.5429 - val_accuracy: 0.5167\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3423 - accuracy: 0.9229 - val_loss: 2.5879 - val_accuracy: 0.4967\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3431 - accuracy: 0.9243 - val_loss: 2.5496 - val_accuracy: 0.5100\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3425 - accuracy: 0.9243 - val_loss: 2.5563 - val_accuracy: 0.5133\n",
      "Epoch 1064/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3422 - accuracy: 0.9171 - val_loss: 2.5540 - val_accuracy: 0.5200\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3424 - accuracy: 0.9257 - val_loss: 2.5729 - val_accuracy: 0.5067\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3417 - accuracy: 0.9243 - val_loss: 2.5570 - val_accuracy: 0.5133\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3422 - accuracy: 0.9229 - val_loss: 2.5653 - val_accuracy: 0.5100\n",
      "Epoch 1068/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3418 - accuracy: 0.9214 - val_loss: 2.5639 - val_accuracy: 0.5033\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3411 - accuracy: 0.9229 - val_loss: 2.5760 - val_accuracy: 0.4933\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3413 - accuracy: 0.9271 - val_loss: 2.5732 - val_accuracy: 0.5133\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3414 - accuracy: 0.9271 - val_loss: 2.5744 - val_accuracy: 0.5067\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3410 - accuracy: 0.9214 - val_loss: 2.5531 - val_accuracy: 0.5133\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3410 - accuracy: 0.9200 - val_loss: 2.5854 - val_accuracy: 0.5100\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3406 - accuracy: 0.9300 - val_loss: 2.5710 - val_accuracy: 0.5000\n",
      "Epoch 1075/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3403 - accuracy: 0.9186 - val_loss: 2.5879 - val_accuracy: 0.5067\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3405 - accuracy: 0.9200 - val_loss: 2.5900 - val_accuracy: 0.5133\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3405 - accuracy: 0.9286 - val_loss: 2.5720 - val_accuracy: 0.5167\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3400 - accuracy: 0.9271 - val_loss: 2.5823 - val_accuracy: 0.5067\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3395 - accuracy: 0.9200 - val_loss: 2.5799 - val_accuracy: 0.5067\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3390 - accuracy: 0.9257 - val_loss: 2.5882 - val_accuracy: 0.5067\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.3389 - accuracy: 0.9257 - val_loss: 2.6088 - val_accuracy: 0.5033\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3388 - accuracy: 0.9257 - val_loss: 2.5853 - val_accuracy: 0.5133\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3382 - accuracy: 0.9257 - val_loss: 2.5993 - val_accuracy: 0.5067\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3391 - accuracy: 0.9271 - val_loss: 2.5864 - val_accuracy: 0.5033\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3385 - accuracy: 0.9243 - val_loss: 2.5882 - val_accuracy: 0.5067\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3396 - accuracy: 0.9229 - val_loss: 2.5917 - val_accuracy: 0.5200\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3383 - accuracy: 0.9243 - val_loss: 2.5824 - val_accuracy: 0.5133\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3381 - accuracy: 0.9286 - val_loss: 2.6192 - val_accuracy: 0.5000\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3385 - accuracy: 0.9257 - val_loss: 2.5882 - val_accuracy: 0.5000\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3373 - accuracy: 0.9229 - val_loss: 2.5869 - val_accuracy: 0.5100\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3363 - accuracy: 0.9300 - val_loss: 2.6222 - val_accuracy: 0.5033\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3378 - accuracy: 0.9286 - val_loss: 2.5947 - val_accuracy: 0.5033\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3367 - accuracy: 0.9271 - val_loss: 2.5891 - val_accuracy: 0.5133\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3351 - accuracy: 0.9229 - val_loss: 2.6038 - val_accuracy: 0.5033\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3369 - accuracy: 0.9271 - val_loss: 2.6034 - val_accuracy: 0.5100\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3365 - accuracy: 0.9229 - val_loss: 2.6172 - val_accuracy: 0.5133\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3371 - accuracy: 0.9243 - val_loss: 2.6056 - val_accuracy: 0.5067\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3367 - accuracy: 0.9243 - val_loss: 2.6075 - val_accuracy: 0.5000\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3365 - accuracy: 0.9243 - val_loss: 2.6237 - val_accuracy: 0.5033\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3362 - accuracy: 0.9300 - val_loss: 2.6214 - val_accuracy: 0.4967\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3358 - accuracy: 0.9257 - val_loss: 2.6175 - val_accuracy: 0.5100\n",
      "Epoch 1102/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 0.3350 - accuracy: 0.9271 - val_loss: 2.6115 - val_accuracy: 0.5033\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3352 - accuracy: 0.9229 - val_loss: 2.6144 - val_accuracy: 0.5100\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3347 - accuracy: 0.9286 - val_loss: 2.6232 - val_accuracy: 0.5000\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3342 - accuracy: 0.9300 - val_loss: 2.6413 - val_accuracy: 0.5033\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3347 - accuracy: 0.9300 - val_loss: 2.6162 - val_accuracy: 0.5067\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3345 - accuracy: 0.9271 - val_loss: 2.6176 - val_accuracy: 0.5067\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.3339 - accuracy: 0.9329 - val_loss: 2.6401 - val_accuracy: 0.5000\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3346 - accuracy: 0.9286 - val_loss: 2.6253 - val_accuracy: 0.5100\n",
      "Epoch 1110/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3335 - accuracy: 0.9271 - val_loss: 2.6417 - val_accuracy: 0.5033\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3336 - accuracy: 0.9329 - val_loss: 2.6278 - val_accuracy: 0.5133\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3328 - accuracy: 0.9286 - val_loss: 2.6414 - val_accuracy: 0.4967\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3341 - accuracy: 0.9286 - val_loss: 2.6336 - val_accuracy: 0.4967\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3338 - accuracy: 0.9286 - val_loss: 2.6302 - val_accuracy: 0.5000\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3334 - accuracy: 0.9271 - val_loss: 2.6305 - val_accuracy: 0.5100\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3331 - accuracy: 0.9300 - val_loss: 2.6191 - val_accuracy: 0.5067\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3326 - accuracy: 0.9314 - val_loss: 2.6312 - val_accuracy: 0.5100\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3338 - accuracy: 0.9300 - val_loss: 2.6395 - val_accuracy: 0.5133\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3329 - accuracy: 0.9271 - val_loss: 2.6407 - val_accuracy: 0.5133\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3320 - accuracy: 0.9200 - val_loss: 2.6497 - val_accuracy: 0.5033\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3322 - accuracy: 0.9271 - val_loss: 2.6541 - val_accuracy: 0.5100\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3314 - accuracy: 0.9343 - val_loss: 2.6414 - val_accuracy: 0.5100\n",
      "Epoch 1123/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3308 - accuracy: 0.9286 - val_loss: 2.6560 - val_accuracy: 0.5133\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3320 - accuracy: 0.9314 - val_loss: 2.6621 - val_accuracy: 0.5000\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3313 - accuracy: 0.9329 - val_loss: 2.6674 - val_accuracy: 0.5000\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3316 - accuracy: 0.9329 - val_loss: 2.6667 - val_accuracy: 0.5033\n",
      "Epoch 1127/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3312 - accuracy: 0.9343 - val_loss: 2.6577 - val_accuracy: 0.5067\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3305 - accuracy: 0.9329 - val_loss: 2.6731 - val_accuracy: 0.5033\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3313 - accuracy: 0.9329 - val_loss: 2.6467 - val_accuracy: 0.5167\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3295 - accuracy: 0.9314 - val_loss: 2.6455 - val_accuracy: 0.5100\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3296 - accuracy: 0.9257 - val_loss: 2.6466 - val_accuracy: 0.5100\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3298 - accuracy: 0.9300 - val_loss: 2.6703 - val_accuracy: 0.5033\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3304 - accuracy: 0.9357 - val_loss: 2.6549 - val_accuracy: 0.5133\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3301 - accuracy: 0.9329 - val_loss: 2.6761 - val_accuracy: 0.5100\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3306 - accuracy: 0.9314 - val_loss: 2.6753 - val_accuracy: 0.5100\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3293 - accuracy: 0.9357 - val_loss: 2.6658 - val_accuracy: 0.4967\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3297 - accuracy: 0.9300 - val_loss: 2.6771 - val_accuracy: 0.5000\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3294 - accuracy: 0.9314 - val_loss: 2.6703 - val_accuracy: 0.5033\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3283 - accuracy: 0.9371 - val_loss: 2.6835 - val_accuracy: 0.5100\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3286 - accuracy: 0.9343 - val_loss: 2.6611 - val_accuracy: 0.5100\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3282 - accuracy: 0.9314 - val_loss: 2.6672 - val_accuracy: 0.5100\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3287 - accuracy: 0.9343 - val_loss: 2.6838 - val_accuracy: 0.5067\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3282 - accuracy: 0.9300 - val_loss: 2.6827 - val_accuracy: 0.5100\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3280 - accuracy: 0.9286 - val_loss: 2.6850 - val_accuracy: 0.5033\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3273 - accuracy: 0.9300 - val_loss: 2.6875 - val_accuracy: 0.5033\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3282 - accuracy: 0.9286 - val_loss: 2.7104 - val_accuracy: 0.5067\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3272 - accuracy: 0.9300 - val_loss: 2.6786 - val_accuracy: 0.5100\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 0.3272 - accuracy: 0.9371 - val_loss: 2.7121 - val_accuracy: 0.5067\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3280 - accuracy: 0.9300 - val_loss: 2.6943 - val_accuracy: 0.5033\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3280 - accuracy: 0.9314 - val_loss: 2.6946 - val_accuracy: 0.5000\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3269 - accuracy: 0.9300 - val_loss: 2.6844 - val_accuracy: 0.5033\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3266 - accuracy: 0.9300 - val_loss: 2.7068 - val_accuracy: 0.5033\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3269 - accuracy: 0.9329 - val_loss: 2.6859 - val_accuracy: 0.5033\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3258 - accuracy: 0.9343 - val_loss: 2.7052 - val_accuracy: 0.5000\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3265 - accuracy: 0.9314 - val_loss: 2.6859 - val_accuracy: 0.5000\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3262 - accuracy: 0.9357 - val_loss: 2.7012 - val_accuracy: 0.5067\n",
      "Epoch 1157/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 126us/step - loss: 0.3254 - accuracy: 0.9314 - val_loss: 2.7000 - val_accuracy: 0.5000\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3265 - accuracy: 0.9414 - val_loss: 2.6900 - val_accuracy: 0.5033\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3258 - accuracy: 0.9357 - val_loss: 2.7156 - val_accuracy: 0.5033\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3257 - accuracy: 0.9371 - val_loss: 2.7129 - val_accuracy: 0.5100\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3252 - accuracy: 0.9371 - val_loss: 2.7030 - val_accuracy: 0.5067\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3251 - accuracy: 0.9400 - val_loss: 2.7133 - val_accuracy: 0.5100\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3238 - accuracy: 0.9371 - val_loss: 2.7281 - val_accuracy: 0.4933\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3252 - accuracy: 0.9329 - val_loss: 2.7172 - val_accuracy: 0.5033\n",
      "Epoch 1165/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3246 - accuracy: 0.9400 - val_loss: 2.7172 - val_accuracy: 0.5067\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3258 - accuracy: 0.9371 - val_loss: 2.7022 - val_accuracy: 0.5033\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3245 - accuracy: 0.9314 - val_loss: 2.7212 - val_accuracy: 0.5000\n",
      "Epoch 1168/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3243 - accuracy: 0.9343 - val_loss: 2.6955 - val_accuracy: 0.5000\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3237 - accuracy: 0.9300 - val_loss: 2.7204 - val_accuracy: 0.5067\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3237 - accuracy: 0.9314 - val_loss: 2.7117 - val_accuracy: 0.5000\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3251 - accuracy: 0.9400 - val_loss: 2.7292 - val_accuracy: 0.5033\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3234 - accuracy: 0.9371 - val_loss: 2.7213 - val_accuracy: 0.5000\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3232 - accuracy: 0.9414 - val_loss: 2.7230 - val_accuracy: 0.5067\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3227 - accuracy: 0.9386 - val_loss: 2.7338 - val_accuracy: 0.5100\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3231 - accuracy: 0.9400 - val_loss: 2.7350 - val_accuracy: 0.5067\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3228 - accuracy: 0.9400 - val_loss: 2.7417 - val_accuracy: 0.5100\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3225 - accuracy: 0.9343 - val_loss: 2.7307 - val_accuracy: 0.5033\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3231 - accuracy: 0.9314 - val_loss: 2.7170 - val_accuracy: 0.5033\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3221 - accuracy: 0.9386 - val_loss: 2.7159 - val_accuracy: 0.5000\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3222 - accuracy: 0.9371 - val_loss: 2.7340 - val_accuracy: 0.5033\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3222 - accuracy: 0.9343 - val_loss: 2.7380 - val_accuracy: 0.5033\n",
      "Epoch 1182/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3217 - accuracy: 0.9343 - val_loss: 2.7301 - val_accuracy: 0.5067\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3220 - accuracy: 0.9357 - val_loss: 2.7500 - val_accuracy: 0.5033\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3214 - accuracy: 0.9343 - val_loss: 2.7547 - val_accuracy: 0.5000\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3215 - accuracy: 0.9386 - val_loss: 2.7545 - val_accuracy: 0.5100\n",
      "Epoch 1186/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3218 - accuracy: 0.9357 - val_loss: 2.7327 - val_accuracy: 0.5033\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3212 - accuracy: 0.9386 - val_loss: 2.7309 - val_accuracy: 0.5033\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.3214 - accuracy: 0.9329 - val_loss: 2.7495 - val_accuracy: 0.5100\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3212 - accuracy: 0.9371 - val_loss: 2.7529 - val_accuracy: 0.5033\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3207 - accuracy: 0.9400 - val_loss: 2.7383 - val_accuracy: 0.5000\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3202 - accuracy: 0.9414 - val_loss: 2.7443 - val_accuracy: 0.5000\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3190 - accuracy: 0.9371 - val_loss: 2.7645 - val_accuracy: 0.5067\n",
      "Epoch 1193/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3204 - accuracy: 0.9386 - val_loss: 2.7586 - val_accuracy: 0.5067\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3205 - accuracy: 0.9343 - val_loss: 2.7409 - val_accuracy: 0.5000\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3195 - accuracy: 0.9371 - val_loss: 2.7662 - val_accuracy: 0.5067\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3204 - accuracy: 0.9371 - val_loss: 2.7588 - val_accuracy: 0.5033\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3194 - accuracy: 0.9314 - val_loss: 2.7699 - val_accuracy: 0.5033\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3190 - accuracy: 0.9400 - val_loss: 2.7773 - val_accuracy: 0.5000\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3200 - accuracy: 0.9386 - val_loss: 2.7630 - val_accuracy: 0.5067\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3187 - accuracy: 0.9443 - val_loss: 2.7671 - val_accuracy: 0.5033\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3199 - accuracy: 0.9386 - val_loss: 2.7605 - val_accuracy: 0.5033\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3185 - accuracy: 0.9314 - val_loss: 2.7738 - val_accuracy: 0.5100\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3186 - accuracy: 0.9371 - val_loss: 2.7609 - val_accuracy: 0.5000\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3180 - accuracy: 0.9357 - val_loss: 2.7574 - val_accuracy: 0.5133\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3185 - accuracy: 0.9371 - val_loss: 2.7627 - val_accuracy: 0.5033\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3184 - accuracy: 0.9357 - val_loss: 2.7821 - val_accuracy: 0.5033\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3181 - accuracy: 0.9386 - val_loss: 2.7757 - val_accuracy: 0.5033\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3179 - accuracy: 0.9371 - val_loss: 2.7735 - val_accuracy: 0.5000\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3165 - accuracy: 0.9386 - val_loss: 2.7895 - val_accuracy: 0.5033\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3178 - accuracy: 0.9386 - val_loss: 2.7814 - val_accuracy: 0.5000\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3184 - accuracy: 0.9386 - val_loss: 2.7771 - val_accuracy: 0.5033\n",
      "Epoch 1212/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 0.3180 - accuracy: 0.9414 - val_loss: 2.7858 - val_accuracy: 0.5000\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3167 - accuracy: 0.9386 - val_loss: 2.7966 - val_accuracy: 0.4900\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3169 - accuracy: 0.9400 - val_loss: 2.7829 - val_accuracy: 0.5000\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3167 - accuracy: 0.9486 - val_loss: 2.7889 - val_accuracy: 0.5033\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3164 - accuracy: 0.9386 - val_loss: 2.7840 - val_accuracy: 0.5000\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3167 - accuracy: 0.9400 - val_loss: 2.7818 - val_accuracy: 0.4933\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3168 - accuracy: 0.9429 - val_loss: 2.7800 - val_accuracy: 0.5000\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3159 - accuracy: 0.9400 - val_loss: 2.7852 - val_accuracy: 0.5033\n",
      "Epoch 1220/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3170 - accuracy: 0.9386 - val_loss: 2.7788 - val_accuracy: 0.5000\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3156 - accuracy: 0.9371 - val_loss: 2.7810 - val_accuracy: 0.4967\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3162 - accuracy: 0.9429 - val_loss: 2.7860 - val_accuracy: 0.5033\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3155 - accuracy: 0.9457 - val_loss: 2.7889 - val_accuracy: 0.4967\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.3149 - accuracy: 0.9414 - val_loss: 2.7895 - val_accuracy: 0.4967\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3158 - accuracy: 0.9371 - val_loss: 2.7971 - val_accuracy: 0.5000\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3155 - accuracy: 0.9357 - val_loss: 2.7915 - val_accuracy: 0.4933\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3152 - accuracy: 0.9357 - val_loss: 2.7928 - val_accuracy: 0.5033\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.3142 - accuracy: 0.9457 - val_loss: 2.8206 - val_accuracy: 0.5067\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3148 - accuracy: 0.9386 - val_loss: 2.8092 - val_accuracy: 0.5033\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3144 - accuracy: 0.9414 - val_loss: 2.8031 - val_accuracy: 0.5000\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3139 - accuracy: 0.9429 - val_loss: 2.8299 - val_accuracy: 0.5100\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3150 - accuracy: 0.9400 - val_loss: 2.8050 - val_accuracy: 0.5033\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3141 - accuracy: 0.9386 - val_loss: 2.8115 - val_accuracy: 0.5000\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3131 - accuracy: 0.9443 - val_loss: 2.8196 - val_accuracy: 0.5033\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3124 - accuracy: 0.9400 - val_loss: 2.7803 - val_accuracy: 0.5100\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3141 - accuracy: 0.9429 - val_loss: 2.8162 - val_accuracy: 0.5033\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3139 - accuracy: 0.9443 - val_loss: 2.8118 - val_accuracy: 0.4967\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3133 - accuracy: 0.9429 - val_loss: 2.8348 - val_accuracy: 0.5033\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.3134 - accuracy: 0.9429 - val_loss: 2.8215 - val_accuracy: 0.5000\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.3133 - accuracy: 0.9443 - val_loss: 2.8197 - val_accuracy: 0.5033\n",
      "Epoch 1241/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3131 - accuracy: 0.9457 - val_loss: 2.8190 - val_accuracy: 0.5067\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.3123 - accuracy: 0.9471 - val_loss: 2.8185 - val_accuracy: 0.5100\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 0.3117 - accuracy: 0.9429 - val_loss: 2.8402 - val_accuracy: 0.5033\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.3123 - accuracy: 0.9414 - val_loss: 2.8168 - val_accuracy: 0.5000\n",
      "Epoch 1245/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3123 - accuracy: 0.9400 - val_loss: 2.8401 - val_accuracy: 0.5067\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3125 - accuracy: 0.9443 - val_loss: 2.8312 - val_accuracy: 0.5000\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3103 - accuracy: 0.9443 - val_loss: 2.8385 - val_accuracy: 0.5000\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 0.3123 - accuracy: 0.9429 - val_loss: 2.8430 - val_accuracy: 0.5067\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 0.3108 - accuracy: 0.9414 - val_loss: 2.8443 - val_accuracy: 0.5033\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.3120 - accuracy: 0.9371 - val_loss: 2.8303 - val_accuracy: 0.4967\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3117 - accuracy: 0.9371 - val_loss: 2.8326 - val_accuracy: 0.5033\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3112 - accuracy: 0.9414 - val_loss: 2.8337 - val_accuracy: 0.5033\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3115 - accuracy: 0.9414 - val_loss: 2.8570 - val_accuracy: 0.5133\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3111 - accuracy: 0.9386 - val_loss: 2.8406 - val_accuracy: 0.5000\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3098 - accuracy: 0.9443 - val_loss: 2.8316 - val_accuracy: 0.4900\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3106 - accuracy: 0.9443 - val_loss: 2.8419 - val_accuracy: 0.4967\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3111 - accuracy: 0.9429 - val_loss: 2.8436 - val_accuracy: 0.5000\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3103 - accuracy: 0.9429 - val_loss: 2.8299 - val_accuracy: 0.5000\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3099 - accuracy: 0.9443 - val_loss: 2.8303 - val_accuracy: 0.5033\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.3097 - accuracy: 0.9414 - val_loss: 2.8538 - val_accuracy: 0.5067\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3097 - accuracy: 0.9429 - val_loss: 2.8434 - val_accuracy: 0.5033\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3096 - accuracy: 0.9414 - val_loss: 2.8705 - val_accuracy: 0.5033\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3095 - accuracy: 0.9429 - val_loss: 2.8591 - val_accuracy: 0.5000\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 0.3098 - accuracy: 0.9429 - val_loss: 2.8726 - val_accuracy: 0.5033\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3093 - accuracy: 0.9429 - val_loss: 2.8589 - val_accuracy: 0.5100\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3097 - accuracy: 0.9429 - val_loss: 2.8873 - val_accuracy: 0.5033\n",
      "Epoch 1267/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 120us/step - loss: 0.3101 - accuracy: 0.9429 - val_loss: 2.8552 - val_accuracy: 0.5033\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3095 - accuracy: 0.9429 - val_loss: 2.8536 - val_accuracy: 0.5033\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3092 - accuracy: 0.9443 - val_loss: 2.8520 - val_accuracy: 0.5033\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 0.3082 - accuracy: 0.9457 - val_loss: 2.8684 - val_accuracy: 0.5167\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3087 - accuracy: 0.9429 - val_loss: 2.8736 - val_accuracy: 0.5000\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3083 - accuracy: 0.9486 - val_loss: 2.8565 - val_accuracy: 0.5000\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.3083 - accuracy: 0.9457 - val_loss: 2.8523 - val_accuracy: 0.5000\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.3084 - accuracy: 0.9443 - val_loss: 2.8660 - val_accuracy: 0.5067\n",
      "Epoch 1275/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3079 - accuracy: 0.9414 - val_loss: 2.8410 - val_accuracy: 0.5000\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3083 - accuracy: 0.9429 - val_loss: 2.8867 - val_accuracy: 0.5067\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3090 - accuracy: 0.9457 - val_loss: 2.8741 - val_accuracy: 0.5033\n",
      "Epoch 1278/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.3077 - accuracy: 0.9429 - val_loss: 2.8751 - val_accuracy: 0.5100\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3069 - accuracy: 0.9429 - val_loss: 2.8721 - val_accuracy: 0.5067\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3078 - accuracy: 0.9443 - val_loss: 2.8741 - val_accuracy: 0.5000\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 0.3073 - accuracy: 0.9414 - val_loss: 2.8879 - val_accuracy: 0.5067\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3071 - accuracy: 0.9429 - val_loss: 2.8871 - val_accuracy: 0.5033\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.3071 - accuracy: 0.9457 - val_loss: 2.8686 - val_accuracy: 0.4967\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3070 - accuracy: 0.9414 - val_loss: 2.8796 - val_accuracy: 0.5067\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3065 - accuracy: 0.9457 - val_loss: 2.8906 - val_accuracy: 0.5033\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3068 - accuracy: 0.9429 - val_loss: 2.8705 - val_accuracy: 0.5000\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3064 - accuracy: 0.9443 - val_loss: 2.9093 - val_accuracy: 0.5100\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3069 - accuracy: 0.9443 - val_loss: 2.8833 - val_accuracy: 0.5000\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3063 - accuracy: 0.9443 - val_loss: 2.8818 - val_accuracy: 0.5033\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3058 - accuracy: 0.9471 - val_loss: 2.8823 - val_accuracy: 0.5033\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3060 - accuracy: 0.9414 - val_loss: 2.8936 - val_accuracy: 0.5033\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3057 - accuracy: 0.9500 - val_loss: 2.8946 - val_accuracy: 0.5000\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3054 - accuracy: 0.9443 - val_loss: 2.8784 - val_accuracy: 0.5000\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3053 - accuracy: 0.9429 - val_loss: 2.8972 - val_accuracy: 0.5067\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3062 - accuracy: 0.9400 - val_loss: 2.9002 - val_accuracy: 0.5133\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3048 - accuracy: 0.9443 - val_loss: 2.9209 - val_accuracy: 0.5100\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3065 - accuracy: 0.9443 - val_loss: 2.9047 - val_accuracy: 0.5067\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3043 - accuracy: 0.9457 - val_loss: 2.8990 - val_accuracy: 0.5100\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3049 - accuracy: 0.9443 - val_loss: 2.8893 - val_accuracy: 0.5000\n",
      "Epoch 1300/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3043 - accuracy: 0.9471 - val_loss: 2.8959 - val_accuracy: 0.5033\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 0.3046 - accuracy: 0.9429 - val_loss: 2.9118 - val_accuracy: 0.4967\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3038 - accuracy: 0.9457 - val_loss: 2.9130 - val_accuracy: 0.5067\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3042 - accuracy: 0.9471 - val_loss: 2.9161 - val_accuracy: 0.5167\n",
      "Epoch 1304/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3041 - accuracy: 0.9457 - val_loss: 2.9153 - val_accuracy: 0.5033\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3036 - accuracy: 0.9414 - val_loss: 2.9068 - val_accuracy: 0.5067\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3035 - accuracy: 0.9443 - val_loss: 2.9060 - val_accuracy: 0.5067\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3040 - accuracy: 0.9471 - val_loss: 2.9144 - val_accuracy: 0.5100\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3033 - accuracy: 0.9386 - val_loss: 2.8988 - val_accuracy: 0.5067\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3038 - accuracy: 0.9443 - val_loss: 2.9063 - val_accuracy: 0.5033\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3038 - accuracy: 0.9471 - val_loss: 2.9233 - val_accuracy: 0.5000\n",
      "Epoch 1311/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3029 - accuracy: 0.9471 - val_loss: 2.9144 - val_accuracy: 0.5033\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3029 - accuracy: 0.9400 - val_loss: 2.9109 - val_accuracy: 0.5000\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3028 - accuracy: 0.9443 - val_loss: 2.9080 - val_accuracy: 0.5067\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3027 - accuracy: 0.9429 - val_loss: 2.9228 - val_accuracy: 0.5067\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3023 - accuracy: 0.9457 - val_loss: 2.9138 - val_accuracy: 0.5067\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3033 - accuracy: 0.9471 - val_loss: 2.9359 - val_accuracy: 0.5033\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.3017 - accuracy: 0.9443 - val_loss: 2.9230 - val_accuracy: 0.5033\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.3030 - accuracy: 0.9443 - val_loss: 2.9200 - val_accuracy: 0.5000\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.3024 - accuracy: 0.9443 - val_loss: 2.9432 - val_accuracy: 0.5000\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3013 - accuracy: 0.9443 - val_loss: 2.9339 - val_accuracy: 0.5033\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3019 - accuracy: 0.9443 - val_loss: 2.9375 - val_accuracy: 0.5000\n",
      "Epoch 1322/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.3019 - accuracy: 0.9471 - val_loss: 2.9260 - val_accuracy: 0.5033\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3017 - accuracy: 0.9486 - val_loss: 2.9315 - val_accuracy: 0.5000\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3011 - accuracy: 0.9414 - val_loss: 2.9373 - val_accuracy: 0.5033\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3016 - accuracy: 0.9486 - val_loss: 2.9218 - val_accuracy: 0.5000\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3008 - accuracy: 0.9500 - val_loss: 2.9538 - val_accuracy: 0.5067\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3011 - accuracy: 0.9457 - val_loss: 2.9483 - val_accuracy: 0.5067\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3015 - accuracy: 0.9429 - val_loss: 2.9356 - val_accuracy: 0.5100\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3006 - accuracy: 0.9471 - val_loss: 2.9270 - val_accuracy: 0.5033\n",
      "Epoch 1330/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3005 - accuracy: 0.9471 - val_loss: 2.9491 - val_accuracy: 0.5000\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3009 - accuracy: 0.9443 - val_loss: 2.9303 - val_accuracy: 0.5067\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3019 - accuracy: 0.9443 - val_loss: 2.9510 - val_accuracy: 0.4967\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3000 - accuracy: 0.9429 - val_loss: 2.9409 - val_accuracy: 0.5067\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2998 - accuracy: 0.9443 - val_loss: 2.9376 - val_accuracy: 0.5067\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.2985 - accuracy: 0.9471 - val_loss: 2.9525 - val_accuracy: 0.5000\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.2975 - accuracy: 0.9443 - val_loss: 2.9569 - val_accuracy: 0.5000\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.2981 - accuracy: 0.9486 - val_loss: 2.9510 - val_accuracy: 0.5067\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2970 - accuracy: 0.9443 - val_loss: 2.9621 - val_accuracy: 0.5033\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.2969 - accuracy: 0.9500 - val_loss: 2.9604 - val_accuracy: 0.5133\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.2968 - accuracy: 0.9443 - val_loss: 2.9459 - val_accuracy: 0.5033\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2961 - accuracy: 0.9414 - val_loss: 2.9720 - val_accuracy: 0.5000\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2966 - accuracy: 0.9429 - val_loss: 2.9715 - val_accuracy: 0.5033\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2954 - accuracy: 0.9443 - val_loss: 2.9752 - val_accuracy: 0.5067\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2963 - accuracy: 0.9486 - val_loss: 2.9724 - val_accuracy: 0.5000\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2958 - accuracy: 0.9500 - val_loss: 2.9697 - val_accuracy: 0.5133\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2956 - accuracy: 0.9457 - val_loss: 2.9798 - val_accuracy: 0.5000\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2954 - accuracy: 0.9457 - val_loss: 2.9558 - val_accuracy: 0.5067\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2963 - accuracy: 0.9486 - val_loss: 2.9963 - val_accuracy: 0.5033\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2947 - accuracy: 0.9486 - val_loss: 2.9730 - val_accuracy: 0.5067\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2948 - accuracy: 0.9414 - val_loss: 2.9768 - val_accuracy: 0.5067\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2952 - accuracy: 0.9471 - val_loss: 2.9774 - val_accuracy: 0.5033\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2938 - accuracy: 0.9457 - val_loss: 2.9696 - val_accuracy: 0.5100\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2949 - accuracy: 0.9486 - val_loss: 2.9633 - val_accuracy: 0.5100\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2949 - accuracy: 0.9471 - val_loss: 2.9858 - val_accuracy: 0.5100\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2949 - accuracy: 0.9443 - val_loss: 3.0072 - val_accuracy: 0.5133\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2937 - accuracy: 0.9471 - val_loss: 2.9624 - val_accuracy: 0.5033\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2938 - accuracy: 0.9457 - val_loss: 2.9905 - val_accuracy: 0.5100\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2941 - accuracy: 0.9471 - val_loss: 2.9750 - val_accuracy: 0.5033\n",
      "Epoch 1359/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2937 - accuracy: 0.9457 - val_loss: 2.9968 - val_accuracy: 0.5067\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 0.2936 - accuracy: 0.9500 - val_loss: 2.9812 - val_accuracy: 0.5000\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2933 - accuracy: 0.9486 - val_loss: 3.0010 - val_accuracy: 0.5033\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2932 - accuracy: 0.9471 - val_loss: 2.9981 - val_accuracy: 0.5000\n",
      "Epoch 1363/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2928 - accuracy: 0.9471 - val_loss: 2.9831 - val_accuracy: 0.5067\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2926 - accuracy: 0.9414 - val_loss: 2.9969 - val_accuracy: 0.5033\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2932 - accuracy: 0.9500 - val_loss: 3.0147 - val_accuracy: 0.5067\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2926 - accuracy: 0.9457 - val_loss: 3.0086 - val_accuracy: 0.5033\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2923 - accuracy: 0.9471 - val_loss: 2.9869 - val_accuracy: 0.5067\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2922 - accuracy: 0.9471 - val_loss: 2.9999 - val_accuracy: 0.5100\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2914 - accuracy: 0.9457 - val_loss: 3.0013 - val_accuracy: 0.4967\n",
      "Epoch 1370/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2920 - accuracy: 0.9457 - val_loss: 3.0116 - val_accuracy: 0.5067\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2917 - accuracy: 0.9514 - val_loss: 2.9863 - val_accuracy: 0.4967\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2915 - accuracy: 0.9443 - val_loss: 3.0147 - val_accuracy: 0.5067\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2920 - accuracy: 0.9500 - val_loss: 2.9868 - val_accuracy: 0.4967\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2916 - accuracy: 0.9486 - val_loss: 3.0160 - val_accuracy: 0.5033\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2909 - accuracy: 0.9514 - val_loss: 3.0053 - val_accuracy: 0.4933\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2908 - accuracy: 0.9471 - val_loss: 3.0081 - val_accuracy: 0.5133\n",
      "Epoch 1377/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 0.2911 - accuracy: 0.9500 - val_loss: 3.0130 - val_accuracy: 0.4967\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2911 - accuracy: 0.9500 - val_loss: 2.9988 - val_accuracy: 0.5100\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2903 - accuracy: 0.9529 - val_loss: 3.0298 - val_accuracy: 0.5033\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.2903 - accuracy: 0.9486 - val_loss: 3.0304 - val_accuracy: 0.4967\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2904 - accuracy: 0.9486 - val_loss: 3.0136 - val_accuracy: 0.5100\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2908 - accuracy: 0.9486 - val_loss: 3.0108 - val_accuracy: 0.4967\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2901 - accuracy: 0.9486 - val_loss: 3.0340 - val_accuracy: 0.5033\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2895 - accuracy: 0.9471 - val_loss: 3.0553 - val_accuracy: 0.4933\n",
      "Epoch 1385/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2896 - accuracy: 0.9471 - val_loss: 3.0239 - val_accuracy: 0.4967\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2896 - accuracy: 0.9471 - val_loss: 3.0274 - val_accuracy: 0.5100\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2891 - accuracy: 0.9471 - val_loss: 3.0419 - val_accuracy: 0.4933\n",
      "Epoch 1388/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2899 - accuracy: 0.9486 - val_loss: 3.0225 - val_accuracy: 0.5100\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2898 - accuracy: 0.9471 - val_loss: 3.0280 - val_accuracy: 0.5067\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2893 - accuracy: 0.9514 - val_loss: 3.0394 - val_accuracy: 0.5133\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2887 - accuracy: 0.9486 - val_loss: 3.0307 - val_accuracy: 0.5067\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2889 - accuracy: 0.9500 - val_loss: 3.0348 - val_accuracy: 0.4933\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2888 - accuracy: 0.9500 - val_loss: 3.0445 - val_accuracy: 0.4967\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2885 - accuracy: 0.9471 - val_loss: 3.0311 - val_accuracy: 0.5000\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2885 - accuracy: 0.9514 - val_loss: 3.0380 - val_accuracy: 0.5000\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2887 - accuracy: 0.9414 - val_loss: 3.0381 - val_accuracy: 0.4933\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2873 - accuracy: 0.9514 - val_loss: 3.0691 - val_accuracy: 0.4967\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2893 - accuracy: 0.9471 - val_loss: 3.0506 - val_accuracy: 0.4967\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2891 - accuracy: 0.9500 - val_loss: 3.0409 - val_accuracy: 0.5000\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2884 - accuracy: 0.9486 - val_loss: 3.0283 - val_accuracy: 0.5067\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2877 - accuracy: 0.9514 - val_loss: 3.0260 - val_accuracy: 0.5067\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2878 - accuracy: 0.9529 - val_loss: 3.0449 - val_accuracy: 0.4967\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2871 - accuracy: 0.9514 - val_loss: 3.0586 - val_accuracy: 0.4967\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2870 - accuracy: 0.9529 - val_loss: 3.0492 - val_accuracy: 0.4967\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2875 - accuracy: 0.9529 - val_loss: 3.0373 - val_accuracy: 0.5067\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2871 - accuracy: 0.9471 - val_loss: 3.0518 - val_accuracy: 0.5100\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2869 - accuracy: 0.9514 - val_loss: 3.0536 - val_accuracy: 0.5100\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2871 - accuracy: 0.9471 - val_loss: 3.0445 - val_accuracy: 0.4967\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2866 - accuracy: 0.9514 - val_loss: 3.0506 - val_accuracy: 0.5067\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2866 - accuracy: 0.9500 - val_loss: 3.0631 - val_accuracy: 0.5100\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2861 - accuracy: 0.9500 - val_loss: 3.0765 - val_accuracy: 0.5033\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2860 - accuracy: 0.9486 - val_loss: 3.0686 - val_accuracy: 0.5000\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2862 - accuracy: 0.9486 - val_loss: 3.0667 - val_accuracy: 0.4967\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2861 - accuracy: 0.9500 - val_loss: 3.0667 - val_accuracy: 0.5000\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2862 - accuracy: 0.9529 - val_loss: 3.0802 - val_accuracy: 0.5000\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2862 - accuracy: 0.9514 - val_loss: 3.0689 - val_accuracy: 0.4967\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2861 - accuracy: 0.9529 - val_loss: 3.0712 - val_accuracy: 0.4967\n",
      "Epoch 1418/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2855 - accuracy: 0.9443 - val_loss: 3.0892 - val_accuracy: 0.4967\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2856 - accuracy: 0.9543 - val_loss: 3.0663 - val_accuracy: 0.4900\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2864 - accuracy: 0.9514 - val_loss: 3.0958 - val_accuracy: 0.4967\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.2849 - accuracy: 0.9514 - val_loss: 3.1051 - val_accuracy: 0.4967\n",
      "Epoch 1422/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2853 - accuracy: 0.9486 - val_loss: 3.0620 - val_accuracy: 0.5033\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2849 - accuracy: 0.9529 - val_loss: 3.0721 - val_accuracy: 0.4967\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2848 - accuracy: 0.9514 - val_loss: 3.0876 - val_accuracy: 0.4933\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2850 - accuracy: 0.9514 - val_loss: 3.0919 - val_accuracy: 0.5000\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2847 - accuracy: 0.9529 - val_loss: 3.0893 - val_accuracy: 0.5067\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2850 - accuracy: 0.9486 - val_loss: 3.0870 - val_accuracy: 0.5067\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2848 - accuracy: 0.9529 - val_loss: 3.0781 - val_accuracy: 0.4933\n",
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2845 - accuracy: 0.9500 - val_loss: 3.0945 - val_accuracy: 0.4967\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2841 - accuracy: 0.9514 - val_loss: 3.0897 - val_accuracy: 0.5067\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2837 - accuracy: 0.9514 - val_loss: 3.1004 - val_accuracy: 0.4967\n",
      "Epoch 1432/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.2843 - accuracy: 0.9514 - val_loss: 3.1140 - val_accuracy: 0.4933\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2842 - accuracy: 0.9471 - val_loss: 3.1035 - val_accuracy: 0.4967\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2842 - accuracy: 0.9514 - val_loss: 3.0738 - val_accuracy: 0.5000\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2836 - accuracy: 0.9500 - val_loss: 3.0970 - val_accuracy: 0.4967\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2839 - accuracy: 0.9500 - val_loss: 3.0968 - val_accuracy: 0.4900\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2829 - accuracy: 0.9514 - val_loss: 3.1324 - val_accuracy: 0.5067\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2842 - accuracy: 0.9500 - val_loss: 3.0952 - val_accuracy: 0.4933\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2829 - accuracy: 0.9529 - val_loss: 3.0960 - val_accuracy: 0.4900\n",
      "Epoch 1440/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2833 - accuracy: 0.9457 - val_loss: 3.1017 - val_accuracy: 0.4933\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2832 - accuracy: 0.9557 - val_loss: 3.1128 - val_accuracy: 0.4933\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2828 - accuracy: 0.9500 - val_loss: 3.1058 - val_accuracy: 0.5000\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2827 - accuracy: 0.9529 - val_loss: 3.0984 - val_accuracy: 0.4900\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2824 - accuracy: 0.9543 - val_loss: 3.1034 - val_accuracy: 0.4967\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2826 - accuracy: 0.9471 - val_loss: 3.1128 - val_accuracy: 0.4967\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2824 - accuracy: 0.9529 - val_loss: 3.1255 - val_accuracy: 0.4967\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2826 - accuracy: 0.9500 - val_loss: 3.1087 - val_accuracy: 0.4933\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2823 - accuracy: 0.9514 - val_loss: 3.1313 - val_accuracy: 0.5000\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2824 - accuracy: 0.9529 - val_loss: 3.1180 - val_accuracy: 0.5100\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2815 - accuracy: 0.9500 - val_loss: 3.1373 - val_accuracy: 0.5000\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2816 - accuracy: 0.9543 - val_loss: 3.0999 - val_accuracy: 0.5033\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2813 - accuracy: 0.9529 - val_loss: 3.1138 - val_accuracy: 0.4900\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2823 - accuracy: 0.9486 - val_loss: 3.1158 - val_accuracy: 0.5100\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2816 - accuracy: 0.9500 - val_loss: 3.1098 - val_accuracy: 0.4933\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2809 - accuracy: 0.9500 - val_loss: 3.1306 - val_accuracy: 0.4933\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2808 - accuracy: 0.9500 - val_loss: 3.1134 - val_accuracy: 0.4933\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2810 - accuracy: 0.9486 - val_loss: 3.1216 - val_accuracy: 0.4900\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2810 - accuracy: 0.9457 - val_loss: 3.1328 - val_accuracy: 0.4933\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2804 - accuracy: 0.9529 - val_loss: 3.1129 - val_accuracy: 0.4900\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2811 - accuracy: 0.9471 - val_loss: 3.1277 - val_accuracy: 0.4967\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2807 - accuracy: 0.9529 - val_loss: 3.1270 - val_accuracy: 0.4967\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2796 - accuracy: 0.9557 - val_loss: 3.1284 - val_accuracy: 0.4900\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2802 - accuracy: 0.9514 - val_loss: 3.1398 - val_accuracy: 0.4967\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2807 - accuracy: 0.9514 - val_loss: 3.1332 - val_accuracy: 0.5000\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2797 - accuracy: 0.9471 - val_loss: 3.1386 - val_accuracy: 0.4867\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2799 - accuracy: 0.9529 - val_loss: 3.1436 - val_accuracy: 0.4867\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2799 - accuracy: 0.9529 - val_loss: 3.1378 - val_accuracy: 0.4900\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2796 - accuracy: 0.9514 - val_loss: 3.1543 - val_accuracy: 0.4933\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2803 - accuracy: 0.9486 - val_loss: 3.1241 - val_accuracy: 0.4900\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2793 - accuracy: 0.9486 - val_loss: 3.1243 - val_accuracy: 0.5000\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2799 - accuracy: 0.9486 - val_loss: 3.1496 - val_accuracy: 0.5000\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2796 - accuracy: 0.9543 - val_loss: 3.1497 - val_accuracy: 0.4933\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2792 - accuracy: 0.9500 - val_loss: 3.1377 - val_accuracy: 0.4933\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2788 - accuracy: 0.9557 - val_loss: 3.1370 - val_accuracy: 0.4900\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2787 - accuracy: 0.9514 - val_loss: 3.1406 - val_accuracy: 0.4933\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2790 - accuracy: 0.9500 - val_loss: 3.1722 - val_accuracy: 0.4967\n",
      "Epoch 1477/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2780 - accuracy: 0.9543 - val_loss: 3.1497 - val_accuracy: 0.4967\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2787 - accuracy: 0.9557 - val_loss: 3.1487 - val_accuracy: 0.4867\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2788 - accuracy: 0.9529 - val_loss: 3.1561 - val_accuracy: 0.4967\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2784 - accuracy: 0.9529 - val_loss: 3.1742 - val_accuracy: 0.4967\n",
      "Epoch 1481/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2787 - accuracy: 0.9543 - val_loss: 3.1470 - val_accuracy: 0.4933\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2782 - accuracy: 0.9471 - val_loss: 3.1609 - val_accuracy: 0.5000\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2775 - accuracy: 0.9514 - val_loss: 3.1655 - val_accuracy: 0.5000\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2783 - accuracy: 0.9514 - val_loss: 3.1715 - val_accuracy: 0.4933\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2779 - accuracy: 0.9557 - val_loss: 3.1801 - val_accuracy: 0.4933\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2779 - accuracy: 0.9529 - val_loss: 3.1816 - val_accuracy: 0.4900\n",
      "Epoch 1487/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 0.2773 - accuracy: 0.9529 - val_loss: 3.1696 - val_accuracy: 0.4900\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2773 - accuracy: 0.9500 - val_loss: 3.1644 - val_accuracy: 0.4933\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2774 - accuracy: 0.9514 - val_loss: 3.1713 - val_accuracy: 0.5000\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2775 - accuracy: 0.9529 - val_loss: 3.1703 - val_accuracy: 0.4933\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2775 - accuracy: 0.9543 - val_loss: 3.1608 - val_accuracy: 0.4867\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2771 - accuracy: 0.9529 - val_loss: 3.1857 - val_accuracy: 0.4933\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2774 - accuracy: 0.9514 - val_loss: 3.1767 - val_accuracy: 0.4900\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2773 - accuracy: 0.9471 - val_loss: 3.1853 - val_accuracy: 0.4900\n",
      "Epoch 1495/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2763 - accuracy: 0.9514 - val_loss: 3.1756 - val_accuracy: 0.4900\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2768 - accuracy: 0.9514 - val_loss: 3.1588 - val_accuracy: 0.4900\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2762 - accuracy: 0.9557 - val_loss: 3.1849 - val_accuracy: 0.5067\n",
      "Epoch 1498/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2764 - accuracy: 0.9500 - val_loss: 3.1688 - val_accuracy: 0.4900\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2768 - accuracy: 0.9500 - val_loss: 3.1807 - val_accuracy: 0.4900\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2759 - accuracy: 0.9500 - val_loss: 3.1818 - val_accuracy: 0.4933\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2764 - accuracy: 0.9514 - val_loss: 3.1885 - val_accuracy: 0.4900\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2758 - accuracy: 0.9500 - val_loss: 3.2024 - val_accuracy: 0.4933\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2753 - accuracy: 0.9529 - val_loss: 3.2013 - val_accuracy: 0.4967\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.2756 - accuracy: 0.9543 - val_loss: 3.1779 - val_accuracy: 0.5067\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2758 - accuracy: 0.9529 - val_loss: 3.1907 - val_accuracy: 0.4900\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2749 - accuracy: 0.9557 - val_loss: 3.1889 - val_accuracy: 0.4933\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2755 - accuracy: 0.9500 - val_loss: 3.1731 - val_accuracy: 0.4900\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2753 - accuracy: 0.9557 - val_loss: 3.1833 - val_accuracy: 0.4933\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2744 - accuracy: 0.9514 - val_loss: 3.1957 - val_accuracy: 0.4867\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2756 - accuracy: 0.9457 - val_loss: 3.2183 - val_accuracy: 0.4967\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2764 - accuracy: 0.9486 - val_loss: 3.1923 - val_accuracy: 0.4933\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2751 - accuracy: 0.9571 - val_loss: 3.1991 - val_accuracy: 0.4933\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2737 - accuracy: 0.9543 - val_loss: 3.2137 - val_accuracy: 0.4933\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2738 - accuracy: 0.9557 - val_loss: 3.2060 - val_accuracy: 0.4900\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2739 - accuracy: 0.9529 - val_loss: 3.2150 - val_accuracy: 0.4933\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2729 - accuracy: 0.9557 - val_loss: 3.2059 - val_accuracy: 0.4900\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2723 - accuracy: 0.9543 - val_loss: 3.2033 - val_accuracy: 0.4833\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2734 - accuracy: 0.9543 - val_loss: 3.2337 - val_accuracy: 0.4900\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2725 - accuracy: 0.9543 - val_loss: 3.2183 - val_accuracy: 0.4900\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2727 - accuracy: 0.9571 - val_loss: 3.2234 - val_accuracy: 0.4933\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2726 - accuracy: 0.9571 - val_loss: 3.2041 - val_accuracy: 0.5000\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2723 - accuracy: 0.9543 - val_loss: 3.2029 - val_accuracy: 0.4933\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2729 - accuracy: 0.9543 - val_loss: 3.2392 - val_accuracy: 0.4867\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2725 - accuracy: 0.9486 - val_loss: 3.2288 - val_accuracy: 0.4933\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2727 - accuracy: 0.9543 - val_loss: 3.2210 - val_accuracy: 0.4867\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2715 - accuracy: 0.9557 - val_loss: 3.2412 - val_accuracy: 0.4900\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2719 - accuracy: 0.9557 - val_loss: 3.2261 - val_accuracy: 0.4933\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2720 - accuracy: 0.9514 - val_loss: 3.2381 - val_accuracy: 0.4933\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2716 - accuracy: 0.9543 - val_loss: 3.2489 - val_accuracy: 0.4900\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2717 - accuracy: 0.9557 - val_loss: 3.2254 - val_accuracy: 0.4900\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2714 - accuracy: 0.9529 - val_loss: 3.2543 - val_accuracy: 0.4933\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2716 - accuracy: 0.9543 - val_loss: 3.2411 - val_accuracy: 0.4900\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2709 - accuracy: 0.9557 - val_loss: 3.2400 - val_accuracy: 0.4867\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2712 - accuracy: 0.9543 - val_loss: 3.2379 - val_accuracy: 0.4900\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2704 - accuracy: 0.9529 - val_loss: 3.2464 - val_accuracy: 0.4933\n",
      "Epoch 1536/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2706 - accuracy: 0.9543 - val_loss: 3.2528 - val_accuracy: 0.4933\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2706 - accuracy: 0.9514 - val_loss: 3.2309 - val_accuracy: 0.4933\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2711 - accuracy: 0.9557 - val_loss: 3.2347 - val_accuracy: 0.4900\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2702 - accuracy: 0.9529 - val_loss: 3.2470 - val_accuracy: 0.4933\n",
      "Epoch 1540/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2708 - accuracy: 0.9514 - val_loss: 3.2539 - val_accuracy: 0.4933\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2708 - accuracy: 0.9529 - val_loss: 3.2484 - val_accuracy: 0.4933\n",
      "Epoch 1542/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 0.2707 - accuracy: 0.9543 - val_loss: 3.2314 - val_accuracy: 0.4933\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2700 - accuracy: 0.9514 - val_loss: 3.2736 - val_accuracy: 0.4900\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2699 - accuracy: 0.9571 - val_loss: 3.2252 - val_accuracy: 0.4800\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.2699 - accuracy: 0.9529 - val_loss: 3.2732 - val_accuracy: 0.4900\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2705 - accuracy: 0.9571 - val_loss: 3.2835 - val_accuracy: 0.4900\n",
      "Epoch 1547/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2698 - accuracy: 0.9557 - val_loss: 3.2567 - val_accuracy: 0.4900\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2692 - accuracy: 0.9529 - val_loss: 3.2364 - val_accuracy: 0.4967\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2701 - accuracy: 0.9529 - val_loss: 3.2531 - val_accuracy: 0.4900\n",
      "Epoch 1550/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2695 - accuracy: 0.9543 - val_loss: 3.2483 - val_accuracy: 0.4967\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2698 - accuracy: 0.9529 - val_loss: 3.2506 - val_accuracy: 0.4900\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2688 - accuracy: 0.9529 - val_loss: 3.2590 - val_accuracy: 0.4967\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2684 - accuracy: 0.9543 - val_loss: 3.2634 - val_accuracy: 0.4967\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2689 - accuracy: 0.9500 - val_loss: 3.2747 - val_accuracy: 0.4933\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2690 - accuracy: 0.9571 - val_loss: 3.2644 - val_accuracy: 0.5000\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2689 - accuracy: 0.9529 - val_loss: 3.2576 - val_accuracy: 0.4933\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2684 - accuracy: 0.9557 - val_loss: 3.2576 - val_accuracy: 0.4933\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2686 - accuracy: 0.9543 - val_loss: 3.2797 - val_accuracy: 0.4900\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2682 - accuracy: 0.9529 - val_loss: 3.2686 - val_accuracy: 0.4933\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2686 - accuracy: 0.9557 - val_loss: 3.2596 - val_accuracy: 0.4867\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2681 - accuracy: 0.9543 - val_loss: 3.2699 - val_accuracy: 0.4900\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2683 - accuracy: 0.9557 - val_loss: 3.2576 - val_accuracy: 0.4933\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2676 - accuracy: 0.9543 - val_loss: 3.2924 - val_accuracy: 0.4900\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2684 - accuracy: 0.9529 - val_loss: 3.2671 - val_accuracy: 0.4933\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2679 - accuracy: 0.9500 - val_loss: 3.2874 - val_accuracy: 0.4900\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2682 - accuracy: 0.9500 - val_loss: 3.2773 - val_accuracy: 0.4867\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2687 - accuracy: 0.9571 - val_loss: 3.2740 - val_accuracy: 0.4867\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2675 - accuracy: 0.9557 - val_loss: 3.2734 - val_accuracy: 0.4867\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2671 - accuracy: 0.9500 - val_loss: 3.2545 - val_accuracy: 0.4900\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2673 - accuracy: 0.9571 - val_loss: 3.2679 - val_accuracy: 0.4900\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2673 - accuracy: 0.9557 - val_loss: 3.2897 - val_accuracy: 0.4900\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2672 - accuracy: 0.9557 - val_loss: 3.2783 - val_accuracy: 0.4933\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2672 - accuracy: 0.9529 - val_loss: 3.2644 - val_accuracy: 0.5000\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2672 - accuracy: 0.9500 - val_loss: 3.2758 - val_accuracy: 0.4933\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2669 - accuracy: 0.9514 - val_loss: 3.2838 - val_accuracy: 0.4933\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2667 - accuracy: 0.9543 - val_loss: 3.2758 - val_accuracy: 0.4900\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2664 - accuracy: 0.9543 - val_loss: 3.2956 - val_accuracy: 0.4900\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2669 - accuracy: 0.9543 - val_loss: 3.3134 - val_accuracy: 0.4900\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2658 - accuracy: 0.9543 - val_loss: 3.2951 - val_accuracy: 0.4900\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2662 - accuracy: 0.9543 - val_loss: 3.2978 - val_accuracy: 0.4933\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2667 - accuracy: 0.9514 - val_loss: 3.2908 - val_accuracy: 0.5000\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2664 - accuracy: 0.9514 - val_loss: 3.2990 - val_accuracy: 0.4900\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2661 - accuracy: 0.9557 - val_loss: 3.3262 - val_accuracy: 0.4867\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2663 - accuracy: 0.9529 - val_loss: 3.3114 - val_accuracy: 0.4900\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2658 - accuracy: 0.9557 - val_loss: 3.3074 - val_accuracy: 0.4900\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.2654 - accuracy: 0.9529 - val_loss: 3.3073 - val_accuracy: 0.4900\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2659 - accuracy: 0.9557 - val_loss: 3.2919 - val_accuracy: 0.4900\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2652 - accuracy: 0.9529 - val_loss: 3.3291 - val_accuracy: 0.4900\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2653 - accuracy: 0.9557 - val_loss: 3.3035 - val_accuracy: 0.4967\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2659 - accuracy: 0.9529 - val_loss: 3.3041 - val_accuracy: 0.4900\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2651 - accuracy: 0.9529 - val_loss: 3.3104 - val_accuracy: 0.4900\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2654 - accuracy: 0.9543 - val_loss: 3.3288 - val_accuracy: 0.4900\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2659 - accuracy: 0.9514 - val_loss: 3.3096 - val_accuracy: 0.4900\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2645 - accuracy: 0.9543 - val_loss: 3.3213 - val_accuracy: 0.4900\n",
      "Epoch 1595/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2653 - accuracy: 0.9543 - val_loss: 3.3162 - val_accuracy: 0.4900\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2648 - accuracy: 0.9586 - val_loss: 3.3092 - val_accuracy: 0.4867\n",
      "Epoch 1597/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.95 - 0s 106us/step - loss: 0.2650 - accuracy: 0.9557 - val_loss: 3.3217 - val_accuracy: 0.4900\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2644 - accuracy: 0.9543 - val_loss: 3.3056 - val_accuracy: 0.4933\n",
      "Epoch 1599/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2647 - accuracy: 0.9514 - val_loss: 3.3171 - val_accuracy: 0.4933\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2646 - accuracy: 0.9543 - val_loss: 3.3158 - val_accuracy: 0.4867\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2641 - accuracy: 0.9514 - val_loss: 3.3197 - val_accuracy: 0.4833\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2646 - accuracy: 0.9557 - val_loss: 3.3015 - val_accuracy: 0.4933\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2645 - accuracy: 0.9543 - val_loss: 3.3518 - val_accuracy: 0.4933\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2643 - accuracy: 0.9571 - val_loss: 3.3220 - val_accuracy: 0.4967\n",
      "Epoch 1605/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2640 - accuracy: 0.9557 - val_loss: 3.3360 - val_accuracy: 0.4867\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2639 - accuracy: 0.9529 - val_loss: 3.3136 - val_accuracy: 0.4933\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2640 - accuracy: 0.9557 - val_loss: 3.3395 - val_accuracy: 0.4833\n",
      "Epoch 1608/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.2640 - accuracy: 0.9529 - val_loss: 3.3196 - val_accuracy: 0.4933\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2634 - accuracy: 0.9586 - val_loss: 3.3266 - val_accuracy: 0.4867\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2635 - accuracy: 0.9571 - val_loss: 3.3324 - val_accuracy: 0.4900\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2635 - accuracy: 0.9529 - val_loss: 3.3415 - val_accuracy: 0.4867\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2636 - accuracy: 0.9543 - val_loss: 3.3308 - val_accuracy: 0.4900\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2630 - accuracy: 0.9557 - val_loss: 3.3343 - val_accuracy: 0.4933\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2631 - accuracy: 0.9514 - val_loss: 3.3239 - val_accuracy: 0.4933\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2627 - accuracy: 0.9543 - val_loss: 3.3367 - val_accuracy: 0.4933\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2631 - accuracy: 0.9586 - val_loss: 3.3077 - val_accuracy: 0.5033\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2634 - accuracy: 0.9557 - val_loss: 3.3607 - val_accuracy: 0.4867\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2627 - accuracy: 0.9543 - val_loss: 3.3337 - val_accuracy: 0.4900\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2625 - accuracy: 0.9514 - val_loss: 3.3333 - val_accuracy: 0.4867\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2622 - accuracy: 0.9557 - val_loss: 3.3616 - val_accuracy: 0.4867\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2629 - accuracy: 0.9571 - val_loss: 3.3226 - val_accuracy: 0.4933\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2623 - accuracy: 0.9529 - val_loss: 3.3442 - val_accuracy: 0.4900\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2621 - accuracy: 0.9586 - val_loss: 3.3249 - val_accuracy: 0.4900\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2621 - accuracy: 0.9586 - val_loss: 3.3734 - val_accuracy: 0.4867\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2622 - accuracy: 0.9514 - val_loss: 3.3603 - val_accuracy: 0.4867\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2616 - accuracy: 0.9557 - val_loss: 3.3414 - val_accuracy: 0.4800\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2625 - accuracy: 0.9557 - val_loss: 3.3708 - val_accuracy: 0.4900\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2611 - accuracy: 0.9557 - val_loss: 3.3609 - val_accuracy: 0.4900\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2612 - accuracy: 0.9543 - val_loss: 3.3674 - val_accuracy: 0.4900\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2609 - accuracy: 0.9571 - val_loss: 3.3741 - val_accuracy: 0.4867\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2617 - accuracy: 0.9529 - val_loss: 3.3546 - val_accuracy: 0.4900\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2623 - accuracy: 0.9543 - val_loss: 3.3626 - val_accuracy: 0.4900\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2615 - accuracy: 0.9557 - val_loss: 3.3613 - val_accuracy: 0.4933\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2612 - accuracy: 0.9543 - val_loss: 3.3685 - val_accuracy: 0.4833\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2616 - accuracy: 0.9557 - val_loss: 3.3694 - val_accuracy: 0.4900\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2614 - accuracy: 0.9543 - val_loss: 3.3669 - val_accuracy: 0.4867\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2612 - accuracy: 0.9557 - val_loss: 3.3640 - val_accuracy: 0.4933\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2609 - accuracy: 0.9543 - val_loss: 3.3701 - val_accuracy: 0.4933\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2616 - accuracy: 0.9557 - val_loss: 3.3931 - val_accuracy: 0.4867\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2606 - accuracy: 0.9557 - val_loss: 3.3594 - val_accuracy: 0.4933\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2608 - accuracy: 0.9543 - val_loss: 3.3897 - val_accuracy: 0.4867\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2609 - accuracy: 0.9557 - val_loss: 3.3555 - val_accuracy: 0.4933\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2602 - accuracy: 0.9571 - val_loss: 3.3861 - val_accuracy: 0.4833\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2601 - accuracy: 0.9557 - val_loss: 3.3914 - val_accuracy: 0.4833\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2600 - accuracy: 0.9586 - val_loss: 3.3654 - val_accuracy: 0.4833\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2599 - accuracy: 0.9543 - val_loss: 3.3836 - val_accuracy: 0.4900\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2605 - accuracy: 0.9557 - val_loss: 3.3801 - val_accuracy: 0.4900\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2600 - accuracy: 0.9557 - val_loss: 3.3714 - val_accuracy: 0.4900\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2601 - accuracy: 0.9529 - val_loss: 3.3712 - val_accuracy: 0.4933\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2602 - accuracy: 0.9543 - val_loss: 3.3646 - val_accuracy: 0.4867\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2600 - accuracy: 0.9571 - val_loss: 3.3765 - val_accuracy: 0.4867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2594 - accuracy: 0.9571 - val_loss: 3.3842 - val_accuracy: 0.4867\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2606 - accuracy: 0.9571 - val_loss: 3.3907 - val_accuracy: 0.4900\n",
      "Epoch 1654/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2600 - accuracy: 0.9600 - val_loss: 3.3695 - val_accuracy: 0.4833\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2596 - accuracy: 0.9543 - val_loss: 3.3702 - val_accuracy: 0.4867\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2597 - accuracy: 0.9571 - val_loss: 3.3927 - val_accuracy: 0.4900\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2596 - accuracy: 0.9543 - val_loss: 3.3733 - val_accuracy: 0.4867\n",
      "Epoch 1658/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2592 - accuracy: 0.9557 - val_loss: 3.3848 - val_accuracy: 0.4900\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2583 - accuracy: 0.9543 - val_loss: 3.3988 - val_accuracy: 0.4833\n",
      "Epoch 1660/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2591 - accuracy: 0.9543 - val_loss: 3.4088 - val_accuracy: 0.4900\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2587 - accuracy: 0.9557 - val_loss: 3.4034 - val_accuracy: 0.4867\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2587 - accuracy: 0.9571 - val_loss: 3.4188 - val_accuracy: 0.4833\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2591 - accuracy: 0.9586 - val_loss: 3.4029 - val_accuracy: 0.4900\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2584 - accuracy: 0.9571 - val_loss: 3.3687 - val_accuracy: 0.4833\n",
      "Epoch 1665/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2586 - accuracy: 0.9571 - val_loss: 3.3941 - val_accuracy: 0.4900\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2584 - accuracy: 0.9543 - val_loss: 3.3870 - val_accuracy: 0.4833\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2578 - accuracy: 0.9571 - val_loss: 3.3756 - val_accuracy: 0.4933\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.2584 - accuracy: 0.9557 - val_loss: 3.3914 - val_accuracy: 0.4900\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2577 - accuracy: 0.9543 - val_loss: 3.4177 - val_accuracy: 0.4867\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2581 - accuracy: 0.9543 - val_loss: 3.3882 - val_accuracy: 0.4933\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2581 - accuracy: 0.9571 - val_loss: 3.3898 - val_accuracy: 0.4900\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2582 - accuracy: 0.9557 - val_loss: 3.4062 - val_accuracy: 0.4833\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2584 - accuracy: 0.9571 - val_loss: 3.4178 - val_accuracy: 0.4900\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2577 - accuracy: 0.9557 - val_loss: 3.4270 - val_accuracy: 0.4867\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2579 - accuracy: 0.9529 - val_loss: 3.4128 - val_accuracy: 0.4900\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2577 - accuracy: 0.9529 - val_loss: 3.4302 - val_accuracy: 0.4867\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2578 - accuracy: 0.9600 - val_loss: 3.4267 - val_accuracy: 0.4867\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2569 - accuracy: 0.9571 - val_loss: 3.4473 - val_accuracy: 0.4867\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2570 - accuracy: 0.9571 - val_loss: 3.4455 - val_accuracy: 0.4867\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2573 - accuracy: 0.9529 - val_loss: 3.4160 - val_accuracy: 0.4900\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2570 - accuracy: 0.9571 - val_loss: 3.4096 - val_accuracy: 0.4900\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2572 - accuracy: 0.9586 - val_loss: 3.4081 - val_accuracy: 0.4900\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2574 - accuracy: 0.9586 - val_loss: 3.4141 - val_accuracy: 0.4833\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2567 - accuracy: 0.9600 - val_loss: 3.4162 - val_accuracy: 0.4867\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2573 - accuracy: 0.9600 - val_loss: 3.4118 - val_accuracy: 0.4900\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2569 - accuracy: 0.9529 - val_loss: 3.3893 - val_accuracy: 0.4900\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2571 - accuracy: 0.9571 - val_loss: 3.4346 - val_accuracy: 0.4867\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2566 - accuracy: 0.9514 - val_loss: 3.4318 - val_accuracy: 0.4833\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2569 - accuracy: 0.9543 - val_loss: 3.4290 - val_accuracy: 0.4933\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2567 - accuracy: 0.9571 - val_loss: 3.4563 - val_accuracy: 0.4900\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2568 - accuracy: 0.9571 - val_loss: 3.4325 - val_accuracy: 0.4833\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2561 - accuracy: 0.9557 - val_loss: 3.4538 - val_accuracy: 0.4867\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2567 - accuracy: 0.9543 - val_loss: 3.4276 - val_accuracy: 0.4900\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2562 - accuracy: 0.9571 - val_loss: 3.4346 - val_accuracy: 0.4933\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2559 - accuracy: 0.9557 - val_loss: 3.4482 - val_accuracy: 0.4833\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2555 - accuracy: 0.9543 - val_loss: 3.4298 - val_accuracy: 0.4867\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2557 - accuracy: 0.9557 - val_loss: 3.4242 - val_accuracy: 0.4900\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2558 - accuracy: 0.9557 - val_loss: 3.4297 - val_accuracy: 0.4900\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2560 - accuracy: 0.9557 - val_loss: 3.4402 - val_accuracy: 0.4867\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2554 - accuracy: 0.9614 - val_loss: 3.4407 - val_accuracy: 0.4900\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2555 - accuracy: 0.9557 - val_loss: 3.4458 - val_accuracy: 0.4800\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2556 - accuracy: 0.9557 - val_loss: 3.4439 - val_accuracy: 0.4800\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2554 - accuracy: 0.9529 - val_loss: 3.4627 - val_accuracy: 0.4833\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.95 - 0s 103us/step - loss: 0.2548 - accuracy: 0.9543 - val_loss: 3.4485 - val_accuracy: 0.4900\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2547 - accuracy: 0.9557 - val_loss: 3.4434 - val_accuracy: 0.4800\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2549 - accuracy: 0.9543 - val_loss: 3.4521 - val_accuracy: 0.4867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2550 - accuracy: 0.9586 - val_loss: 3.4372 - val_accuracy: 0.4867\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2544 - accuracy: 0.9571 - val_loss: 3.4673 - val_accuracy: 0.4833\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2545 - accuracy: 0.9571 - val_loss: 3.4515 - val_accuracy: 0.4833\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2546 - accuracy: 0.9586 - val_loss: 3.4434 - val_accuracy: 0.4867\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2545 - accuracy: 0.9557 - val_loss: 3.4610 - val_accuracy: 0.4833\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2545 - accuracy: 0.9543 - val_loss: 3.4429 - val_accuracy: 0.4900\n",
      "Epoch 1713/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2545 - accuracy: 0.9571 - val_loss: 3.4674 - val_accuracy: 0.4800\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2545 - accuracy: 0.9543 - val_loss: 3.4410 - val_accuracy: 0.4900\n",
      "Epoch 1715/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2542 - accuracy: 0.9557 - val_loss: 3.4458 - val_accuracy: 0.4933\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2544 - accuracy: 0.9586 - val_loss: 3.4612 - val_accuracy: 0.4867\n",
      "Epoch 1717/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2542 - accuracy: 0.9557 - val_loss: 3.4818 - val_accuracy: 0.4867\n",
      "Epoch 1718/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2537 - accuracy: 0.9571 - val_loss: 3.4814 - val_accuracy: 0.4833\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2537 - accuracy: 0.9571 - val_loss: 3.4540 - val_accuracy: 0.4900\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2541 - accuracy: 0.9586 - val_loss: 3.4668 - val_accuracy: 0.4833\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2531 - accuracy: 0.9586 - val_loss: 3.4578 - val_accuracy: 0.4967\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2539 - accuracy: 0.9557 - val_loss: 3.4766 - val_accuracy: 0.4900\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2538 - accuracy: 0.9543 - val_loss: 3.4719 - val_accuracy: 0.4900\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2537 - accuracy: 0.9571 - val_loss: 3.4607 - val_accuracy: 0.4867\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2536 - accuracy: 0.9586 - val_loss: 3.4690 - val_accuracy: 0.4833\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2534 - accuracy: 0.9586 - val_loss: 3.4816 - val_accuracy: 0.4900\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2539 - accuracy: 0.9557 - val_loss: 3.4717 - val_accuracy: 0.4867\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2533 - accuracy: 0.9586 - val_loss: 3.4614 - val_accuracy: 0.4833\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2532 - accuracy: 0.9557 - val_loss: 3.4598 - val_accuracy: 0.4900\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2534 - accuracy: 0.9586 - val_loss: 3.4649 - val_accuracy: 0.4900\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2533 - accuracy: 0.9571 - val_loss: 3.4850 - val_accuracy: 0.4833\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2528 - accuracy: 0.9557 - val_loss: 3.5262 - val_accuracy: 0.4900\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2534 - accuracy: 0.9543 - val_loss: 3.4987 - val_accuracy: 0.4867\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2531 - accuracy: 0.9586 - val_loss: 3.4853 - val_accuracy: 0.4833\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2524 - accuracy: 0.9557 - val_loss: 3.4732 - val_accuracy: 0.4933\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2528 - accuracy: 0.9600 - val_loss: 3.4918 - val_accuracy: 0.4800\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2519 - accuracy: 0.9543 - val_loss: 3.4681 - val_accuracy: 0.4933\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2523 - accuracy: 0.9557 - val_loss: 3.4842 - val_accuracy: 0.4900\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2525 - accuracy: 0.9586 - val_loss: 3.4774 - val_accuracy: 0.4933\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2522 - accuracy: 0.9586 - val_loss: 3.4849 - val_accuracy: 0.4833\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2517 - accuracy: 0.9529 - val_loss: 3.4966 - val_accuracy: 0.4833\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2523 - accuracy: 0.9614 - val_loss: 3.4679 - val_accuracy: 0.4967\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2522 - accuracy: 0.9600 - val_loss: 3.4885 - val_accuracy: 0.4900\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2517 - accuracy: 0.9543 - val_loss: 3.4717 - val_accuracy: 0.4900\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2522 - accuracy: 0.9571 - val_loss: 3.4975 - val_accuracy: 0.4833\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2520 - accuracy: 0.9586 - val_loss: 3.4730 - val_accuracy: 0.4933\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2515 - accuracy: 0.9571 - val_loss: 3.4968 - val_accuracy: 0.4900\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2515 - accuracy: 0.9586 - val_loss: 3.5082 - val_accuracy: 0.4867\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2521 - accuracy: 0.9557 - val_loss: 3.5001 - val_accuracy: 0.4800\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2511 - accuracy: 0.9586 - val_loss: 3.4922 - val_accuracy: 0.4867\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2517 - accuracy: 0.9571 - val_loss: 3.4909 - val_accuracy: 0.4867\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2515 - accuracy: 0.9557 - val_loss: 3.5151 - val_accuracy: 0.4833\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2515 - accuracy: 0.9586 - val_loss: 3.5068 - val_accuracy: 0.4867\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2511 - accuracy: 0.9571 - val_loss: 3.5086 - val_accuracy: 0.4833\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2508 - accuracy: 0.9514 - val_loss: 3.5160 - val_accuracy: 0.4833\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2507 - accuracy: 0.9571 - val_loss: 3.4843 - val_accuracy: 0.4867\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2507 - accuracy: 0.9600 - val_loss: 3.5056 - val_accuracy: 0.4833\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2507 - accuracy: 0.9600 - val_loss: 3.5321 - val_accuracy: 0.4867\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2503 - accuracy: 0.9571 - val_loss: 3.4957 - val_accuracy: 0.4933\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2505 - accuracy: 0.9586 - val_loss: 3.5228 - val_accuracy: 0.4800\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2510 - accuracy: 0.9600 - val_loss: 3.5177 - val_accuracy: 0.4867\n",
      "Epoch 1762/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.2503 - accuracy: 0.9629 - val_loss: 3.5295 - val_accuracy: 0.4867\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2506 - accuracy: 0.9586 - val_loss: 3.5202 - val_accuracy: 0.4800\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2498 - accuracy: 0.9557 - val_loss: 3.5138 - val_accuracy: 0.4867\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2509 - accuracy: 0.9600 - val_loss: 3.4958 - val_accuracy: 0.4833\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2500 - accuracy: 0.9600 - val_loss: 3.5197 - val_accuracy: 0.4933\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2506 - accuracy: 0.9571 - val_loss: 3.5182 - val_accuracy: 0.4900\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2495 - accuracy: 0.9571 - val_loss: 3.4936 - val_accuracy: 0.4833\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2504 - accuracy: 0.9571 - val_loss: 3.5229 - val_accuracy: 0.4800\n",
      "Epoch 1770/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2498 - accuracy: 0.9600 - val_loss: 3.5397 - val_accuracy: 0.4867\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2500 - accuracy: 0.9586 - val_loss: 3.5388 - val_accuracy: 0.4867\n",
      "Epoch 1772/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2498 - accuracy: 0.9571 - val_loss: 3.5525 - val_accuracy: 0.4867\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2495 - accuracy: 0.9600 - val_loss: 3.5312 - val_accuracy: 0.4833\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2497 - accuracy: 0.9600 - val_loss: 3.5158 - val_accuracy: 0.4833\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2497 - accuracy: 0.9571 - val_loss: 3.5210 - val_accuracy: 0.4900\n",
      "Epoch 1776/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2495 - accuracy: 0.9571 - val_loss: 3.5122 - val_accuracy: 0.4867\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2493 - accuracy: 0.9600 - val_loss: 3.5506 - val_accuracy: 0.4867\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2493 - accuracy: 0.9557 - val_loss: 3.5195 - val_accuracy: 0.4867\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2491 - accuracy: 0.9586 - val_loss: 3.5228 - val_accuracy: 0.4833\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2488 - accuracy: 0.9571 - val_loss: 3.5349 - val_accuracy: 0.4933\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2489 - accuracy: 0.9557 - val_loss: 3.5531 - val_accuracy: 0.4867\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2492 - accuracy: 0.9600 - val_loss: 3.5206 - val_accuracy: 0.4867\n",
      "Epoch 1783/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2488 - accuracy: 0.9586 - val_loss: 3.5248 - val_accuracy: 0.4900\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2490 - accuracy: 0.9614 - val_loss: 3.5246 - val_accuracy: 0.4900\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2489 - accuracy: 0.9571 - val_loss: 3.5239 - val_accuracy: 0.4833\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2487 - accuracy: 0.9614 - val_loss: 3.5384 - val_accuracy: 0.4900\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2483 - accuracy: 0.9614 - val_loss: 3.5826 - val_accuracy: 0.4867\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2490 - accuracy: 0.9586 - val_loss: 3.5320 - val_accuracy: 0.4933\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2485 - accuracy: 0.9586 - val_loss: 3.5485 - val_accuracy: 0.4867\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2486 - accuracy: 0.9586 - val_loss: 3.5368 - val_accuracy: 0.4933\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2480 - accuracy: 0.9571 - val_loss: 3.5529 - val_accuracy: 0.4867\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.2483 - accuracy: 0.9571 - val_loss: 3.5332 - val_accuracy: 0.4833\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.2483 - accuracy: 0.9571 - val_loss: 3.5684 - val_accuracy: 0.4867\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2481 - accuracy: 0.9571 - val_loss: 3.5377 - val_accuracy: 0.4900\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2481 - accuracy: 0.9600 - val_loss: 3.5542 - val_accuracy: 0.4833\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2479 - accuracy: 0.9571 - val_loss: 3.5470 - val_accuracy: 0.4833\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2478 - accuracy: 0.9571 - val_loss: 3.5501 - val_accuracy: 0.4933\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2482 - accuracy: 0.9614 - val_loss: 3.5382 - val_accuracy: 0.4833\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2474 - accuracy: 0.9571 - val_loss: 3.5454 - val_accuracy: 0.4900\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2476 - accuracy: 0.9614 - val_loss: 3.5503 - val_accuracy: 0.4833\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2471 - accuracy: 0.9571 - val_loss: 3.5430 - val_accuracy: 0.4900\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2475 - accuracy: 0.9571 - val_loss: 3.5585 - val_accuracy: 0.4800\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2473 - accuracy: 0.9557 - val_loss: 3.5724 - val_accuracy: 0.4900\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2473 - accuracy: 0.9571 - val_loss: 3.5372 - val_accuracy: 0.4900\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2473 - accuracy: 0.9600 - val_loss: 3.5713 - val_accuracy: 0.4867\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2475 - accuracy: 0.9571 - val_loss: 3.5607 - val_accuracy: 0.4833\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.2473 - accuracy: 0.9557 - val_loss: 3.5731 - val_accuracy: 0.4800\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2464 - accuracy: 0.9586 - val_loss: 3.5655 - val_accuracy: 0.4867\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2470 - accuracy: 0.9543 - val_loss: 3.5606 - val_accuracy: 0.4833\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2467 - accuracy: 0.9600 - val_loss: 3.5664 - val_accuracy: 0.4833\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2468 - accuracy: 0.9600 - val_loss: 3.5695 - val_accuracy: 0.4833\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2462 - accuracy: 0.9557 - val_loss: 3.5671 - val_accuracy: 0.4833\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2470 - accuracy: 0.9614 - val_loss: 3.5732 - val_accuracy: 0.4833\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2466 - accuracy: 0.9571 - val_loss: 3.5729 - val_accuracy: 0.4833\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2468 - accuracy: 0.9571 - val_loss: 3.5886 - val_accuracy: 0.4800\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2466 - accuracy: 0.9586 - val_loss: 3.5895 - val_accuracy: 0.4800\n",
      "Epoch 1817/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 0.2466 - accuracy: 0.9600 - val_loss: 3.5849 - val_accuracy: 0.4867\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2463 - accuracy: 0.9600 - val_loss: 3.5750 - val_accuracy: 0.4833\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2462 - accuracy: 0.9586 - val_loss: 3.5750 - val_accuracy: 0.4833\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2462 - accuracy: 0.9614 - val_loss: 3.5865 - val_accuracy: 0.4867\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2460 - accuracy: 0.9600 - val_loss: 3.5805 - val_accuracy: 0.4833\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2459 - accuracy: 0.9571 - val_loss: 3.6110 - val_accuracy: 0.4833\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2463 - accuracy: 0.9571 - val_loss: 3.6132 - val_accuracy: 0.4867\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2457 - accuracy: 0.9557 - val_loss: 3.5979 - val_accuracy: 0.4800\n",
      "Epoch 1825/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2456 - accuracy: 0.9614 - val_loss: 3.5977 - val_accuracy: 0.4867\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2458 - accuracy: 0.9586 - val_loss: 3.5953 - val_accuracy: 0.4833\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2456 - accuracy: 0.9586 - val_loss: 3.5793 - val_accuracy: 0.4833\n",
      "Epoch 1828/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2456 - accuracy: 0.9571 - val_loss: 3.6147 - val_accuracy: 0.4867\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2454 - accuracy: 0.9629 - val_loss: 3.5747 - val_accuracy: 0.4800\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2454 - accuracy: 0.9571 - val_loss: 3.5845 - val_accuracy: 0.4833\n",
      "Epoch 1831/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2450 - accuracy: 0.9629 - val_loss: 3.5870 - val_accuracy: 0.4833\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2451 - accuracy: 0.9586 - val_loss: 3.5691 - val_accuracy: 0.4900\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.2456 - accuracy: 0.9571 - val_loss: 3.5861 - val_accuracy: 0.4833\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2446 - accuracy: 0.9586 - val_loss: 3.6041 - val_accuracy: 0.4833\n",
      "Epoch 1835/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2453 - accuracy: 0.9586 - val_loss: 3.5821 - val_accuracy: 0.4900\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2451 - accuracy: 0.9614 - val_loss: 3.5905 - val_accuracy: 0.4800\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2450 - accuracy: 0.9614 - val_loss: 3.5922 - val_accuracy: 0.4800\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2451 - accuracy: 0.9557 - val_loss: 3.6187 - val_accuracy: 0.4833\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2450 - accuracy: 0.9600 - val_loss: 3.6326 - val_accuracy: 0.4900\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2450 - accuracy: 0.9571 - val_loss: 3.6046 - val_accuracy: 0.4867\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2443 - accuracy: 0.9586 - val_loss: 3.6024 - val_accuracy: 0.4833\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2446 - accuracy: 0.9614 - val_loss: 3.6164 - val_accuracy: 0.4867\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2441 - accuracy: 0.9614 - val_loss: 3.5725 - val_accuracy: 0.4867\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2444 - accuracy: 0.9571 - val_loss: 3.6025 - val_accuracy: 0.4833\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2451 - accuracy: 0.9571 - val_loss: 3.5965 - val_accuracy: 0.4800\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2447 - accuracy: 0.9600 - val_loss: 3.6330 - val_accuracy: 0.4800\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2441 - accuracy: 0.9614 - val_loss: 3.6143 - val_accuracy: 0.4833\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2443 - accuracy: 0.9543 - val_loss: 3.6023 - val_accuracy: 0.4800\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2442 - accuracy: 0.9586 - val_loss: 3.6289 - val_accuracy: 0.4833\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2438 - accuracy: 0.9571 - val_loss: 3.5946 - val_accuracy: 0.4833\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2438 - accuracy: 0.9571 - val_loss: 3.6100 - val_accuracy: 0.4800\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2440 - accuracy: 0.9586 - val_loss: 3.6245 - val_accuracy: 0.4900\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2431 - accuracy: 0.9557 - val_loss: 3.6335 - val_accuracy: 0.4800\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2438 - accuracy: 0.9586 - val_loss: 3.6175 - val_accuracy: 0.4800\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2432 - accuracy: 0.9571 - val_loss: 3.6318 - val_accuracy: 0.4800\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2440 - accuracy: 0.9586 - val_loss: 3.5978 - val_accuracy: 0.4867\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2436 - accuracy: 0.9557 - val_loss: 3.6269 - val_accuracy: 0.4800\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2431 - accuracy: 0.9557 - val_loss: 3.6229 - val_accuracy: 0.4833\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2426 - accuracy: 0.9529 - val_loss: 3.6242 - val_accuracy: 0.4800\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2425 - accuracy: 0.9571 - val_loss: 3.6235 - val_accuracy: 0.4833\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2429 - accuracy: 0.9586 - val_loss: 3.6069 - val_accuracy: 0.4833\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2421 - accuracy: 0.9586 - val_loss: 3.6218 - val_accuracy: 0.4833\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2430 - accuracy: 0.9557 - val_loss: 3.6325 - val_accuracy: 0.4833\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2424 - accuracy: 0.9586 - val_loss: 3.6329 - val_accuracy: 0.4833\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2426 - accuracy: 0.9586 - val_loss: 3.6149 - val_accuracy: 0.4867\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2418 - accuracy: 0.9629 - val_loss: 3.6706 - val_accuracy: 0.4900\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2428 - accuracy: 0.9614 - val_loss: 3.6261 - val_accuracy: 0.4833\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2423 - accuracy: 0.9586 - val_loss: 3.6248 - val_accuracy: 0.4900\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2419 - accuracy: 0.9600 - val_loss: 3.6502 - val_accuracy: 0.4800\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2428 - accuracy: 0.9571 - val_loss: 3.6208 - val_accuracy: 0.4800\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2419 - accuracy: 0.9586 - val_loss: 3.6394 - val_accuracy: 0.4767\n",
      "Epoch 1872/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 0.2418 - accuracy: 0.9629 - val_loss: 3.6219 - val_accuracy: 0.4833\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2415 - accuracy: 0.9586 - val_loss: 3.6291 - val_accuracy: 0.4867\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.2413 - accuracy: 0.9586 - val_loss: 3.6322 - val_accuracy: 0.4867\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2414 - accuracy: 0.9600 - val_loss: 3.6326 - val_accuracy: 0.4867\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2415 - accuracy: 0.9586 - val_loss: 3.6233 - val_accuracy: 0.4800\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2414 - accuracy: 0.9629 - val_loss: 3.6509 - val_accuracy: 0.4833\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2411 - accuracy: 0.9614 - val_loss: 3.6574 - val_accuracy: 0.4933\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2410 - accuracy: 0.9586 - val_loss: 3.6272 - val_accuracy: 0.4800\n",
      "Epoch 1880/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2411 - accuracy: 0.9600 - val_loss: 3.6360 - val_accuracy: 0.4900\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2411 - accuracy: 0.9629 - val_loss: 3.6487 - val_accuracy: 0.4833\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2409 - accuracy: 0.9600 - val_loss: 3.6593 - val_accuracy: 0.4833\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2407 - accuracy: 0.9571 - val_loss: 3.6643 - val_accuracy: 0.4800\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2410 - accuracy: 0.9629 - val_loss: 3.6273 - val_accuracy: 0.4800\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2407 - accuracy: 0.9586 - val_loss: 3.6387 - val_accuracy: 0.4833\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2403 - accuracy: 0.9557 - val_loss: 3.6573 - val_accuracy: 0.4800\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2406 - accuracy: 0.9571 - val_loss: 3.6536 - val_accuracy: 0.4767\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2406 - accuracy: 0.9600 - val_loss: 3.6561 - val_accuracy: 0.4833\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2404 - accuracy: 0.9600 - val_loss: 3.6328 - val_accuracy: 0.4867\n",
      "Epoch 1890/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2398 - accuracy: 0.9614 - val_loss: 3.6933 - val_accuracy: 0.4867\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2410 - accuracy: 0.9600 - val_loss: 3.6468 - val_accuracy: 0.4867\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2406 - accuracy: 0.9586 - val_loss: 3.6526 - val_accuracy: 0.4833\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2402 - accuracy: 0.9600 - val_loss: 3.6613 - val_accuracy: 0.4867\n",
      "Epoch 1894/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2398 - accuracy: 0.9614 - val_loss: 3.6785 - val_accuracy: 0.4833\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2402 - accuracy: 0.9614 - val_loss: 3.6612 - val_accuracy: 0.4867\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2402 - accuracy: 0.9600 - val_loss: 3.6498 - val_accuracy: 0.4833\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2395 - accuracy: 0.9614 - val_loss: 3.6881 - val_accuracy: 0.4867\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2395 - accuracy: 0.9586 - val_loss: 3.6766 - val_accuracy: 0.4800\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2398 - accuracy: 0.9600 - val_loss: 3.6822 - val_accuracy: 0.4833\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2395 - accuracy: 0.9600 - val_loss: 3.6784 - val_accuracy: 0.4833\n",
      "Epoch 1901/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2398 - accuracy: 0.9600 - val_loss: 3.6521 - val_accuracy: 0.4767\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2394 - accuracy: 0.9629 - val_loss: 3.6523 - val_accuracy: 0.4867\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2397 - accuracy: 0.9629 - val_loss: 3.6611 - val_accuracy: 0.4800\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2391 - accuracy: 0.9600 - val_loss: 3.6545 - val_accuracy: 0.4800\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2393 - accuracy: 0.9586 - val_loss: 3.6730 - val_accuracy: 0.4800\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2387 - accuracy: 0.9571 - val_loss: 3.6606 - val_accuracy: 0.4800\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2392 - accuracy: 0.9614 - val_loss: 3.6601 - val_accuracy: 0.4800\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2391 - accuracy: 0.9614 - val_loss: 3.6668 - val_accuracy: 0.4767\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2392 - accuracy: 0.9629 - val_loss: 3.6477 - val_accuracy: 0.4767\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2388 - accuracy: 0.9600 - val_loss: 3.6650 - val_accuracy: 0.4833\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2389 - accuracy: 0.9614 - val_loss: 3.6537 - val_accuracy: 0.4800\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2390 - accuracy: 0.9571 - val_loss: 3.6796 - val_accuracy: 0.4833\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2385 - accuracy: 0.9629 - val_loss: 3.6667 - val_accuracy: 0.4833\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2389 - accuracy: 0.9629 - val_loss: 3.6751 - val_accuracy: 0.4833\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2388 - accuracy: 0.9614 - val_loss: 3.6682 - val_accuracy: 0.4800\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2387 - accuracy: 0.9614 - val_loss: 3.6728 - val_accuracy: 0.4867\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2386 - accuracy: 0.9614 - val_loss: 3.7189 - val_accuracy: 0.4867\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2396 - accuracy: 0.9557 - val_loss: 3.6915 - val_accuracy: 0.4833\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2386 - accuracy: 0.9643 - val_loss: 3.6871 - val_accuracy: 0.4800\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2383 - accuracy: 0.9629 - val_loss: 3.6897 - val_accuracy: 0.4833\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2382 - accuracy: 0.9614 - val_loss: 3.6797 - val_accuracy: 0.4833\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2380 - accuracy: 0.9600 - val_loss: 3.6877 - val_accuracy: 0.4800\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2377 - accuracy: 0.9586 - val_loss: 3.6678 - val_accuracy: 0.4833\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2376 - accuracy: 0.9600 - val_loss: 3.6937 - val_accuracy: 0.4800\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2379 - accuracy: 0.9614 - val_loss: 3.6918 - val_accuracy: 0.4767\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2379 - accuracy: 0.9629 - val_loss: 3.6911 - val_accuracy: 0.4800\n",
      "Epoch 1927/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 0.2374 - accuracy: 0.9629 - val_loss: 3.7053 - val_accuracy: 0.4867\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2369 - accuracy: 0.9657 - val_loss: 3.6776 - val_accuracy: 0.4767\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2375 - accuracy: 0.9571 - val_loss: 3.6758 - val_accuracy: 0.4867\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2382 - accuracy: 0.9600 - val_loss: 3.6853 - val_accuracy: 0.4800\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2379 - accuracy: 0.9629 - val_loss: 3.7107 - val_accuracy: 0.4867\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2374 - accuracy: 0.9600 - val_loss: 3.6990 - val_accuracy: 0.4833\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2372 - accuracy: 0.9614 - val_loss: 3.6948 - val_accuracy: 0.4767\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2372 - accuracy: 0.9643 - val_loss: 3.7129 - val_accuracy: 0.4800\n",
      "Epoch 1935/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2367 - accuracy: 0.9629 - val_loss: 3.6996 - val_accuracy: 0.4900\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2372 - accuracy: 0.9614 - val_loss: 3.6956 - val_accuracy: 0.4833\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2376 - accuracy: 0.9643 - val_loss: 3.7148 - val_accuracy: 0.4800\n",
      "Epoch 1938/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2375 - accuracy: 0.9643 - val_loss: 3.6938 - val_accuracy: 0.4800\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2374 - accuracy: 0.9600 - val_loss: 3.7065 - val_accuracy: 0.4800\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2365 - accuracy: 0.9629 - val_loss: 3.6933 - val_accuracy: 0.4867\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2370 - accuracy: 0.9586 - val_loss: 3.7113 - val_accuracy: 0.4833\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2370 - accuracy: 0.9643 - val_loss: 3.6945 - val_accuracy: 0.4867\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2368 - accuracy: 0.9629 - val_loss: 3.7120 - val_accuracy: 0.4833\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2367 - accuracy: 0.9614 - val_loss: 3.7053 - val_accuracy: 0.4833\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2368 - accuracy: 0.9629 - val_loss: 3.6943 - val_accuracy: 0.4833\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2369 - accuracy: 0.9643 - val_loss: 3.7072 - val_accuracy: 0.4833\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2366 - accuracy: 0.9629 - val_loss: 3.7251 - val_accuracy: 0.4800\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2365 - accuracy: 0.9614 - val_loss: 3.7027 - val_accuracy: 0.4767\n",
      "Epoch 1949/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2363 - accuracy: 0.9586 - val_loss: 3.7334 - val_accuracy: 0.4833\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2361 - accuracy: 0.9614 - val_loss: 3.7193 - val_accuracy: 0.4833\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2358 - accuracy: 0.9614 - val_loss: 3.7186 - val_accuracy: 0.4800\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2362 - accuracy: 0.9643 - val_loss: 3.7385 - val_accuracy: 0.4867\n",
      "Epoch 1953/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2362 - accuracy: 0.9600 - val_loss: 3.7110 - val_accuracy: 0.4800\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2359 - accuracy: 0.9614 - val_loss: 3.7181 - val_accuracy: 0.4833\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2363 - accuracy: 0.9614 - val_loss: 3.7382 - val_accuracy: 0.4867\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2357 - accuracy: 0.9614 - val_loss: 3.7276 - val_accuracy: 0.4867\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.2357 - accuracy: 0.9600 - val_loss: 3.7074 - val_accuracy: 0.4800\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2359 - accuracy: 0.9600 - val_loss: 3.7344 - val_accuracy: 0.4833\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2358 - accuracy: 0.9614 - val_loss: 3.7225 - val_accuracy: 0.4800\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2356 - accuracy: 0.9629 - val_loss: 3.7239 - val_accuracy: 0.4833\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2357 - accuracy: 0.9643 - val_loss: 3.7458 - val_accuracy: 0.4833\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2356 - accuracy: 0.9643 - val_loss: 3.7190 - val_accuracy: 0.4800\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2355 - accuracy: 0.9600 - val_loss: 3.7655 - val_accuracy: 0.4833\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2353 - accuracy: 0.9614 - val_loss: 3.7376 - val_accuracy: 0.4833\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2353 - accuracy: 0.9614 - val_loss: 3.7316 - val_accuracy: 0.4800\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2353 - accuracy: 0.9629 - val_loss: 3.7335 - val_accuracy: 0.4833\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2354 - accuracy: 0.9629 - val_loss: 3.7391 - val_accuracy: 0.4833\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2353 - accuracy: 0.9614 - val_loss: 3.7438 - val_accuracy: 0.4833\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2351 - accuracy: 0.9614 - val_loss: 3.7574 - val_accuracy: 0.4867\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2348 - accuracy: 0.9629 - val_loss: 3.7330 - val_accuracy: 0.4800\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2348 - accuracy: 0.9614 - val_loss: 3.7331 - val_accuracy: 0.4800\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2353 - accuracy: 0.9629 - val_loss: 3.7342 - val_accuracy: 0.4833\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2347 - accuracy: 0.9629 - val_loss: 3.7407 - val_accuracy: 0.4833\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2351 - accuracy: 0.9629 - val_loss: 3.7366 - val_accuracy: 0.4800\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2344 - accuracy: 0.9629 - val_loss: 3.7533 - val_accuracy: 0.4800\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2344 - accuracy: 0.9614 - val_loss: 3.7529 - val_accuracy: 0.4800\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2345 - accuracy: 0.9614 - val_loss: 3.7562 - val_accuracy: 0.4833\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2347 - accuracy: 0.9657 - val_loss: 3.7610 - val_accuracy: 0.4867\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2342 - accuracy: 0.9614 - val_loss: 3.7501 - val_accuracy: 0.4867\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2346 - accuracy: 0.9586 - val_loss: 3.7522 - val_accuracy: 0.4833\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2343 - accuracy: 0.9600 - val_loss: 3.7666 - val_accuracy: 0.4833\n",
      "Epoch 1982/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 0.2343 - accuracy: 0.9629 - val_loss: 3.7374 - val_accuracy: 0.4867\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2342 - accuracy: 0.9643 - val_loss: 3.7629 - val_accuracy: 0.4867\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2343 - accuracy: 0.9600 - val_loss: 3.7597 - val_accuracy: 0.4833\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2336 - accuracy: 0.9586 - val_loss: 3.7332 - val_accuracy: 0.4867\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2339 - accuracy: 0.9614 - val_loss: 3.7650 - val_accuracy: 0.4833\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2343 - accuracy: 0.9643 - val_loss: 3.7528 - val_accuracy: 0.4833\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2335 - accuracy: 0.9629 - val_loss: 3.7643 - val_accuracy: 0.4833\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2339 - accuracy: 0.9629 - val_loss: 3.7695 - val_accuracy: 0.4900\n",
      "Epoch 1990/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2339 - accuracy: 0.9600 - val_loss: 3.7458 - val_accuracy: 0.4800\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2340 - accuracy: 0.9600 - val_loss: 3.7654 - val_accuracy: 0.4833\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2332 - accuracy: 0.9643 - val_loss: 3.7491 - val_accuracy: 0.4867\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2339 - accuracy: 0.9571 - val_loss: 3.7578 - val_accuracy: 0.4800\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2337 - accuracy: 0.9614 - val_loss: 3.7424 - val_accuracy: 0.4767\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2333 - accuracy: 0.9600 - val_loss: 3.7899 - val_accuracy: 0.4867\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2333 - accuracy: 0.9643 - val_loss: 3.7830 - val_accuracy: 0.4833\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2335 - accuracy: 0.9629 - val_loss: 3.7554 - val_accuracy: 0.4800\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.2333 - accuracy: 0.9643 - val_loss: 3.7680 - val_accuracy: 0.4800\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2329 - accuracy: 0.9614 - val_loss: 3.7788 - val_accuracy: 0.4833\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2330 - accuracy: 0.9629 - val_loss: 3.7701 - val_accuracy: 0.4800\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2334 - accuracy: 0.9600 - val_loss: 3.7598 - val_accuracy: 0.4800\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2330 - accuracy: 0.9600 - val_loss: 3.7772 - val_accuracy: 0.4800\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2330 - accuracy: 0.9571 - val_loss: 3.7736 - val_accuracy: 0.4867\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2329 - accuracy: 0.9657 - val_loss: 3.7701 - val_accuracy: 0.4800\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2328 - accuracy: 0.9643 - val_loss: 3.7645 - val_accuracy: 0.4767\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2328 - accuracy: 0.9614 - val_loss: 3.7749 - val_accuracy: 0.4800\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.2327 - accuracy: 0.9643 - val_loss: 3.7703 - val_accuracy: 0.4867\n",
      "Epoch 2008/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2322 - accuracy: 0.9629 - val_loss: 3.7673 - val_accuracy: 0.4833\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2327 - accuracy: 0.9643 - val_loss: 3.7920 - val_accuracy: 0.4867\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2323 - accuracy: 0.9614 - val_loss: 3.7957 - val_accuracy: 0.4867\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2326 - accuracy: 0.9643 - val_loss: 3.7965 - val_accuracy: 0.4833\n",
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2324 - accuracy: 0.9614 - val_loss: 3.7694 - val_accuracy: 0.4733\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2327 - accuracy: 0.9629 - val_loss: 3.7970 - val_accuracy: 0.4833\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2319 - accuracy: 0.9614 - val_loss: 3.7946 - val_accuracy: 0.4833\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2319 - accuracy: 0.9600 - val_loss: 3.7981 - val_accuracy: 0.4833\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2324 - accuracy: 0.9629 - val_loss: 3.7717 - val_accuracy: 0.4767\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2318 - accuracy: 0.9600 - val_loss: 3.7922 - val_accuracy: 0.4833\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2321 - accuracy: 0.9614 - val_loss: 3.8027 - val_accuracy: 0.4900\n",
      "Epoch 2019/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2319 - accuracy: 0.9586 - val_loss: 3.8190 - val_accuracy: 0.4867\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2321 - accuracy: 0.9643 - val_loss: 3.8078 - val_accuracy: 0.4800\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2315 - accuracy: 0.9629 - val_loss: 3.7795 - val_accuracy: 0.4867\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2315 - accuracy: 0.9629 - val_loss: 3.8044 - val_accuracy: 0.4833\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2317 - accuracy: 0.9629 - val_loss: 3.7983 - val_accuracy: 0.4800\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2314 - accuracy: 0.9600 - val_loss: 3.7999 - val_accuracy: 0.4800\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2319 - accuracy: 0.9629 - val_loss: 3.7753 - val_accuracy: 0.4733\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2316 - accuracy: 0.9629 - val_loss: 3.7800 - val_accuracy: 0.4767\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2316 - accuracy: 0.9629 - val_loss: 3.8237 - val_accuracy: 0.4800\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2315 - accuracy: 0.9614 - val_loss: 3.8032 - val_accuracy: 0.4767\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2314 - accuracy: 0.9586 - val_loss: 3.7983 - val_accuracy: 0.4833\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2311 - accuracy: 0.9657 - val_loss: 3.8004 - val_accuracy: 0.4767\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2312 - accuracy: 0.9643 - val_loss: 3.7944 - val_accuracy: 0.4833\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2307 - accuracy: 0.9629 - val_loss: 3.7922 - val_accuracy: 0.4833\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2309 - accuracy: 0.9657 - val_loss: 3.8039 - val_accuracy: 0.4867\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2312 - accuracy: 0.9614 - val_loss: 3.8066 - val_accuracy: 0.4833\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2309 - accuracy: 0.9657 - val_loss: 3.8244 - val_accuracy: 0.4800\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2312 - accuracy: 0.9614 - val_loss: 3.8336 - val_accuracy: 0.4833\n",
      "Epoch 2037/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.2310 - accuracy: 0.9643 - val_loss: 3.8231 - val_accuracy: 0.4800\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2311 - accuracy: 0.9629 - val_loss: 3.8190 - val_accuracy: 0.4867\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.2307 - accuracy: 0.9629 - val_loss: 3.8157 - val_accuracy: 0.4900\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2306 - accuracy: 0.9643 - val_loss: 3.8133 - val_accuracy: 0.4867\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2306 - accuracy: 0.9629 - val_loss: 3.8264 - val_accuracy: 0.4767\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2303 - accuracy: 0.9629 - val_loss: 3.8198 - val_accuracy: 0.4833\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2307 - accuracy: 0.9614 - val_loss: 3.8336 - val_accuracy: 0.4833\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2305 - accuracy: 0.9643 - val_loss: 3.8185 - val_accuracy: 0.4833\n",
      "Epoch 2045/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2307 - accuracy: 0.9600 - val_loss: 3.8239 - val_accuracy: 0.4833\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2300 - accuracy: 0.9643 - val_loss: 3.8263 - val_accuracy: 0.4867\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2303 - accuracy: 0.9600 - val_loss: 3.8217 - val_accuracy: 0.4800\n",
      "Epoch 2048/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2299 - accuracy: 0.9643 - val_loss: 3.8449 - val_accuracy: 0.4833\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2301 - accuracy: 0.9614 - val_loss: 3.7991 - val_accuracy: 0.4833\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2302 - accuracy: 0.9600 - val_loss: 3.8353 - val_accuracy: 0.4833\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2303 - accuracy: 0.9643 - val_loss: 3.8508 - val_accuracy: 0.4867\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2299 - accuracy: 0.9600 - val_loss: 3.8275 - val_accuracy: 0.4867\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2296 - accuracy: 0.9614 - val_loss: 3.8248 - val_accuracy: 0.4867\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2294 - accuracy: 0.9629 - val_loss: 3.8225 - val_accuracy: 0.4867\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2300 - accuracy: 0.9614 - val_loss: 3.8225 - val_accuracy: 0.4900\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2298 - accuracy: 0.9629 - val_loss: 3.8485 - val_accuracy: 0.4867\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2295 - accuracy: 0.9643 - val_loss: 3.8364 - val_accuracy: 0.4867\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2300 - accuracy: 0.9629 - val_loss: 3.8195 - val_accuracy: 0.4833\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2297 - accuracy: 0.9629 - val_loss: 3.8231 - val_accuracy: 0.4867\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2292 - accuracy: 0.9643 - val_loss: 3.8298 - val_accuracy: 0.4867\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2296 - accuracy: 0.9629 - val_loss: 3.8156 - val_accuracy: 0.4833\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2297 - accuracy: 0.9629 - val_loss: 3.8138 - val_accuracy: 0.4833\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2291 - accuracy: 0.9643 - val_loss: 3.8278 - val_accuracy: 0.4833\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2289 - accuracy: 0.9629 - val_loss: 3.8387 - val_accuracy: 0.4867\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2295 - accuracy: 0.9614 - val_loss: 3.8680 - val_accuracy: 0.4867\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2294 - accuracy: 0.9643 - val_loss: 3.8602 - val_accuracy: 0.4933\n",
      "Epoch 2067/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2296 - accuracy: 0.9657 - val_loss: 3.8322 - val_accuracy: 0.4833\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2291 - accuracy: 0.9614 - val_loss: 3.8564 - val_accuracy: 0.4833\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2292 - accuracy: 0.9629 - val_loss: 3.8290 - val_accuracy: 0.4800\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2287 - accuracy: 0.9657 - val_loss: 3.8604 - val_accuracy: 0.4800\n",
      "Epoch 2071/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2290 - accuracy: 0.9614 - val_loss: 3.8525 - val_accuracy: 0.4867\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2288 - accuracy: 0.9629 - val_loss: 3.8494 - val_accuracy: 0.4800\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2292 - accuracy: 0.9600 - val_loss: 3.8503 - val_accuracy: 0.4833\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2285 - accuracy: 0.9629 - val_loss: 3.8810 - val_accuracy: 0.4767\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2288 - accuracy: 0.9600 - val_loss: 3.8396 - val_accuracy: 0.4833\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2288 - accuracy: 0.9614 - val_loss: 3.8458 - val_accuracy: 0.4900\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2283 - accuracy: 0.9629 - val_loss: 3.8418 - val_accuracy: 0.4833\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2283 - accuracy: 0.9643 - val_loss: 3.8586 - val_accuracy: 0.4833\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2283 - accuracy: 0.9614 - val_loss: 3.8412 - val_accuracy: 0.4800\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2287 - accuracy: 0.9629 - val_loss: 3.8403 - val_accuracy: 0.4767\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2280 - accuracy: 0.9643 - val_loss: 3.8452 - val_accuracy: 0.4800\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2280 - accuracy: 0.9657 - val_loss: 3.8293 - val_accuracy: 0.4833\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2281 - accuracy: 0.9629 - val_loss: 3.8423 - val_accuracy: 0.4867\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2281 - accuracy: 0.9600 - val_loss: 3.8665 - val_accuracy: 0.4833\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2280 - accuracy: 0.9643 - val_loss: 3.8434 - val_accuracy: 0.4833\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2280 - accuracy: 0.9614 - val_loss: 3.8569 - val_accuracy: 0.4867\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2280 - accuracy: 0.9643 - val_loss: 3.8513 - val_accuracy: 0.4833\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2280 - accuracy: 0.9614 - val_loss: 3.8562 - val_accuracy: 0.4900\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2277 - accuracy: 0.9657 - val_loss: 3.8433 - val_accuracy: 0.4867\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2279 - accuracy: 0.9643 - val_loss: 3.8573 - val_accuracy: 0.4900\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2279 - accuracy: 0.9643 - val_loss: 3.8794 - val_accuracy: 0.4933\n",
      "Epoch 2092/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 0.2278 - accuracy: 0.9614 - val_loss: 3.8648 - val_accuracy: 0.4867\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2273 - accuracy: 0.9657 - val_loss: 3.8618 - val_accuracy: 0.4800\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2275 - accuracy: 0.9657 - val_loss: 3.8555 - val_accuracy: 0.4833\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2276 - accuracy: 0.9629 - val_loss: 3.8896 - val_accuracy: 0.4767\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2278 - accuracy: 0.9643 - val_loss: 3.8618 - val_accuracy: 0.4833\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2275 - accuracy: 0.9657 - val_loss: 3.8801 - val_accuracy: 0.4833\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2275 - accuracy: 0.9657 - val_loss: 3.8676 - val_accuracy: 0.4867\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2267 - accuracy: 0.9629 - val_loss: 3.8664 - val_accuracy: 0.4833\n",
      "Epoch 2100/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2271 - accuracy: 0.9643 - val_loss: 3.8982 - val_accuracy: 0.4767\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2274 - accuracy: 0.9643 - val_loss: 3.8673 - val_accuracy: 0.4867\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2273 - accuracy: 0.9643 - val_loss: 3.9033 - val_accuracy: 0.4767\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2267 - accuracy: 0.9657 - val_loss: 3.8404 - val_accuracy: 0.4800\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2272 - accuracy: 0.9614 - val_loss: 3.8674 - val_accuracy: 0.4800\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2273 - accuracy: 0.9657 - val_loss: 3.8909 - val_accuracy: 0.4833\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2269 - accuracy: 0.9657 - val_loss: 3.8682 - val_accuracy: 0.4800\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2270 - accuracy: 0.9643 - val_loss: 3.8845 - val_accuracy: 0.4900\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2265 - accuracy: 0.9629 - val_loss: 3.8742 - val_accuracy: 0.4833\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2273 - accuracy: 0.9600 - val_loss: 3.8880 - val_accuracy: 0.4867\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2273 - accuracy: 0.9614 - val_loss: 3.8956 - val_accuracy: 0.4800\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2267 - accuracy: 0.9629 - val_loss: 3.8798 - val_accuracy: 0.4900\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2266 - accuracy: 0.9643 - val_loss: 3.8599 - val_accuracy: 0.4800\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2265 - accuracy: 0.9614 - val_loss: 3.8860 - val_accuracy: 0.4800\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2261 - accuracy: 0.9643 - val_loss: 3.8826 - val_accuracy: 0.4900\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2265 - accuracy: 0.9657 - val_loss: 3.8931 - val_accuracy: 0.4933\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2265 - accuracy: 0.9600 - val_loss: 3.8874 - val_accuracy: 0.4833\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2266 - accuracy: 0.9600 - val_loss: 3.9087 - val_accuracy: 0.4867\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2259 - accuracy: 0.9629 - val_loss: 3.8780 - val_accuracy: 0.4833\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2262 - accuracy: 0.9657 - val_loss: 3.8807 - val_accuracy: 0.4833\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2264 - accuracy: 0.9643 - val_loss: 3.8830 - val_accuracy: 0.4900\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2256 - accuracy: 0.9629 - val_loss: 3.8918 - val_accuracy: 0.4833\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.2258 - accuracy: 0.9614 - val_loss: 3.9082 - val_accuracy: 0.4900\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2256 - accuracy: 0.9657 - val_loss: 3.8883 - val_accuracy: 0.4833\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2255 - accuracy: 0.9643 - val_loss: 3.8685 - val_accuracy: 0.4767\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2259 - accuracy: 0.9629 - val_loss: 3.9202 - val_accuracy: 0.4833\n",
      "Epoch 2126/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2260 - accuracy: 0.9586 - val_loss: 3.9088 - val_accuracy: 0.4900\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2257 - accuracy: 0.9629 - val_loss: 3.8827 - val_accuracy: 0.4867\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2254 - accuracy: 0.9614 - val_loss: 3.9055 - val_accuracy: 0.4900\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2253 - accuracy: 0.9643 - val_loss: 3.9030 - val_accuracy: 0.4833\n",
      "Epoch 2130/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2255 - accuracy: 0.9643 - val_loss: 3.8841 - val_accuracy: 0.4867\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2253 - accuracy: 0.9643 - val_loss: 3.9097 - val_accuracy: 0.4833\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2251 - accuracy: 0.9643 - val_loss: 3.8789 - val_accuracy: 0.4800\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2255 - accuracy: 0.9629 - val_loss: 3.8962 - val_accuracy: 0.4867\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2255 - accuracy: 0.9657 - val_loss: 3.8959 - val_accuracy: 0.4867\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2254 - accuracy: 0.9614 - val_loss: 3.8863 - val_accuracy: 0.4833\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2250 - accuracy: 0.9629 - val_loss: 3.9012 - val_accuracy: 0.4833\n",
      "Epoch 2137/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2251 - accuracy: 0.9643 - val_loss: 3.8802 - val_accuracy: 0.4767\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2253 - accuracy: 0.9643 - val_loss: 3.9062 - val_accuracy: 0.4900\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2251 - accuracy: 0.9614 - val_loss: 3.8938 - val_accuracy: 0.4833\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2249 - accuracy: 0.9600 - val_loss: 3.9139 - val_accuracy: 0.4867\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2248 - accuracy: 0.9643 - val_loss: 3.9128 - val_accuracy: 0.4833\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2248 - accuracy: 0.9629 - val_loss: 3.9293 - val_accuracy: 0.4767\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2245 - accuracy: 0.9643 - val_loss: 3.8960 - val_accuracy: 0.4733\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2245 - accuracy: 0.9643 - val_loss: 3.9270 - val_accuracy: 0.4833\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2247 - accuracy: 0.9629 - val_loss: 3.9319 - val_accuracy: 0.4867\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2246 - accuracy: 0.9614 - val_loss: 3.8999 - val_accuracy: 0.4800\n",
      "Epoch 2147/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.2244 - accuracy: 0.9629 - val_loss: 3.9255 - val_accuracy: 0.4933\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2244 - accuracy: 0.9643 - val_loss: 3.9261 - val_accuracy: 0.4867\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2245 - accuracy: 0.9600 - val_loss: 3.9649 - val_accuracy: 0.4800\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2246 - accuracy: 0.9629 - val_loss: 3.9154 - val_accuracy: 0.4867\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2245 - accuracy: 0.9657 - val_loss: 3.9162 - val_accuracy: 0.4867\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2245 - accuracy: 0.9643 - val_loss: 3.9259 - val_accuracy: 0.4900\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2241 - accuracy: 0.9600 - val_loss: 3.9445 - val_accuracy: 0.4867\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2243 - accuracy: 0.9614 - val_loss: 3.9255 - val_accuracy: 0.4900\n",
      "Epoch 2155/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2236 - accuracy: 0.9629 - val_loss: 3.9181 - val_accuracy: 0.4867\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2240 - accuracy: 0.9629 - val_loss: 3.9295 - val_accuracy: 0.4867\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2237 - accuracy: 0.9643 - val_loss: 3.9232 - val_accuracy: 0.4867\n",
      "Epoch 2158/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2240 - accuracy: 0.9643 - val_loss: 3.9178 - val_accuracy: 0.4833\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2239 - accuracy: 0.9629 - val_loss: 3.9431 - val_accuracy: 0.4900\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2237 - accuracy: 0.9643 - val_loss: 3.9429 - val_accuracy: 0.4833\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2237 - accuracy: 0.9657 - val_loss: 3.9209 - val_accuracy: 0.4867\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2239 - accuracy: 0.9643 - val_loss: 3.9483 - val_accuracy: 0.4900\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.2237 - accuracy: 0.9600 - val_loss: 3.9403 - val_accuracy: 0.4900\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2236 - accuracy: 0.9643 - val_loss: 3.9254 - val_accuracy: 0.4867\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2234 - accuracy: 0.9643 - val_loss: 3.9170 - val_accuracy: 0.4833\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2237 - accuracy: 0.9614 - val_loss: 3.9254 - val_accuracy: 0.4900\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2237 - accuracy: 0.9614 - val_loss: 3.9408 - val_accuracy: 0.4900\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2230 - accuracy: 0.9643 - val_loss: 3.9383 - val_accuracy: 0.4867\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2237 - accuracy: 0.9643 - val_loss: 3.9518 - val_accuracy: 0.4867\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2237 - accuracy: 0.9629 - val_loss: 3.9728 - val_accuracy: 0.4867\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2235 - accuracy: 0.9629 - val_loss: 3.9550 - val_accuracy: 0.4833\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2236 - accuracy: 0.9629 - val_loss: 3.9557 - val_accuracy: 0.4933\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2231 - accuracy: 0.9629 - val_loss: 3.9425 - val_accuracy: 0.4867\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2230 - accuracy: 0.9629 - val_loss: 3.9256 - val_accuracy: 0.4900\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2227 - accuracy: 0.9643 - val_loss: 3.9609 - val_accuracy: 0.4833\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2227 - accuracy: 0.9643 - val_loss: 3.9674 - val_accuracy: 0.4900\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2229 - accuracy: 0.9643 - val_loss: 3.9449 - val_accuracy: 0.4867\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2229 - accuracy: 0.9614 - val_loss: 3.9667 - val_accuracy: 0.4900\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2229 - accuracy: 0.9657 - val_loss: 3.9664 - val_accuracy: 0.4900\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2233 - accuracy: 0.9614 - val_loss: 3.9356 - val_accuracy: 0.4933\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2226 - accuracy: 0.9657 - val_loss: 3.9554 - val_accuracy: 0.4933\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2228 - accuracy: 0.9643 - val_loss: 3.9465 - val_accuracy: 0.4833\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2228 - accuracy: 0.9643 - val_loss: 3.9529 - val_accuracy: 0.4933\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2229 - accuracy: 0.9643 - val_loss: 3.9522 - val_accuracy: 0.4867\n",
      "Epoch 2185/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2229 - accuracy: 0.9586 - val_loss: 3.9164 - val_accuracy: 0.4767\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2228 - accuracy: 0.9629 - val_loss: 3.9677 - val_accuracy: 0.4800\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2221 - accuracy: 0.9629 - val_loss: 3.9681 - val_accuracy: 0.4867\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2223 - accuracy: 0.9629 - val_loss: 3.9472 - val_accuracy: 0.4800\n",
      "Epoch 2189/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2221 - accuracy: 0.9629 - val_loss: 3.9821 - val_accuracy: 0.4867\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2219 - accuracy: 0.9657 - val_loss: 3.9463 - val_accuracy: 0.4800\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2223 - accuracy: 0.9629 - val_loss: 3.9320 - val_accuracy: 0.4767\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2219 - accuracy: 0.9629 - val_loss: 3.9345 - val_accuracy: 0.4800\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2223 - accuracy: 0.9643 - val_loss: 3.9631 - val_accuracy: 0.4933\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2219 - accuracy: 0.9643 - val_loss: 3.9687 - val_accuracy: 0.4833\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2218 - accuracy: 0.9643 - val_loss: 3.9687 - val_accuracy: 0.4900\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2222 - accuracy: 0.9657 - val_loss: 3.9684 - val_accuracy: 0.4867\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2218 - accuracy: 0.9657 - val_loss: 4.0077 - val_accuracy: 0.4833\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2216 - accuracy: 0.9643 - val_loss: 4.0036 - val_accuracy: 0.4833\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2220 - accuracy: 0.9629 - val_loss: 3.9802 - val_accuracy: 0.4833\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2218 - accuracy: 0.9614 - val_loss: 3.9620 - val_accuracy: 0.4900\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2217 - accuracy: 0.9643 - val_loss: 3.9931 - val_accuracy: 0.4867\n",
      "Epoch 2202/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 101us/step - loss: 0.2216 - accuracy: 0.9657 - val_loss: 3.9974 - val_accuracy: 0.4833\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2214 - accuracy: 0.9629 - val_loss: 3.9788 - val_accuracy: 0.4900\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2215 - accuracy: 0.9614 - val_loss: 3.9890 - val_accuracy: 0.4867\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2218 - accuracy: 0.9657 - val_loss: 3.9830 - val_accuracy: 0.4933\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2216 - accuracy: 0.9657 - val_loss: 3.9835 - val_accuracy: 0.4867\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2212 - accuracy: 0.9643 - val_loss: 4.0137 - val_accuracy: 0.4833\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.2214 - accuracy: 0.9600 - val_loss: 3.9751 - val_accuracy: 0.4867\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2207 - accuracy: 0.9657 - val_loss: 4.0263 - val_accuracy: 0.4867\n",
      "Epoch 2210/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2217 - accuracy: 0.9629 - val_loss: 3.9908 - val_accuracy: 0.4833\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2210 - accuracy: 0.9629 - val_loss: 3.9760 - val_accuracy: 0.4867\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2212 - accuracy: 0.9643 - val_loss: 3.9770 - val_accuracy: 0.4867\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2210 - accuracy: 0.9657 - val_loss: 3.9985 - val_accuracy: 0.4833\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2208 - accuracy: 0.9643 - val_loss: 3.9942 - val_accuracy: 0.4933\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2211 - accuracy: 0.9629 - val_loss: 3.9767 - val_accuracy: 0.4900\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2207 - accuracy: 0.9614 - val_loss: 3.9846 - val_accuracy: 0.4933\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2208 - accuracy: 0.9629 - val_loss: 3.9995 - val_accuracy: 0.4900\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2208 - accuracy: 0.9657 - val_loss: 3.9886 - val_accuracy: 0.4833\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2204 - accuracy: 0.9629 - val_loss: 3.9597 - val_accuracy: 0.4800\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2208 - accuracy: 0.9643 - val_loss: 3.9978 - val_accuracy: 0.4900\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2205 - accuracy: 0.9657 - val_loss: 3.9865 - val_accuracy: 0.4867\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2203 - accuracy: 0.9643 - val_loss: 3.9935 - val_accuracy: 0.4900\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2204 - accuracy: 0.9643 - val_loss: 3.9922 - val_accuracy: 0.4867\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2208 - accuracy: 0.9657 - val_loss: 3.9949 - val_accuracy: 0.4900\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2206 - accuracy: 0.9600 - val_loss: 4.0246 - val_accuracy: 0.4833\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2211 - accuracy: 0.9629 - val_loss: 3.9764 - val_accuracy: 0.4867\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2203 - accuracy: 0.9600 - val_loss: 3.9991 - val_accuracy: 0.4867\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2203 - accuracy: 0.9643 - val_loss: 4.0125 - val_accuracy: 0.4900\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2203 - accuracy: 0.9614 - val_loss: 4.0107 - val_accuracy: 0.4900\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2200 - accuracy: 0.9657 - val_loss: 4.0005 - val_accuracy: 0.4900\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2202 - accuracy: 0.9657 - val_loss: 4.0038 - val_accuracy: 0.4867\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2205 - accuracy: 0.9600 - val_loss: 4.0044 - val_accuracy: 0.4900\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2208 - accuracy: 0.9643 - val_loss: 4.0081 - val_accuracy: 0.4867\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2195 - accuracy: 0.9657 - val_loss: 4.0050 - val_accuracy: 0.4900\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2190 - accuracy: 0.9657 - val_loss: 4.0433 - val_accuracy: 0.4900\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2193 - accuracy: 0.9657 - val_loss: 4.0317 - val_accuracy: 0.4833\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2187 - accuracy: 0.9671 - val_loss: 3.9815 - val_accuracy: 0.4800\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2183 - accuracy: 0.9629 - val_loss: 3.9962 - val_accuracy: 0.4867\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2187 - accuracy: 0.9643 - val_loss: 4.0056 - val_accuracy: 0.4867\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2182 - accuracy: 0.9671 - val_loss: 4.0111 - val_accuracy: 0.4867\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2182 - accuracy: 0.9643 - val_loss: 4.0174 - val_accuracy: 0.4900\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2181 - accuracy: 0.9657 - val_loss: 4.0062 - val_accuracy: 0.4867\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2183 - accuracy: 0.9671 - val_loss: 4.0047 - val_accuracy: 0.4867\n",
      "Epoch 2244/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2180 - accuracy: 0.9643 - val_loss: 4.0236 - val_accuracy: 0.4833\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2176 - accuracy: 0.9643 - val_loss: 4.0177 - val_accuracy: 0.4900\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.2179 - accuracy: 0.9671 - val_loss: 4.0265 - val_accuracy: 0.4900\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2181 - accuracy: 0.9629 - val_loss: 3.9972 - val_accuracy: 0.4833\n",
      "Epoch 2248/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2176 - accuracy: 0.9657 - val_loss: 3.9872 - val_accuracy: 0.4800\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2181 - accuracy: 0.9643 - val_loss: 4.0341 - val_accuracy: 0.4900\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2177 - accuracy: 0.9614 - val_loss: 4.0140 - val_accuracy: 0.4867\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2175 - accuracy: 0.9629 - val_loss: 4.0283 - val_accuracy: 0.4900\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2175 - accuracy: 0.9671 - val_loss: 3.9992 - val_accuracy: 0.4867\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2171 - accuracy: 0.9657 - val_loss: 4.0241 - val_accuracy: 0.4867\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2175 - accuracy: 0.9643 - val_loss: 4.0542 - val_accuracy: 0.4833\n",
      "Epoch 2255/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2175 - accuracy: 0.9643 - val_loss: 4.0299 - val_accuracy: 0.4867\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2170 - accuracy: 0.9671 - val_loss: 4.0215 - val_accuracy: 0.4867\n",
      "Epoch 2257/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 0.2171 - accuracy: 0.9629 - val_loss: 4.0337 - val_accuracy: 0.4867\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2176 - accuracy: 0.9657 - val_loss: 4.0435 - val_accuracy: 0.4900\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2171 - accuracy: 0.9657 - val_loss: 4.0178 - val_accuracy: 0.4867\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2172 - accuracy: 0.9643 - val_loss: 4.0357 - val_accuracy: 0.4867\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2170 - accuracy: 0.9671 - val_loss: 4.0496 - val_accuracy: 0.4833\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2170 - accuracy: 0.9671 - val_loss: 4.0217 - val_accuracy: 0.4867\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2168 - accuracy: 0.9657 - val_loss: 4.0420 - val_accuracy: 0.4833\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2168 - accuracy: 0.9657 - val_loss: 4.0416 - val_accuracy: 0.4833\n",
      "Epoch 2265/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2165 - accuracy: 0.9643 - val_loss: 4.0431 - val_accuracy: 0.4900\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2163 - accuracy: 0.9671 - val_loss: 4.0646 - val_accuracy: 0.4833\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2172 - accuracy: 0.9643 - val_loss: 4.0385 - val_accuracy: 0.4867\n",
      "Epoch 2268/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2165 - accuracy: 0.9671 - val_loss: 4.0405 - val_accuracy: 0.4867\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2164 - accuracy: 0.9671 - val_loss: 4.0688 - val_accuracy: 0.4833\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2170 - accuracy: 0.9643 - val_loss: 4.0485 - val_accuracy: 0.4867\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2164 - accuracy: 0.9657 - val_loss: 4.0409 - val_accuracy: 0.4867\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2165 - accuracy: 0.9657 - val_loss: 4.0352 - val_accuracy: 0.4867\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2164 - accuracy: 0.9671 - val_loss: 4.0595 - val_accuracy: 0.4833\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2160 - accuracy: 0.9657 - val_loss: 4.0315 - val_accuracy: 0.4867\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2164 - accuracy: 0.9671 - val_loss: 4.0590 - val_accuracy: 0.4833\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2164 - accuracy: 0.9671 - val_loss: 4.0427 - val_accuracy: 0.4867\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2164 - accuracy: 0.9671 - val_loss: 4.0406 - val_accuracy: 0.4867\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2159 - accuracy: 0.9657 - val_loss: 4.0731 - val_accuracy: 0.4867\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2158 - accuracy: 0.9643 - val_loss: 4.0582 - val_accuracy: 0.4900\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2163 - accuracy: 0.9657 - val_loss: 4.0342 - val_accuracy: 0.4867\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2165 - accuracy: 0.9643 - val_loss: 4.0479 - val_accuracy: 0.4867\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2157 - accuracy: 0.9643 - val_loss: 4.0645 - val_accuracy: 0.4833\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2162 - accuracy: 0.9643 - val_loss: 4.0689 - val_accuracy: 0.4833\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2158 - accuracy: 0.9657 - val_loss: 4.0561 - val_accuracy: 0.4867\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2159 - accuracy: 0.9657 - val_loss: 4.0620 - val_accuracy: 0.4867\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2159 - accuracy: 0.9671 - val_loss: 4.0659 - val_accuracy: 0.4833\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2153 - accuracy: 0.9657 - val_loss: 4.0330 - val_accuracy: 0.4833\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.2154 - accuracy: 0.9600 - val_loss: 4.0731 - val_accuracy: 0.4900\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2157 - accuracy: 0.9643 - val_loss: 4.0438 - val_accuracy: 0.4867\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2153 - accuracy: 0.9671 - val_loss: 4.0638 - val_accuracy: 0.4867\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2151 - accuracy: 0.9629 - val_loss: 4.0919 - val_accuracy: 0.4833\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2159 - accuracy: 0.9629 - val_loss: 4.0607 - val_accuracy: 0.4867\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2152 - accuracy: 0.9643 - val_loss: 4.0841 - val_accuracy: 0.4833\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2152 - accuracy: 0.9671 - val_loss: 4.0837 - val_accuracy: 0.4833\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2155 - accuracy: 0.9643 - val_loss: 4.0654 - val_accuracy: 0.4867\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2149 - accuracy: 0.9657 - val_loss: 4.0258 - val_accuracy: 0.4733\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2152 - accuracy: 0.9629 - val_loss: 4.0629 - val_accuracy: 0.4867\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2153 - accuracy: 0.9671 - val_loss: 4.0783 - val_accuracy: 0.4833\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2152 - accuracy: 0.9671 - val_loss: 4.0732 - val_accuracy: 0.4867\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2151 - accuracy: 0.9643 - val_loss: 4.0795 - val_accuracy: 0.4900\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 0.2150 - accuracy: 0.9600 - val_loss: 4.0955 - val_accuracy: 0.4867\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 0.2149 - accuracy: 0.9643 - val_loss: 4.0547 - val_accuracy: 0.4867\n",
      "Epoch 2303/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2149 - accuracy: 0.9657 - val_loss: 4.0662 - val_accuracy: 0.4867\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2148 - accuracy: 0.9657 - val_loss: 4.0800 - val_accuracy: 0.4833\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2148 - accuracy: 0.9671 - val_loss: 4.0774 - val_accuracy: 0.4833\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2146 - accuracy: 0.9671 - val_loss: 4.0728 - val_accuracy: 0.4833\n",
      "Epoch 2307/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2148 - accuracy: 0.9671 - val_loss: 4.0620 - val_accuracy: 0.4867\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2148 - accuracy: 0.9629 - val_loss: 4.0752 - val_accuracy: 0.4900\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2148 - accuracy: 0.9657 - val_loss: 4.0742 - val_accuracy: 0.4867\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2141 - accuracy: 0.9657 - val_loss: 4.0506 - val_accuracy: 0.4867\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.96 - 0s 103us/step - loss: 0.2145 - accuracy: 0.9671 - val_loss: 4.0769 - val_accuracy: 0.4900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2146 - accuracy: 0.9657 - val_loss: 4.0764 - val_accuracy: 0.4867\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2148 - accuracy: 0.9657 - val_loss: 4.0879 - val_accuracy: 0.4833\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2143 - accuracy: 0.9643 - val_loss: 4.0731 - val_accuracy: 0.4900\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2144 - accuracy: 0.9671 - val_loss: 4.0848 - val_accuracy: 0.4867\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2144 - accuracy: 0.9671 - val_loss: 4.0835 - val_accuracy: 0.4833\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2141 - accuracy: 0.9671 - val_loss: 4.1007 - val_accuracy: 0.4833\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2140 - accuracy: 0.9657 - val_loss: 4.0962 - val_accuracy: 0.4833\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2137 - accuracy: 0.9657 - val_loss: 4.0778 - val_accuracy: 0.4900\n",
      "Epoch 2320/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2140 - accuracy: 0.9657 - val_loss: 4.1120 - val_accuracy: 0.4833\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2142 - accuracy: 0.9657 - val_loss: 4.0706 - val_accuracy: 0.4900\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2141 - accuracy: 0.9657 - val_loss: 4.1215 - val_accuracy: 0.4833\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2141 - accuracy: 0.9671 - val_loss: 4.1092 - val_accuracy: 0.4867\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2137 - accuracy: 0.9643 - val_loss: 4.0881 - val_accuracy: 0.4867\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2136 - accuracy: 0.9657 - val_loss: 4.1087 - val_accuracy: 0.4833\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2136 - accuracy: 0.9671 - val_loss: 4.1090 - val_accuracy: 0.4900\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2138 - accuracy: 0.9629 - val_loss: 4.0767 - val_accuracy: 0.4833\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.2137 - accuracy: 0.9671 - val_loss: 4.0995 - val_accuracy: 0.4867\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2138 - accuracy: 0.9657 - val_loss: 4.0803 - val_accuracy: 0.4800\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2136 - accuracy: 0.9657 - val_loss: 4.0922 - val_accuracy: 0.4867\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2137 - accuracy: 0.9657 - val_loss: 4.0932 - val_accuracy: 0.4867\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2135 - accuracy: 0.9671 - val_loss: 4.0801 - val_accuracy: 0.4867\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2135 - accuracy: 0.9657 - val_loss: 4.0803 - val_accuracy: 0.4867\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2135 - accuracy: 0.9671 - val_loss: 4.1201 - val_accuracy: 0.4867\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2133 - accuracy: 0.9657 - val_loss: 4.0974 - val_accuracy: 0.4867\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2136 - accuracy: 0.9629 - val_loss: 4.0955 - val_accuracy: 0.4867\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2131 - accuracy: 0.9643 - val_loss: 4.0944 - val_accuracy: 0.4900\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2133 - accuracy: 0.9671 - val_loss: 4.0937 - val_accuracy: 0.4900\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2131 - accuracy: 0.9671 - val_loss: 4.1092 - val_accuracy: 0.4833\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2131 - accuracy: 0.9671 - val_loss: 4.1137 - val_accuracy: 0.4833\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2134 - accuracy: 0.9657 - val_loss: 4.1239 - val_accuracy: 0.4833\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2131 - accuracy: 0.9671 - val_loss: 4.0918 - val_accuracy: 0.4867\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2128 - accuracy: 0.9657 - val_loss: 4.1087 - val_accuracy: 0.4867\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2129 - accuracy: 0.9657 - val_loss: 4.1021 - val_accuracy: 0.4867\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2132 - accuracy: 0.9657 - val_loss: 4.1216 - val_accuracy: 0.4867\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2130 - accuracy: 0.9657 - val_loss: 4.1154 - val_accuracy: 0.4867\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2127 - accuracy: 0.9643 - val_loss: 4.1276 - val_accuracy: 0.4867\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2126 - accuracy: 0.9657 - val_loss: 4.1195 - val_accuracy: 0.4867\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2127 - accuracy: 0.9671 - val_loss: 4.1404 - val_accuracy: 0.4867\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2128 - accuracy: 0.9657 - val_loss: 4.0823 - val_accuracy: 0.4833\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2129 - accuracy: 0.9629 - val_loss: 4.1222 - val_accuracy: 0.4833\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2125 - accuracy: 0.9671 - val_loss: 4.1280 - val_accuracy: 0.4833\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2130 - accuracy: 0.9614 - val_loss: 4.1018 - val_accuracy: 0.4867\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2123 - accuracy: 0.9629 - val_loss: 4.1375 - val_accuracy: 0.4867\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2125 - accuracy: 0.9657 - val_loss: 4.1186 - val_accuracy: 0.4833\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2126 - accuracy: 0.9671 - val_loss: 4.1072 - val_accuracy: 0.4833\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2121 - accuracy: 0.9671 - val_loss: 4.1192 - val_accuracy: 0.4833\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2122 - accuracy: 0.9671 - val_loss: 4.1524 - val_accuracy: 0.4867\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2122 - accuracy: 0.9643 - val_loss: 4.1220 - val_accuracy: 0.4867\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2120 - accuracy: 0.9657 - val_loss: 4.1174 - val_accuracy: 0.4867\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2123 - accuracy: 0.9671 - val_loss: 4.1207 - val_accuracy: 0.4833\n",
      "Epoch 2362/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2122 - accuracy: 0.9657 - val_loss: 4.1333 - val_accuracy: 0.4867\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2123 - accuracy: 0.9657 - val_loss: 4.1384 - val_accuracy: 0.4833\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2118 - accuracy: 0.9657 - val_loss: 4.1075 - val_accuracy: 0.4833\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2120 - accuracy: 0.9671 - val_loss: 4.1531 - val_accuracy: 0.4833\n",
      "Epoch 2366/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2124 - accuracy: 0.9643 - val_loss: 4.1180 - val_accuracy: 0.4833\n",
      "Epoch 2367/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.2115 - accuracy: 0.9657 - val_loss: 4.1580 - val_accuracy: 0.4867\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2118 - accuracy: 0.9657 - val_loss: 4.1537 - val_accuracy: 0.4900\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.2124 - accuracy: 0.9643 - val_loss: 4.1397 - val_accuracy: 0.4833\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2118 - accuracy: 0.9643 - val_loss: 4.1559 - val_accuracy: 0.4867\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2119 - accuracy: 0.9657 - val_loss: 4.1326 - val_accuracy: 0.4833\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2117 - accuracy: 0.9643 - val_loss: 4.1474 - val_accuracy: 0.4867\n",
      "Epoch 2373/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2115 - accuracy: 0.9629 - val_loss: 4.1431 - val_accuracy: 0.4833\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2115 - accuracy: 0.9671 - val_loss: 4.1332 - val_accuracy: 0.4900\n",
      "Epoch 2375/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2119 - accuracy: 0.9643 - val_loss: 4.1373 - val_accuracy: 0.4833\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2113 - accuracy: 0.9671 - val_loss: 4.1448 - val_accuracy: 0.4833\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2113 - accuracy: 0.9657 - val_loss: 4.1627 - val_accuracy: 0.4833\n",
      "Epoch 2378/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2117 - accuracy: 0.9671 - val_loss: 4.1493 - val_accuracy: 0.4833\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2113 - accuracy: 0.9671 - val_loss: 4.1504 - val_accuracy: 0.4833\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2116 - accuracy: 0.9643 - val_loss: 4.1594 - val_accuracy: 0.4867\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2113 - accuracy: 0.9657 - val_loss: 4.1427 - val_accuracy: 0.4833\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2111 - accuracy: 0.9643 - val_loss: 4.1439 - val_accuracy: 0.4867\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2111 - accuracy: 0.9657 - val_loss: 4.1592 - val_accuracy: 0.4833\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2112 - accuracy: 0.9629 - val_loss: 4.1483 - val_accuracy: 0.4833\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2109 - accuracy: 0.9657 - val_loss: 4.1587 - val_accuracy: 0.4833\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2115 - accuracy: 0.9657 - val_loss: 4.1486 - val_accuracy: 0.4833\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2112 - accuracy: 0.9657 - val_loss: 4.1463 - val_accuracy: 0.4833\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2112 - accuracy: 0.9671 - val_loss: 4.1210 - val_accuracy: 0.4800\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2112 - accuracy: 0.9643 - val_loss: 4.1527 - val_accuracy: 0.4833\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2108 - accuracy: 0.9657 - val_loss: 4.1618 - val_accuracy: 0.4833\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2109 - accuracy: 0.9657 - val_loss: 4.1478 - val_accuracy: 0.4833\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2108 - accuracy: 0.9671 - val_loss: 4.1616 - val_accuracy: 0.4833\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2112 - accuracy: 0.9671 - val_loss: 4.1557 - val_accuracy: 0.4867\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2105 - accuracy: 0.9671 - val_loss: 4.1592 - val_accuracy: 0.4833\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2104 - accuracy: 0.9657 - val_loss: 4.1677 - val_accuracy: 0.4833\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2108 - accuracy: 0.9671 - val_loss: 4.1777 - val_accuracy: 0.4867\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2107 - accuracy: 0.9643 - val_loss: 4.1392 - val_accuracy: 0.4867\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2106 - accuracy: 0.9657 - val_loss: 4.1555 - val_accuracy: 0.4867\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2104 - accuracy: 0.9671 - val_loss: 4.1468 - val_accuracy: 0.4867\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2105 - accuracy: 0.9671 - val_loss: 4.1457 - val_accuracy: 0.4833\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2105 - accuracy: 0.9671 - val_loss: 4.1458 - val_accuracy: 0.4867\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2107 - accuracy: 0.9600 - val_loss: 4.1449 - val_accuracy: 0.4867\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2106 - accuracy: 0.9643 - val_loss: 4.1638 - val_accuracy: 0.4833\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2100 - accuracy: 0.9643 - val_loss: 4.1773 - val_accuracy: 0.4833\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2103 - accuracy: 0.9671 - val_loss: 4.1520 - val_accuracy: 0.4867\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2101 - accuracy: 0.9657 - val_loss: 4.1893 - val_accuracy: 0.4867\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2101 - accuracy: 0.9657 - val_loss: 4.1737 - val_accuracy: 0.4867\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2102 - accuracy: 0.9671 - val_loss: 4.1597 - val_accuracy: 0.4867\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2099 - accuracy: 0.9643 - val_loss: 4.1506 - val_accuracy: 0.4867\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.2096 - accuracy: 0.9657 - val_loss: 4.2020 - val_accuracy: 0.4833\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2102 - accuracy: 0.9671 - val_loss: 4.1601 - val_accuracy: 0.4833\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2100 - accuracy: 0.9643 - val_loss: 4.1788 - val_accuracy: 0.4833\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2097 - accuracy: 0.9643 - val_loss: 4.1391 - val_accuracy: 0.4867\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2098 - accuracy: 0.9657 - val_loss: 4.1623 - val_accuracy: 0.4867\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2097 - accuracy: 0.9657 - val_loss: 4.1677 - val_accuracy: 0.4833\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2102 - accuracy: 0.9643 - val_loss: 4.1656 - val_accuracy: 0.4867\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2098 - accuracy: 0.9643 - val_loss: 4.1690 - val_accuracy: 0.4867\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2098 - accuracy: 0.9643 - val_loss: 4.1807 - val_accuracy: 0.4833\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2097 - accuracy: 0.9657 - val_loss: 4.1701 - val_accuracy: 0.4833\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2094 - accuracy: 0.9657 - val_loss: 4.1697 - val_accuracy: 0.4867\n",
      "Epoch 2421/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2097 - accuracy: 0.9671 - val_loss: 4.1730 - val_accuracy: 0.4833\n",
      "Epoch 2422/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 0.2094 - accuracy: 0.9671 - val_loss: 4.1610 - val_accuracy: 0.4833\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2095 - accuracy: 0.9657 - val_loss: 4.1966 - val_accuracy: 0.4833\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2094 - accuracy: 0.9671 - val_loss: 4.1861 - val_accuracy: 0.4833\n",
      "Epoch 2425/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2094 - accuracy: 0.9657 - val_loss: 4.1955 - val_accuracy: 0.4867\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2094 - accuracy: 0.9671 - val_loss: 4.1852 - val_accuracy: 0.4867\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2091 - accuracy: 0.9657 - val_loss: 4.1814 - val_accuracy: 0.4833\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2089 - accuracy: 0.9671 - val_loss: 4.2031 - val_accuracy: 0.4833\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2096 - accuracy: 0.9629 - val_loss: 4.1803 - val_accuracy: 0.4867\n",
      "Epoch 2430/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2091 - accuracy: 0.9657 - val_loss: 4.1755 - val_accuracy: 0.4867\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2093 - accuracy: 0.9657 - val_loss: 4.1830 - val_accuracy: 0.4833\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2093 - accuracy: 0.9657 - val_loss: 4.1984 - val_accuracy: 0.4833\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2091 - accuracy: 0.9657 - val_loss: 4.1690 - val_accuracy: 0.4833\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2091 - accuracy: 0.9657 - val_loss: 4.1820 - val_accuracy: 0.4833\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2086 - accuracy: 0.9643 - val_loss: 4.1948 - val_accuracy: 0.4867\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2090 - accuracy: 0.9671 - val_loss: 4.1884 - val_accuracy: 0.4833\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2089 - accuracy: 0.9629 - val_loss: 4.1973 - val_accuracy: 0.4833\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2089 - accuracy: 0.9671 - val_loss: 4.2052 - val_accuracy: 0.4867\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2089 - accuracy: 0.9643 - val_loss: 4.1895 - val_accuracy: 0.4833\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2085 - accuracy: 0.9671 - val_loss: 4.1897 - val_accuracy: 0.4833\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2086 - accuracy: 0.9629 - val_loss: 4.2033 - val_accuracy: 0.4833\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2088 - accuracy: 0.9671 - val_loss: 4.1804 - val_accuracy: 0.4867\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2086 - accuracy: 0.9671 - val_loss: 4.1983 - val_accuracy: 0.4833\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2085 - accuracy: 0.9671 - val_loss: 4.1886 - val_accuracy: 0.4833\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2084 - accuracy: 0.9657 - val_loss: 4.1822 - val_accuracy: 0.4867\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2085 - accuracy: 0.9671 - val_loss: 4.2120 - val_accuracy: 0.4833\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2083 - accuracy: 0.9657 - val_loss: 4.1899 - val_accuracy: 0.4833\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2082 - accuracy: 0.9671 - val_loss: 4.2073 - val_accuracy: 0.4867\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2081 - accuracy: 0.9671 - val_loss: 4.2220 - val_accuracy: 0.4867\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2088 - accuracy: 0.9671 - val_loss: 4.1818 - val_accuracy: 0.4833\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2080 - accuracy: 0.9671 - val_loss: 4.2328 - val_accuracy: 0.4867\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 0.2082 - accuracy: 0.9671 - val_loss: 4.2086 - val_accuracy: 0.4867\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2082 - accuracy: 0.9657 - val_loss: 4.2044 - val_accuracy: 0.4833\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2084 - accuracy: 0.9671 - val_loss: 4.1918 - val_accuracy: 0.4800\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2081 - accuracy: 0.9671 - val_loss: 4.2242 - val_accuracy: 0.4833\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2085 - accuracy: 0.9643 - val_loss: 4.1898 - val_accuracy: 0.4867\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2083 - accuracy: 0.9671 - val_loss: 4.2149 - val_accuracy: 0.4833\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2082 - accuracy: 0.9643 - val_loss: 4.2079 - val_accuracy: 0.4900\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2080 - accuracy: 0.9643 - val_loss: 4.2006 - val_accuracy: 0.4833\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2082 - accuracy: 0.9657 - val_loss: 4.2208 - val_accuracy: 0.4833\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2075 - accuracy: 0.9643 - val_loss: 4.1870 - val_accuracy: 0.4833\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2080 - accuracy: 0.9657 - val_loss: 4.2105 - val_accuracy: 0.4833\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2077 - accuracy: 0.9671 - val_loss: 4.2163 - val_accuracy: 0.4833\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2081 - accuracy: 0.9657 - val_loss: 4.2213 - val_accuracy: 0.4833\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2079 - accuracy: 0.9671 - val_loss: 4.2212 - val_accuracy: 0.4833\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2078 - accuracy: 0.9657 - val_loss: 4.2173 - val_accuracy: 0.4833\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2076 - accuracy: 0.9657 - val_loss: 4.2196 - val_accuracy: 0.4833\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2077 - accuracy: 0.9657 - val_loss: 4.2240 - val_accuracy: 0.4833\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2079 - accuracy: 0.9629 - val_loss: 4.1933 - val_accuracy: 0.4900\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2082 - accuracy: 0.9643 - val_loss: 4.2122 - val_accuracy: 0.4833\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2073 - accuracy: 0.9643 - val_loss: 4.2149 - val_accuracy: 0.4867\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2075 - accuracy: 0.9657 - val_loss: 4.2066 - val_accuracy: 0.4867\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2072 - accuracy: 0.9671 - val_loss: 4.2285 - val_accuracy: 0.4867\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2075 - accuracy: 0.9643 - val_loss: 4.2181 - val_accuracy: 0.4833\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2073 - accuracy: 0.9643 - val_loss: 4.2189 - val_accuracy: 0.4833\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2073 - accuracy: 0.9643 - val_loss: 4.2209 - val_accuracy: 0.4833\n",
      "Epoch 2477/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.2073 - accuracy: 0.9657 - val_loss: 4.2166 - val_accuracy: 0.4833\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2073 - accuracy: 0.9643 - val_loss: 4.2238 - val_accuracy: 0.4833\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2070 - accuracy: 0.9657 - val_loss: 4.2261 - val_accuracy: 0.4833\n",
      "Epoch 2480/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2071 - accuracy: 0.9671 - val_loss: 4.2216 - val_accuracy: 0.4833\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2071 - accuracy: 0.9629 - val_loss: 4.2474 - val_accuracy: 0.4833\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2071 - accuracy: 0.9657 - val_loss: 4.2137 - val_accuracy: 0.4867\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2068 - accuracy: 0.9671 - val_loss: 4.2383 - val_accuracy: 0.4833\n",
      "Epoch 2484/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2070 - accuracy: 0.9671 - val_loss: 4.2327 - val_accuracy: 0.4833\n",
      "Epoch 2485/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2070 - accuracy: 0.9657 - val_loss: 4.2501 - val_accuracy: 0.4833\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2067 - accuracy: 0.9657 - val_loss: 4.2257 - val_accuracy: 0.4833\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2068 - accuracy: 0.9657 - val_loss: 4.2437 - val_accuracy: 0.4833\n",
      "Epoch 2488/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2068 - accuracy: 0.9671 - val_loss: 4.2231 - val_accuracy: 0.4833\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2068 - accuracy: 0.9657 - val_loss: 4.2292 - val_accuracy: 0.4867\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2067 - accuracy: 0.9671 - val_loss: 4.2571 - val_accuracy: 0.4867\n",
      "Epoch 2491/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2066 - accuracy: 0.9671 - val_loss: 4.2342 - val_accuracy: 0.4833\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.2065 - accuracy: 0.9671 - val_loss: 4.2456 - val_accuracy: 0.4833\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2065 - accuracy: 0.9657 - val_loss: 4.2469 - val_accuracy: 0.4833\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2065 - accuracy: 0.9629 - val_loss: 4.2584 - val_accuracy: 0.4867\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2065 - accuracy: 0.9671 - val_loss: 4.2569 - val_accuracy: 0.4833\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2065 - accuracy: 0.9671 - val_loss: 4.2480 - val_accuracy: 0.4833\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2059 - accuracy: 0.9657 - val_loss: 4.2597 - val_accuracy: 0.4833\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2060 - accuracy: 0.9657 - val_loss: 4.2368 - val_accuracy: 0.4833\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2061 - accuracy: 0.9671 - val_loss: 4.2328 - val_accuracy: 0.4833\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2063 - accuracy: 0.9671 - val_loss: 4.2218 - val_accuracy: 0.4833\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2064 - accuracy: 0.9657 - val_loss: 4.2381 - val_accuracy: 0.4833\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2063 - accuracy: 0.9671 - val_loss: 4.2488 - val_accuracy: 0.4833\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2060 - accuracy: 0.9657 - val_loss: 4.2677 - val_accuracy: 0.4833\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2063 - accuracy: 0.9657 - val_loss: 4.2526 - val_accuracy: 0.4833\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2059 - accuracy: 0.9671 - val_loss: 4.2586 - val_accuracy: 0.4800\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2062 - accuracy: 0.9657 - val_loss: 4.2303 - val_accuracy: 0.4833\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2060 - accuracy: 0.9643 - val_loss: 4.2761 - val_accuracy: 0.4867\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2061 - accuracy: 0.9671 - val_loss: 4.2584 - val_accuracy: 0.4833\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2060 - accuracy: 0.9671 - val_loss: 4.2536 - val_accuracy: 0.4833\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2060 - accuracy: 0.9657 - val_loss: 4.2700 - val_accuracy: 0.4867\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2060 - accuracy: 0.9657 - val_loss: 4.2614 - val_accuracy: 0.4867\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2060 - accuracy: 0.9643 - val_loss: 4.2711 - val_accuracy: 0.4833\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2061 - accuracy: 0.9671 - val_loss: 4.2403 - val_accuracy: 0.4800\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2058 - accuracy: 0.9657 - val_loss: 4.2483 - val_accuracy: 0.4833\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2055 - accuracy: 0.9643 - val_loss: 4.2436 - val_accuracy: 0.4800\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2056 - accuracy: 0.9629 - val_loss: 4.3014 - val_accuracy: 0.4867\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2055 - accuracy: 0.9671 - val_loss: 4.2159 - val_accuracy: 0.4867\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2056 - accuracy: 0.9671 - val_loss: 4.2625 - val_accuracy: 0.4867\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2055 - accuracy: 0.9643 - val_loss: 4.2245 - val_accuracy: 0.4833\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2055 - accuracy: 0.9657 - val_loss: 4.2558 - val_accuracy: 0.4833\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2056 - accuracy: 0.9671 - val_loss: 4.2674 - val_accuracy: 0.4867\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2056 - accuracy: 0.9643 - val_loss: 4.2696 - val_accuracy: 0.4833\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2054 - accuracy: 0.9657 - val_loss: 4.2680 - val_accuracy: 0.4833\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2051 - accuracy: 0.9657 - val_loss: 4.2980 - val_accuracy: 0.4867\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2053 - accuracy: 0.9686 - val_loss: 4.2470 - val_accuracy: 0.4833\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2054 - accuracy: 0.9629 - val_loss: 4.2610 - val_accuracy: 0.4833\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2053 - accuracy: 0.9657 - val_loss: 4.2730 - val_accuracy: 0.4800\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2052 - accuracy: 0.9671 - val_loss: 4.2762 - val_accuracy: 0.4833\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2052 - accuracy: 0.9643 - val_loss: 4.2788 - val_accuracy: 0.4833\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.96 - 0s 104us/step - loss: 0.2052 - accuracy: 0.9657 - val_loss: 4.2860 - val_accuracy: 0.4833\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2051 - accuracy: 0.9671 - val_loss: 4.2700 - val_accuracy: 0.4833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2049 - accuracy: 0.9671 - val_loss: 4.3014 - val_accuracy: 0.4867\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.2051 - accuracy: 0.9671 - val_loss: 4.2658 - val_accuracy: 0.4833\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2048 - accuracy: 0.9657 - val_loss: 4.2842 - val_accuracy: 0.4833\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2048 - accuracy: 0.9671 - val_loss: 4.2596 - val_accuracy: 0.4833\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2050 - accuracy: 0.9643 - val_loss: 4.2801 - val_accuracy: 0.4833\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2048 - accuracy: 0.9657 - val_loss: 4.2649 - val_accuracy: 0.4833\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2044 - accuracy: 0.9671 - val_loss: 4.2553 - val_accuracy: 0.4833\n",
      "Epoch 2539/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2049 - accuracy: 0.9671 - val_loss: 4.2725 - val_accuracy: 0.4833\n",
      "Epoch 2540/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2047 - accuracy: 0.9657 - val_loss: 4.2580 - val_accuracy: 0.4867\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2047 - accuracy: 0.9657 - val_loss: 4.2632 - val_accuracy: 0.4833\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2046 - accuracy: 0.9657 - val_loss: 4.2556 - val_accuracy: 0.4833\n",
      "Epoch 2543/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2046 - accuracy: 0.9671 - val_loss: 4.2800 - val_accuracy: 0.4833\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2043 - accuracy: 0.9671 - val_loss: 4.2796 - val_accuracy: 0.4833\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2045 - accuracy: 0.9671 - val_loss: 4.2875 - val_accuracy: 0.4833\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2043 - accuracy: 0.9671 - val_loss: 4.2740 - val_accuracy: 0.4800\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2045 - accuracy: 0.9657 - val_loss: 4.2884 - val_accuracy: 0.4833\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2045 - accuracy: 0.9671 - val_loss: 4.3102 - val_accuracy: 0.4867\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2045 - accuracy: 0.9643 - val_loss: 4.3062 - val_accuracy: 0.4833\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2044 - accuracy: 0.9686 - val_loss: 4.2785 - val_accuracy: 0.4833\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2046 - accuracy: 0.9686 - val_loss: 4.2716 - val_accuracy: 0.4833\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2043 - accuracy: 0.9686 - val_loss: 4.2855 - val_accuracy: 0.4833\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2044 - accuracy: 0.9657 - val_loss: 4.3000 - val_accuracy: 0.4833\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2038 - accuracy: 0.9671 - val_loss: 4.3054 - val_accuracy: 0.4833\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2041 - accuracy: 0.9686 - val_loss: 4.2719 - val_accuracy: 0.4833\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2042 - accuracy: 0.9657 - val_loss: 4.2798 - val_accuracy: 0.4800\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2042 - accuracy: 0.9657 - val_loss: 4.2816 - val_accuracy: 0.4833\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2038 - accuracy: 0.9643 - val_loss: 4.2979 - val_accuracy: 0.4833\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2039 - accuracy: 0.9671 - val_loss: 4.2904 - val_accuracy: 0.4833\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2041 - accuracy: 0.9686 - val_loss: 4.2988 - val_accuracy: 0.4833\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2038 - accuracy: 0.9671 - val_loss: 4.3045 - val_accuracy: 0.4833\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2037 - accuracy: 0.9686 - val_loss: 4.3105 - val_accuracy: 0.4833\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2036 - accuracy: 0.9671 - val_loss: 4.2724 - val_accuracy: 0.4800\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2039 - accuracy: 0.9671 - val_loss: 4.3301 - val_accuracy: 0.4833\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2038 - accuracy: 0.9671 - val_loss: 4.2778 - val_accuracy: 0.4800\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2033 - accuracy: 0.9671 - val_loss: 4.3122 - val_accuracy: 0.4833\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2038 - accuracy: 0.9671 - val_loss: 4.3199 - val_accuracy: 0.4867\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2036 - accuracy: 0.9671 - val_loss: 4.3343 - val_accuracy: 0.4867\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2034 - accuracy: 0.9671 - val_loss: 4.3094 - val_accuracy: 0.4900\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2039 - accuracy: 0.9671 - val_loss: 4.3005 - val_accuracy: 0.4833\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2033 - accuracy: 0.9671 - val_loss: 4.3119 - val_accuracy: 0.4800\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2036 - accuracy: 0.9657 - val_loss: 4.3335 - val_accuracy: 0.4833\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2035 - accuracy: 0.9657 - val_loss: 4.3118 - val_accuracy: 0.4833\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.2031 - accuracy: 0.9671 - val_loss: 4.2860 - val_accuracy: 0.4800\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2034 - accuracy: 0.9671 - val_loss: 4.3169 - val_accuracy: 0.4833\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2034 - accuracy: 0.9686 - val_loss: 4.3180 - val_accuracy: 0.4833\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2032 - accuracy: 0.9657 - val_loss: 4.3222 - val_accuracy: 0.4833\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2031 - accuracy: 0.9657 - val_loss: 4.3144 - val_accuracy: 0.4833\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2030 - accuracy: 0.9686 - val_loss: 4.2999 - val_accuracy: 0.4800\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2030 - accuracy: 0.9671 - val_loss: 4.3319 - val_accuracy: 0.4833\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2033 - accuracy: 0.9671 - val_loss: 4.3151 - val_accuracy: 0.4833\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2030 - accuracy: 0.9643 - val_loss: 4.3069 - val_accuracy: 0.4833\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2031 - accuracy: 0.9671 - val_loss: 4.3045 - val_accuracy: 0.4833\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2029 - accuracy: 0.9671 - val_loss: 4.2874 - val_accuracy: 0.4867\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2033 - accuracy: 0.9643 - val_loss: 4.3201 - val_accuracy: 0.4867\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2030 - accuracy: 0.9643 - val_loss: 4.3394 - val_accuracy: 0.4833\n",
      "Epoch 2587/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.2029 - accuracy: 0.9657 - val_loss: 4.3160 - val_accuracy: 0.4833\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2029 - accuracy: 0.9686 - val_loss: 4.3100 - val_accuracy: 0.4833\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2030 - accuracy: 0.9671 - val_loss: 4.3221 - val_accuracy: 0.4833\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2029 - accuracy: 0.9686 - val_loss: 4.3143 - val_accuracy: 0.4800\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2029 - accuracy: 0.9657 - val_loss: 4.3016 - val_accuracy: 0.4833\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2028 - accuracy: 0.9671 - val_loss: 4.3381 - val_accuracy: 0.4833\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2027 - accuracy: 0.9671 - val_loss: 4.3281 - val_accuracy: 0.4833\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2025 - accuracy: 0.9671 - val_loss: 4.3522 - val_accuracy: 0.4900\n",
      "Epoch 2595/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2026 - accuracy: 0.9671 - val_loss: 4.3246 - val_accuracy: 0.4800\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2026 - accuracy: 0.9686 - val_loss: 4.3209 - val_accuracy: 0.4833\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2025 - accuracy: 0.9671 - val_loss: 4.3469 - val_accuracy: 0.4833\n",
      "Epoch 2598/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2024 - accuracy: 0.9686 - val_loss: 4.3348 - val_accuracy: 0.4800\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2025 - accuracy: 0.9671 - val_loss: 4.3327 - val_accuracy: 0.4800\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2027 - accuracy: 0.9671 - val_loss: 4.3428 - val_accuracy: 0.4833\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2023 - accuracy: 0.9686 - val_loss: 4.3224 - val_accuracy: 0.4833\n",
      "Epoch 2602/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2023 - accuracy: 0.9671 - val_loss: 4.3561 - val_accuracy: 0.4833\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2022 - accuracy: 0.9657 - val_loss: 4.3278 - val_accuracy: 0.4867\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2021 - accuracy: 0.9671 - val_loss: 4.3348 - val_accuracy: 0.4833\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2026 - accuracy: 0.9657 - val_loss: 4.3378 - val_accuracy: 0.4833\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2025 - accuracy: 0.9657 - val_loss: 4.3472 - val_accuracy: 0.4833\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2024 - accuracy: 0.9671 - val_loss: 4.3314 - val_accuracy: 0.4833\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2023 - accuracy: 0.9686 - val_loss: 4.3544 - val_accuracy: 0.4833\n",
      "Epoch 2609/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2022 - accuracy: 0.9671 - val_loss: 4.3246 - val_accuracy: 0.4800\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2020 - accuracy: 0.9671 - val_loss: 4.3223 - val_accuracy: 0.4833\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2022 - accuracy: 0.9686 - val_loss: 4.3201 - val_accuracy: 0.4800\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2021 - accuracy: 0.9686 - val_loss: 4.3371 - val_accuracy: 0.4833\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2021 - accuracy: 0.9657 - val_loss: 4.3358 - val_accuracy: 0.4800\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2019 - accuracy: 0.9671 - val_loss: 4.3284 - val_accuracy: 0.4833\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.2018 - accuracy: 0.9686 - val_loss: 4.3280 - val_accuracy: 0.4833\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2017 - accuracy: 0.9671 - val_loss: 4.3049 - val_accuracy: 0.4867\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2017 - accuracy: 0.9686 - val_loss: 4.3137 - val_accuracy: 0.4833\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2019 - accuracy: 0.9657 - val_loss: 4.3333 - val_accuracy: 0.4867\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2016 - accuracy: 0.9671 - val_loss: 4.3299 - val_accuracy: 0.4833\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2018 - accuracy: 0.9643 - val_loss: 4.3527 - val_accuracy: 0.4833\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2018 - accuracy: 0.9671 - val_loss: 4.3552 - val_accuracy: 0.4833\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2017 - accuracy: 0.9671 - val_loss: 4.3568 - val_accuracy: 0.4800\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2017 - accuracy: 0.9671 - val_loss: 4.3332 - val_accuracy: 0.4833\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2014 - accuracy: 0.9671 - val_loss: 4.3143 - val_accuracy: 0.4833\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2016 - accuracy: 0.9671 - val_loss: 4.3453 - val_accuracy: 0.4800\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2016 - accuracy: 0.9671 - val_loss: 4.3389 - val_accuracy: 0.4800\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2019 - accuracy: 0.9671 - val_loss: 4.3624 - val_accuracy: 0.4833\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2014 - accuracy: 0.9671 - val_loss: 4.3403 - val_accuracy: 0.4833\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2014 - accuracy: 0.9671 - val_loss: 4.3475 - val_accuracy: 0.4867\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2013 - accuracy: 0.9671 - val_loss: 4.3735 - val_accuracy: 0.4833\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2013 - accuracy: 0.9686 - val_loss: 4.3504 - val_accuracy: 0.4833\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2013 - accuracy: 0.9671 - val_loss: 4.3658 - val_accuracy: 0.4833\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2013 - accuracy: 0.9657 - val_loss: 4.3129 - val_accuracy: 0.4867\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2013 - accuracy: 0.9686 - val_loss: 4.3670 - val_accuracy: 0.4833\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2012 - accuracy: 0.9671 - val_loss: 4.3488 - val_accuracy: 0.4833\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2010 - accuracy: 0.9686 - val_loss: 4.3428 - val_accuracy: 0.4833\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2012 - accuracy: 0.9686 - val_loss: 4.3829 - val_accuracy: 0.4867\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2011 - accuracy: 0.9657 - val_loss: 4.3700 - val_accuracy: 0.4833\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2009 - accuracy: 0.9671 - val_loss: 4.3909 - val_accuracy: 0.4900\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2012 - accuracy: 0.9671 - val_loss: 4.3687 - val_accuracy: 0.4833\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2011 - accuracy: 0.9686 - val_loss: 4.3960 - val_accuracy: 0.4833\n",
      "Epoch 2642/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.2014 - accuracy: 0.9686 - val_loss: 4.3717 - val_accuracy: 0.4833\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2009 - accuracy: 0.9686 - val_loss: 4.3441 - val_accuracy: 0.4800\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2011 - accuracy: 0.9671 - val_loss: 4.3778 - val_accuracy: 0.4867\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2007 - accuracy: 0.9671 - val_loss: 4.3792 - val_accuracy: 0.4867\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2008 - accuracy: 0.9671 - val_loss: 4.3760 - val_accuracy: 0.4833\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2006 - accuracy: 0.9671 - val_loss: 4.3810 - val_accuracy: 0.4900\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2008 - accuracy: 0.9686 - val_loss: 4.3758 - val_accuracy: 0.4833\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2005 - accuracy: 0.9671 - val_loss: 4.3605 - val_accuracy: 0.4833\n",
      "Epoch 2650/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2008 - accuracy: 0.9671 - val_loss: 4.3693 - val_accuracy: 0.4833\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2006 - accuracy: 0.9686 - val_loss: 4.3655 - val_accuracy: 0.4800\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2005 - accuracy: 0.9686 - val_loss: 4.3798 - val_accuracy: 0.4833\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2006 - accuracy: 0.9686 - val_loss: 4.3730 - val_accuracy: 0.4800\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2004 - accuracy: 0.9686 - val_loss: 4.3729 - val_accuracy: 0.4800\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 0.2003 - accuracy: 0.9686 - val_loss: 4.3658 - val_accuracy: 0.4833\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2002 - accuracy: 0.9671 - val_loss: 4.3587 - val_accuracy: 0.4833\n",
      "Epoch 2657/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2005 - accuracy: 0.9657 - val_loss: 4.3786 - val_accuracy: 0.4800\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2003 - accuracy: 0.9671 - val_loss: 4.4008 - val_accuracy: 0.4867\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2002 - accuracy: 0.9686 - val_loss: 4.3988 - val_accuracy: 0.4867\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2005 - accuracy: 0.9671 - val_loss: 4.3720 - val_accuracy: 0.4833\n",
      "Epoch 2661/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2003 - accuracy: 0.9671 - val_loss: 4.3733 - val_accuracy: 0.4833\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2002 - accuracy: 0.9671 - val_loss: 4.3873 - val_accuracy: 0.4833\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2000 - accuracy: 0.9671 - val_loss: 4.3694 - val_accuracy: 0.4833\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2002 - accuracy: 0.9657 - val_loss: 4.3961 - val_accuracy: 0.4867\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2001 - accuracy: 0.9671 - val_loss: 4.3833 - val_accuracy: 0.4800\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2000 - accuracy: 0.9671 - val_loss: 4.3607 - val_accuracy: 0.4867\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2000 - accuracy: 0.9671 - val_loss: 4.4115 - val_accuracy: 0.4833\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2002 - accuracy: 0.9671 - val_loss: 4.3931 - val_accuracy: 0.4833\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2000 - accuracy: 0.9671 - val_loss: 4.3883 - val_accuracy: 0.4833\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2003 - accuracy: 0.9671 - val_loss: 4.3933 - val_accuracy: 0.4833\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1999 - accuracy: 0.9671 - val_loss: 4.3940 - val_accuracy: 0.4867\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1997 - accuracy: 0.9686 - val_loss: 4.3781 - val_accuracy: 0.4833\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1997 - accuracy: 0.9686 - val_loss: 4.3673 - val_accuracy: 0.4833\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2001 - accuracy: 0.9643 - val_loss: 4.3930 - val_accuracy: 0.4833\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1999 - accuracy: 0.9671 - val_loss: 4.3924 - val_accuracy: 0.4833\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1995 - accuracy: 0.9657 - val_loss: 4.3755 - val_accuracy: 0.4833\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1998 - accuracy: 0.9657 - val_loss: 4.4036 - val_accuracy: 0.4833\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1995 - accuracy: 0.9686 - val_loss: 4.3797 - val_accuracy: 0.4833\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1993 - accuracy: 0.9686 - val_loss: 4.3740 - val_accuracy: 0.4833\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1997 - accuracy: 0.9686 - val_loss: 4.4002 - val_accuracy: 0.4900\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1995 - accuracy: 0.9686 - val_loss: 4.4105 - val_accuracy: 0.4867\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1994 - accuracy: 0.9657 - val_loss: 4.4086 - val_accuracy: 0.4833\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.1997 - accuracy: 0.9671 - val_loss: 4.4203 - val_accuracy: 0.4867\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1994 - accuracy: 0.9686 - val_loss: 4.3942 - val_accuracy: 0.4833\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1994 - accuracy: 0.9686 - val_loss: 4.3806 - val_accuracy: 0.4833\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1997 - accuracy: 0.9686 - val_loss: 4.4140 - val_accuracy: 0.4833\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1994 - accuracy: 0.9657 - val_loss: 4.4044 - val_accuracy: 0.4867\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1996 - accuracy: 0.9671 - val_loss: 4.4046 - val_accuracy: 0.4833\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1993 - accuracy: 0.9686 - val_loss: 4.4099 - val_accuracy: 0.4867\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1993 - accuracy: 0.9686 - val_loss: 4.3989 - val_accuracy: 0.4833\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1992 - accuracy: 0.9686 - val_loss: 4.4237 - val_accuracy: 0.4867\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1991 - accuracy: 0.9686 - val_loss: 4.4088 - val_accuracy: 0.4833\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1994 - accuracy: 0.9686 - val_loss: 4.3953 - val_accuracy: 0.4867\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1994 - accuracy: 0.9686 - val_loss: 4.4027 - val_accuracy: 0.4800\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.1990 - accuracy: 0.9657 - val_loss: 4.4173 - val_accuracy: 0.4800\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1989 - accuracy: 0.9686 - val_loss: 4.3816 - val_accuracy: 0.4833\n",
      "Epoch 2697/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 0.1988 - accuracy: 0.9671 - val_loss: 4.4287 - val_accuracy: 0.4900\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1992 - accuracy: 0.9686 - val_loss: 4.4224 - val_accuracy: 0.4867\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1990 - accuracy: 0.9686 - val_loss: 4.4170 - val_accuracy: 0.4867\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1989 - accuracy: 0.9671 - val_loss: 4.4097 - val_accuracy: 0.4867\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1992 - accuracy: 0.9686 - val_loss: 4.4130 - val_accuracy: 0.4833\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1988 - accuracy: 0.9686 - val_loss: 4.4056 - val_accuracy: 0.4867\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1984 - accuracy: 0.9686 - val_loss: 4.4185 - val_accuracy: 0.4833\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1988 - accuracy: 0.9686 - val_loss: 4.4128 - val_accuracy: 0.4867\n",
      "Epoch 2705/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.1989 - accuracy: 0.9686 - val_loss: 4.3839 - val_accuracy: 0.4833\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.1989 - accuracy: 0.9686 - val_loss: 4.4194 - val_accuracy: 0.4833\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.1986 - accuracy: 0.9643 - val_loss: 4.4114 - val_accuracy: 0.4833\n",
      "Epoch 2708/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.1985 - accuracy: 0.9671 - val_loss: 4.4112 - val_accuracy: 0.4833\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.1987 - accuracy: 0.9686 - val_loss: 4.4232 - val_accuracy: 0.4867\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.1985 - accuracy: 0.9686 - val_loss: 4.3938 - val_accuracy: 0.4833\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.1987 - accuracy: 0.9686 - val_loss: 4.4290 - val_accuracy: 0.4867\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1984 - accuracy: 0.9671 - val_loss: 4.4294 - val_accuracy: 0.4833\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1985 - accuracy: 0.9686 - val_loss: 4.4266 - val_accuracy: 0.4833\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1985 - accuracy: 0.9686 - val_loss: 4.4067 - val_accuracy: 0.4833\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1984 - accuracy: 0.9671 - val_loss: 4.4275 - val_accuracy: 0.4833\n",
      "Epoch 2716/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1984 - accuracy: 0.9686 - val_loss: 4.4387 - val_accuracy: 0.4833\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1984 - accuracy: 0.9671 - val_loss: 4.4203 - val_accuracy: 0.4833\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1982 - accuracy: 0.9657 - val_loss: 4.4662 - val_accuracy: 0.4833\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1983 - accuracy: 0.9671 - val_loss: 4.4227 - val_accuracy: 0.4833\n",
      "Epoch 2720/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1981 - accuracy: 0.9686 - val_loss: 4.4336 - val_accuracy: 0.4833\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1981 - accuracy: 0.9686 - val_loss: 4.4455 - val_accuracy: 0.4833\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1981 - accuracy: 0.9686 - val_loss: 4.4459 - val_accuracy: 0.4833\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1984 - accuracy: 0.9657 - val_loss: 4.4218 - val_accuracy: 0.4833\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1983 - accuracy: 0.9671 - val_loss: 4.4127 - val_accuracy: 0.4833\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1981 - accuracy: 0.9686 - val_loss: 4.4299 - val_accuracy: 0.4833\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1981 - accuracy: 0.9686 - val_loss: 4.4566 - val_accuracy: 0.4900\n",
      "Epoch 2727/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1982 - accuracy: 0.9671 - val_loss: 4.4516 - val_accuracy: 0.4867\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1983 - accuracy: 0.9629 - val_loss: 4.4244 - val_accuracy: 0.4867\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1980 - accuracy: 0.9657 - val_loss: 4.4525 - val_accuracy: 0.4833\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1981 - accuracy: 0.9686 - val_loss: 4.4332 - val_accuracy: 0.4833\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1980 - accuracy: 0.9686 - val_loss: 4.4356 - val_accuracy: 0.4867\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1978 - accuracy: 0.9686 - val_loss: 4.4309 - val_accuracy: 0.4833\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1978 - accuracy: 0.9686 - val_loss: 4.4144 - val_accuracy: 0.4833\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.1979 - accuracy: 0.9671 - val_loss: 4.4375 - val_accuracy: 0.4833\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1979 - accuracy: 0.9671 - val_loss: 4.4315 - val_accuracy: 0.4833\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1979 - accuracy: 0.9686 - val_loss: 4.4333 - val_accuracy: 0.4833\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1977 - accuracy: 0.9686 - val_loss: 4.4213 - val_accuracy: 0.4833\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1976 - accuracy: 0.9686 - val_loss: 4.4409 - val_accuracy: 0.4833\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1977 - accuracy: 0.9657 - val_loss: 4.4312 - val_accuracy: 0.4833\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1975 - accuracy: 0.9671 - val_loss: 4.4306 - val_accuracy: 0.4867\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1975 - accuracy: 0.9671 - val_loss: 4.4464 - val_accuracy: 0.4867\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1974 - accuracy: 0.9671 - val_loss: 4.4185 - val_accuracy: 0.4833\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1975 - accuracy: 0.9671 - val_loss: 4.4268 - val_accuracy: 0.4833\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1974 - accuracy: 0.9671 - val_loss: 4.4422 - val_accuracy: 0.4833\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1973 - accuracy: 0.9686 - val_loss: 4.4209 - val_accuracy: 0.4833\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1973 - accuracy: 0.9686 - val_loss: 4.4249 - val_accuracy: 0.4833\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1972 - accuracy: 0.9686 - val_loss: 4.4353 - val_accuracy: 0.4867\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1975 - accuracy: 0.9686 - val_loss: 4.4384 - val_accuracy: 0.4833\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1970 - accuracy: 0.9686 - val_loss: 4.4486 - val_accuracy: 0.4867\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1973 - accuracy: 0.9671 - val_loss: 4.4406 - val_accuracy: 0.4833\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1972 - accuracy: 0.9671 - val_loss: 4.4577 - val_accuracy: 0.4833\n",
      "Epoch 2752/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.1973 - accuracy: 0.9686 - val_loss: 4.4871 - val_accuracy: 0.4867\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1973 - accuracy: 0.9686 - val_loss: 4.4536 - val_accuracy: 0.4833\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1969 - accuracy: 0.9671 - val_loss: 4.4700 - val_accuracy: 0.4867\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1970 - accuracy: 0.9671 - val_loss: 4.4410 - val_accuracy: 0.4833\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1972 - accuracy: 0.9686 - val_loss: 4.4533 - val_accuracy: 0.4833\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1968 - accuracy: 0.9671 - val_loss: 4.4763 - val_accuracy: 0.4867\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1971 - accuracy: 0.9671 - val_loss: 4.4264 - val_accuracy: 0.4833\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1969 - accuracy: 0.9686 - val_loss: 4.4721 - val_accuracy: 0.4867\n",
      "Epoch 2760/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1968 - accuracy: 0.9686 - val_loss: 4.4875 - val_accuracy: 0.4900\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1972 - accuracy: 0.9686 - val_loss: 4.4421 - val_accuracy: 0.4833\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1968 - accuracy: 0.9686 - val_loss: 4.4509 - val_accuracy: 0.4867\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1967 - accuracy: 0.9686 - val_loss: 4.4566 - val_accuracy: 0.4833\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1967 - accuracy: 0.9686 - val_loss: 4.4799 - val_accuracy: 0.4900\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1968 - accuracy: 0.9686 - val_loss: 4.4636 - val_accuracy: 0.4833\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1966 - accuracy: 0.9686 - val_loss: 4.4768 - val_accuracy: 0.4867\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1970 - accuracy: 0.9686 - val_loss: 4.4829 - val_accuracy: 0.4867\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1966 - accuracy: 0.9671 - val_loss: 4.4549 - val_accuracy: 0.4833\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1968 - accuracy: 0.9686 - val_loss: 4.4747 - val_accuracy: 0.4833\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1968 - accuracy: 0.9686 - val_loss: 4.4404 - val_accuracy: 0.4833\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1968 - accuracy: 0.9686 - val_loss: 4.4518 - val_accuracy: 0.4833\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1966 - accuracy: 0.9686 - val_loss: 4.4790 - val_accuracy: 0.4833\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1962 - accuracy: 0.9686 - val_loss: 4.4307 - val_accuracy: 0.4833\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.1965 - accuracy: 0.9686 - val_loss: 4.4679 - val_accuracy: 0.4833\n",
      "Epoch 2775/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1964 - accuracy: 0.9686 - val_loss: 4.4685 - val_accuracy: 0.4833\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1965 - accuracy: 0.9686 - val_loss: 4.4954 - val_accuracy: 0.4900\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1962 - accuracy: 0.9686 - val_loss: 4.4823 - val_accuracy: 0.4867\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1962 - accuracy: 0.9686 - val_loss: 4.4764 - val_accuracy: 0.4833\n",
      "Epoch 2779/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1964 - accuracy: 0.9686 - val_loss: 4.4753 - val_accuracy: 0.4867\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1964 - accuracy: 0.9686 - val_loss: 4.4889 - val_accuracy: 0.4867\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1961 - accuracy: 0.9671 - val_loss: 4.4625 - val_accuracy: 0.4833\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1964 - accuracy: 0.9671 - val_loss: 4.4798 - val_accuracy: 0.4833\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1961 - accuracy: 0.9686 - val_loss: 4.4585 - val_accuracy: 0.4867\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1965 - accuracy: 0.9686 - val_loss: 4.4566 - val_accuracy: 0.4833\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1961 - accuracy: 0.9686 - val_loss: 4.4762 - val_accuracy: 0.4833\n",
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1961 - accuracy: 0.9686 - val_loss: 4.4651 - val_accuracy: 0.4833\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1959 - accuracy: 0.9686 - val_loss: 4.4861 - val_accuracy: 0.4833\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1959 - accuracy: 0.9686 - val_loss: 4.4731 - val_accuracy: 0.4833\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1960 - accuracy: 0.9671 - val_loss: 4.4788 - val_accuracy: 0.4833\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1959 - accuracy: 0.9686 - val_loss: 4.4584 - val_accuracy: 0.4833\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1961 - accuracy: 0.9686 - val_loss: 4.4750 - val_accuracy: 0.4833\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1959 - accuracy: 0.9686 - val_loss: 4.4765 - val_accuracy: 0.4833\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1958 - accuracy: 0.9686 - val_loss: 4.4944 - val_accuracy: 0.4867\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1959 - accuracy: 0.9686 - val_loss: 4.4909 - val_accuracy: 0.4867\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1956 - accuracy: 0.9671 - val_loss: 4.4905 - val_accuracy: 0.4833\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1961 - accuracy: 0.9671 - val_loss: 4.4932 - val_accuracy: 0.4867\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1957 - accuracy: 0.9686 - val_loss: 4.4930 - val_accuracy: 0.4833\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1957 - accuracy: 0.9671 - val_loss: 4.5122 - val_accuracy: 0.4900\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.1957 - accuracy: 0.9671 - val_loss: 4.5181 - val_accuracy: 0.4900\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1959 - accuracy: 0.9686 - val_loss: 4.4890 - val_accuracy: 0.4833\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1957 - accuracy: 0.9686 - val_loss: 4.4974 - val_accuracy: 0.4833\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.1957 - accuracy: 0.9686 - val_loss: 4.4767 - val_accuracy: 0.4833\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.1955 - accuracy: 0.9686 - val_loss: 4.4872 - val_accuracy: 0.4833\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1953 - accuracy: 0.9686 - val_loss: 4.5072 - val_accuracy: 0.4833\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1958 - accuracy: 0.9671 - val_loss: 4.4791 - val_accuracy: 0.4833\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1955 - accuracy: 0.9686 - val_loss: 4.4839 - val_accuracy: 0.4833\n",
      "Epoch 2807/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 0.1953 - accuracy: 0.9686 - val_loss: 4.5001 - val_accuracy: 0.4800\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1953 - accuracy: 0.9686 - val_loss: 4.4856 - val_accuracy: 0.4833\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1955 - accuracy: 0.9686 - val_loss: 4.4880 - val_accuracy: 0.4833\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1954 - accuracy: 0.9671 - val_loss: 4.4936 - val_accuracy: 0.4833\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1953 - accuracy: 0.9657 - val_loss: 4.5059 - val_accuracy: 0.4833\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1956 - accuracy: 0.9643 - val_loss: 4.4944 - val_accuracy: 0.4833\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1952 - accuracy: 0.9686 - val_loss: 4.5086 - val_accuracy: 0.4867\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.1951 - accuracy: 0.9686 - val_loss: 4.5385 - val_accuracy: 0.4867\n",
      "Epoch 2815/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1951 - accuracy: 0.9657 - val_loss: 4.4832 - val_accuracy: 0.4833\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1952 - accuracy: 0.9686 - val_loss: 4.5065 - val_accuracy: 0.4867\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1951 - accuracy: 0.9686 - val_loss: 4.4816 - val_accuracy: 0.4833\n",
      "Epoch 2818/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1953 - accuracy: 0.9686 - val_loss: 4.4781 - val_accuracy: 0.4867\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1951 - accuracy: 0.9671 - val_loss: 4.4723 - val_accuracy: 0.4833\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1950 - accuracy: 0.9686 - val_loss: 4.4879 - val_accuracy: 0.4833\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1949 - accuracy: 0.9671 - val_loss: 4.5200 - val_accuracy: 0.4800\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.96 - 0s 113us/step - loss: 0.1950 - accuracy: 0.9686 - val_loss: 4.4892 - val_accuracy: 0.4833\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1953 - accuracy: 0.9657 - val_loss: 4.5164 - val_accuracy: 0.4833\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.1947 - accuracy: 0.9686 - val_loss: 4.5080 - val_accuracy: 0.4833\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1949 - accuracy: 0.9686 - val_loss: 4.5208 - val_accuracy: 0.4833\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1946 - accuracy: 0.9671 - val_loss: 4.5002 - val_accuracy: 0.4833\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.1947 - accuracy: 0.9671 - val_loss: 4.4939 - val_accuracy: 0.4833\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1949 - accuracy: 0.9686 - val_loss: 4.4995 - val_accuracy: 0.4833\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1950 - accuracy: 0.9686 - val_loss: 4.4975 - val_accuracy: 0.4833\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1947 - accuracy: 0.9686 - val_loss: 4.5329 - val_accuracy: 0.4833\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.1945 - accuracy: 0.9657 - val_loss: 4.5144 - val_accuracy: 0.4833\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1948 - accuracy: 0.9671 - val_loss: 4.5017 - val_accuracy: 0.4833\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1948 - accuracy: 0.9686 - val_loss: 4.5169 - val_accuracy: 0.4833\n",
      "Epoch 2834/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1946 - accuracy: 0.9686 - val_loss: 4.5090 - val_accuracy: 0.4833\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.1948 - accuracy: 0.9686 - val_loss: 4.4984 - val_accuracy: 0.4833\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1943 - accuracy: 0.9686 - val_loss: 4.4824 - val_accuracy: 0.4833\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1944 - accuracy: 0.9686 - val_loss: 4.5116 - val_accuracy: 0.4833\n",
      "Epoch 2838/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1945 - accuracy: 0.9686 - val_loss: 4.5312 - val_accuracy: 0.4867\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1945 - accuracy: 0.9671 - val_loss: 4.5158 - val_accuracy: 0.4833\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1943 - accuracy: 0.9686 - val_loss: 4.5080 - val_accuracy: 0.4833\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1943 - accuracy: 0.9671 - val_loss: 4.5198 - val_accuracy: 0.4833\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1944 - accuracy: 0.9686 - val_loss: 4.5152 - val_accuracy: 0.4833\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1944 - accuracy: 0.9686 - val_loss: 4.5406 - val_accuracy: 0.4867\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1942 - accuracy: 0.9686 - val_loss: 4.5116 - val_accuracy: 0.4833\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1942 - accuracy: 0.9686 - val_loss: 4.5301 - val_accuracy: 0.4867\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1941 - accuracy: 0.9671 - val_loss: 4.5360 - val_accuracy: 0.4867\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1942 - accuracy: 0.9686 - val_loss: 4.5020 - val_accuracy: 0.4867\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1944 - accuracy: 0.9686 - val_loss: 4.5369 - val_accuracy: 0.4800\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1943 - accuracy: 0.9671 - val_loss: 4.4938 - val_accuracy: 0.4833\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1940 - accuracy: 0.9686 - val_loss: 4.5259 - val_accuracy: 0.4867\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1941 - accuracy: 0.9671 - val_loss: 4.5211 - val_accuracy: 0.4800\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1940 - accuracy: 0.9686 - val_loss: 4.5308 - val_accuracy: 0.4833\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1940 - accuracy: 0.9671 - val_loss: 4.5286 - val_accuracy: 0.4800\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 0.1939 - accuracy: 0.9686 - val_loss: 4.5313 - val_accuracy: 0.4800\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.1938 - accuracy: 0.9671 - val_loss: 4.5243 - val_accuracy: 0.4833\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.1938 - accuracy: 0.9686 - val_loss: 4.5344 - val_accuracy: 0.4833\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1940 - accuracy: 0.9671 - val_loss: 4.5067 - val_accuracy: 0.4867\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.1938 - accuracy: 0.9686 - val_loss: 4.5316 - val_accuracy: 0.4800\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.1938 - accuracy: 0.9686 - val_loss: 4.5406 - val_accuracy: 0.4800\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1937 - accuracy: 0.9686 - val_loss: 4.5233 - val_accuracy: 0.4800\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1937 - accuracy: 0.9686 - val_loss: 4.5303 - val_accuracy: 0.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1939 - accuracy: 0.9686 - val_loss: 4.5141 - val_accuracy: 0.4833\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1937 - accuracy: 0.9686 - val_loss: 4.5567 - val_accuracy: 0.4900\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1938 - accuracy: 0.9686 - val_loss: 4.5502 - val_accuracy: 0.4800\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1936 - accuracy: 0.9671 - val_loss: 4.5195 - val_accuracy: 0.4833\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1936 - accuracy: 0.9671 - val_loss: 4.5412 - val_accuracy: 0.4833\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 0.1934 - accuracy: 0.9686 - val_loss: 4.5118 - val_accuracy: 0.4867\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1936 - accuracy: 0.9671 - val_loss: 4.5405 - val_accuracy: 0.4833\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1936 - accuracy: 0.9686 - val_loss: 4.5329 - val_accuracy: 0.4833\n",
      "Epoch 2870/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1933 - accuracy: 0.9671 - val_loss: 4.5374 - val_accuracy: 0.4833\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1935 - accuracy: 0.9686 - val_loss: 4.5305 - val_accuracy: 0.4833\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1934 - accuracy: 0.9686 - val_loss: 4.5473 - val_accuracy: 0.4833\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1935 - accuracy: 0.9686 - val_loss: 4.5673 - val_accuracy: 0.4867\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1932 - accuracy: 0.9686 - val_loss: 4.5474 - val_accuracy: 0.4833\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1932 - accuracy: 0.9686 - val_loss: 4.5272 - val_accuracy: 0.4833\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1933 - accuracy: 0.9657 - val_loss: 4.5408 - val_accuracy: 0.4833\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1935 - accuracy: 0.9671 - val_loss: 4.5531 - val_accuracy: 0.4833\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1935 - accuracy: 0.9686 - val_loss: 4.5502 - val_accuracy: 0.4800\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1931 - accuracy: 0.9686 - val_loss: 4.5265 - val_accuracy: 0.4833\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1930 - accuracy: 0.9686 - val_loss: 4.5821 - val_accuracy: 0.4867\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1930 - accuracy: 0.9657 - val_loss: 4.5260 - val_accuracy: 0.4833\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1933 - accuracy: 0.9686 - val_loss: 4.5375 - val_accuracy: 0.4833\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1931 - accuracy: 0.9686 - val_loss: 4.5339 - val_accuracy: 0.4833\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1928 - accuracy: 0.9686 - val_loss: 4.5388 - val_accuracy: 0.4800\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1932 - accuracy: 0.9657 - val_loss: 4.5759 - val_accuracy: 0.4867\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1930 - accuracy: 0.9686 - val_loss: 4.5680 - val_accuracy: 0.4867\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1928 - accuracy: 0.9686 - val_loss: 4.5295 - val_accuracy: 0.4867\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1928 - accuracy: 0.9686 - val_loss: 4.5376 - val_accuracy: 0.4833\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1928 - accuracy: 0.9686 - val_loss: 4.5399 - val_accuracy: 0.4833\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1928 - accuracy: 0.9686 - val_loss: 4.5522 - val_accuracy: 0.4833\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.1929 - accuracy: 0.9671 - val_loss: 4.5361 - val_accuracy: 0.4833\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1930 - accuracy: 0.9686 - val_loss: 4.5427 - val_accuracy: 0.4833\n",
      "Epoch 2893/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1926 - accuracy: 0.9671 - val_loss: 4.5396 - val_accuracy: 0.4833\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.1926 - accuracy: 0.9686 - val_loss: 4.5735 - val_accuracy: 0.4833\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.1931 - accuracy: 0.9671 - val_loss: 4.5604 - val_accuracy: 0.4800\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.1928 - accuracy: 0.9686 - val_loss: 4.5501 - val_accuracy: 0.4800\n",
      "Epoch 2897/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.1930 - accuracy: 0.9686 - val_loss: 4.5539 - val_accuracy: 0.4833\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1930 - accuracy: 0.9686 - val_loss: 4.5604 - val_accuracy: 0.4833\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1928 - accuracy: 0.9671 - val_loss: 4.5794 - val_accuracy: 0.4867\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1927 - accuracy: 0.9686 - val_loss: 4.5558 - val_accuracy: 0.4800\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1925 - accuracy: 0.9671 - val_loss: 4.5977 - val_accuracy: 0.4833\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.1926 - accuracy: 0.9686 - val_loss: 4.5986 - val_accuracy: 0.4800\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.1927 - accuracy: 0.9686 - val_loss: 4.5854 - val_accuracy: 0.4867\n",
      "Epoch 2904/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1924 - accuracy: 0.9671 - val_loss: 4.5517 - val_accuracy: 0.4833\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1923 - accuracy: 0.9671 - val_loss: 4.5549 - val_accuracy: 0.4833\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.1922 - accuracy: 0.9686 - val_loss: 4.5527 - val_accuracy: 0.4833\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1918 - accuracy: 0.9671 - val_loss: 4.5665 - val_accuracy: 0.4867\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1917 - accuracy: 0.9657 - val_loss: 4.5557 - val_accuracy: 0.4833\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1915 - accuracy: 0.9686 - val_loss: 4.5665 - val_accuracy: 0.4833\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1920 - accuracy: 0.9671 - val_loss: 4.5830 - val_accuracy: 0.4800\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1916 - accuracy: 0.9686 - val_loss: 4.5763 - val_accuracy: 0.4833\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1916 - accuracy: 0.9671 - val_loss: 4.5579 - val_accuracy: 0.4867\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1919 - accuracy: 0.9686 - val_loss: 4.5642 - val_accuracy: 0.4833\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1917 - accuracy: 0.9686 - val_loss: 4.5626 - val_accuracy: 0.4800\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1916 - accuracy: 0.9686 - val_loss: 4.5766 - val_accuracy: 0.4833\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1915 - accuracy: 0.9686 - val_loss: 4.5598 - val_accuracy: 0.4867\n",
      "Epoch 2917/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.1912 - accuracy: 0.9686 - val_loss: 4.5756 - val_accuracy: 0.4833\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1915 - accuracy: 0.9686 - val_loss: 4.5795 - val_accuracy: 0.4833\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.1916 - accuracy: 0.9657 - val_loss: 4.5877 - val_accuracy: 0.4867\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1914 - accuracy: 0.9671 - val_loss: 4.5781 - val_accuracy: 0.4833\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1913 - accuracy: 0.9686 - val_loss: 4.5969 - val_accuracy: 0.4800\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1913 - accuracy: 0.9671 - val_loss: 4.5849 - val_accuracy: 0.4833\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1911 - accuracy: 0.9671 - val_loss: 4.6070 - val_accuracy: 0.4867\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1911 - accuracy: 0.9686 - val_loss: 4.5986 - val_accuracy: 0.4833\n",
      "Epoch 2925/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1912 - accuracy: 0.9671 - val_loss: 4.5699 - val_accuracy: 0.4833\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1911 - accuracy: 0.9671 - val_loss: 4.5912 - val_accuracy: 0.4833\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.1910 - accuracy: 0.9686 - val_loss: 4.5755 - val_accuracy: 0.4867\n",
      "Epoch 2928/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1911 - accuracy: 0.9686 - val_loss: 4.5959 - val_accuracy: 0.4800\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.1911 - accuracy: 0.9686 - val_loss: 4.5786 - val_accuracy: 0.4833\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1910 - accuracy: 0.9686 - val_loss: 4.5882 - val_accuracy: 0.4833\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1910 - accuracy: 0.9686 - val_loss: 4.5926 - val_accuracy: 0.4833\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1913 - accuracy: 0.9686 - val_loss: 4.5973 - val_accuracy: 0.4833\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1909 - accuracy: 0.9686 - val_loss: 4.5809 - val_accuracy: 0.4833\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1907 - accuracy: 0.9686 - val_loss: 4.5838 - val_accuracy: 0.4833\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.1907 - accuracy: 0.9686 - val_loss: 4.5721 - val_accuracy: 0.4867\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1906 - accuracy: 0.9686 - val_loss: 4.5864 - val_accuracy: 0.4833\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.1909 - accuracy: 0.9686 - val_loss: 4.5811 - val_accuracy: 0.4833\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.1907 - accuracy: 0.9686 - val_loss: 4.6230 - val_accuracy: 0.4833\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1906 - accuracy: 0.9671 - val_loss: 4.6036 - val_accuracy: 0.4767\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1906 - accuracy: 0.9686 - val_loss: 4.6153 - val_accuracy: 0.4767\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1907 - accuracy: 0.9686 - val_loss: 4.5887 - val_accuracy: 0.4867\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.1907 - accuracy: 0.9686 - val_loss: 4.6128 - val_accuracy: 0.4767\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1904 - accuracy: 0.9686 - val_loss: 4.6095 - val_accuracy: 0.4800\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1905 - accuracy: 0.9671 - val_loss: 4.6013 - val_accuracy: 0.4833\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1904 - accuracy: 0.9671 - val_loss: 4.5959 - val_accuracy: 0.4833\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1904 - accuracy: 0.9686 - val_loss: 4.6035 - val_accuracy: 0.4767\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1903 - accuracy: 0.9686 - val_loss: 4.6013 - val_accuracy: 0.4800\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1903 - accuracy: 0.9686 - val_loss: 4.5917 - val_accuracy: 0.4833\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.1902 - accuracy: 0.9686 - val_loss: 4.6133 - val_accuracy: 0.4767\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1903 - accuracy: 0.9686 - val_loss: 4.6025 - val_accuracy: 0.4833\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1901 - accuracy: 0.9686 - val_loss: 4.6056 - val_accuracy: 0.4800\n",
      "Epoch 2952/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1903 - accuracy: 0.9686 - val_loss: 4.6097 - val_accuracy: 0.4800\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1902 - accuracy: 0.9686 - val_loss: 4.6286 - val_accuracy: 0.4767\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1902 - accuracy: 0.9686 - val_loss: 4.6313 - val_accuracy: 0.4767\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1901 - accuracy: 0.9686 - val_loss: 4.5822 - val_accuracy: 0.4833\n",
      "Epoch 2956/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1901 - accuracy: 0.9671 - val_loss: 4.6145 - val_accuracy: 0.4800\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1900 - accuracy: 0.9657 - val_loss: 4.6192 - val_accuracy: 0.4767\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1900 - accuracy: 0.9686 - val_loss: 4.6417 - val_accuracy: 0.4867\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1899 - accuracy: 0.9686 - val_loss: 4.6195 - val_accuracy: 0.4767\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1899 - accuracy: 0.9686 - val_loss: 4.6168 - val_accuracy: 0.4767\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1897 - accuracy: 0.9686 - val_loss: 4.6256 - val_accuracy: 0.4767\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.1901 - accuracy: 0.9671 - val_loss: 4.6135 - val_accuracy: 0.4800\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1899 - accuracy: 0.9686 - val_loss: 4.6352 - val_accuracy: 0.4800\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1899 - accuracy: 0.9700 - val_loss: 4.6081 - val_accuracy: 0.4800\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1900 - accuracy: 0.9686 - val_loss: 4.5974 - val_accuracy: 0.4833\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1898 - accuracy: 0.9686 - val_loss: 4.6149 - val_accuracy: 0.4767\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1897 - accuracy: 0.9686 - val_loss: 4.6390 - val_accuracy: 0.4767\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1899 - accuracy: 0.9686 - val_loss: 4.6155 - val_accuracy: 0.4800\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1897 - accuracy: 0.9686 - val_loss: 4.6357 - val_accuracy: 0.4800\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1896 - accuracy: 0.9686 - val_loss: 4.6038 - val_accuracy: 0.4833\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1896 - accuracy: 0.9686 - val_loss: 4.6022 - val_accuracy: 0.4833\n",
      "Epoch 2972/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.1895 - accuracy: 0.9686 - val_loss: 4.6320 - val_accuracy: 0.4800\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1893 - accuracy: 0.9686 - val_loss: 4.6574 - val_accuracy: 0.4800\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1894 - accuracy: 0.9686 - val_loss: 4.6085 - val_accuracy: 0.4833\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.1894 - accuracy: 0.9671 - val_loss: 4.6287 - val_accuracy: 0.4833\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.1893 - accuracy: 0.9686 - val_loss: 4.6232 - val_accuracy: 0.4800\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1894 - accuracy: 0.9686 - val_loss: 4.6134 - val_accuracy: 0.4833\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1895 - accuracy: 0.9671 - val_loss: 4.6157 - val_accuracy: 0.4800\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1894 - accuracy: 0.9686 - val_loss: 4.6335 - val_accuracy: 0.4800\n",
      "Epoch 2980/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1895 - accuracy: 0.9686 - val_loss: 4.5909 - val_accuracy: 0.4833\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1893 - accuracy: 0.9686 - val_loss: 4.6397 - val_accuracy: 0.4767\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.1894 - accuracy: 0.9686 - val_loss: 4.6268 - val_accuracy: 0.4833\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.1894 - accuracy: 0.9686 - val_loss: 4.6105 - val_accuracy: 0.4833\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1893 - accuracy: 0.9686 - val_loss: 4.6327 - val_accuracy: 0.4800\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.1891 - accuracy: 0.9686 - val_loss: 4.6239 - val_accuracy: 0.4800\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1890 - accuracy: 0.9686 - val_loss: 4.6595 - val_accuracy: 0.4800\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.1894 - accuracy: 0.9686 - val_loss: 4.6475 - val_accuracy: 0.4833\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1892 - accuracy: 0.9686 - val_loss: 4.6359 - val_accuracy: 0.4833\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1889 - accuracy: 0.9686 - val_loss: 4.6395 - val_accuracy: 0.4767\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.1891 - accuracy: 0.9686 - val_loss: 4.6706 - val_accuracy: 0.4867\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1892 - accuracy: 0.9686 - val_loss: 4.6224 - val_accuracy: 0.4800\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.1890 - accuracy: 0.9686 - val_loss: 4.6528 - val_accuracy: 0.4833\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1890 - accuracy: 0.9686 - val_loss: 4.6354 - val_accuracy: 0.4833\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.1891 - accuracy: 0.9686 - val_loss: 4.6660 - val_accuracy: 0.4800\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.1890 - accuracy: 0.9686 - val_loss: 4.6402 - val_accuracy: 0.4800\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.1888 - accuracy: 0.9686 - val_loss: 4.6260 - val_accuracy: 0.4800\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.1889 - accuracy: 0.9686 - val_loss: 4.6463 - val_accuracy: 0.4800\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.1888 - accuracy: 0.9686 - val_loss: 4.6472 - val_accuracy: 0.4800\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.1888 - accuracy: 0.9686 - val_loss: 4.6526 - val_accuracy: 0.4833\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.1890 - accuracy: 0.9671 - val_loss: 4.6390 - val_accuracy: 0.4800\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "hist = model.fit(xTrain, yTrain, epochs=3000, batch_size=10, validation_data=(xVal, yVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax = plt.subplots()\n",
    "\n",
    "# 축을 공유하는 플랏을 만드는 함수\n",
    "acc_ax = loss_ax.twinx()\n",
    "# loss 그래프\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "# acc 그래프\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "# 범례\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "# 축이름\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "?plt.xticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.961728657150268, 0.4803999960422516]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.evaluate(xTest, yTest, batch_size=32)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "# 콜백함수 : 어떤 상황이 되었을 때(val loss가 떨어지다가 올라가게 된 시점) 함수 내에서 또 다른 어떤 함수를 호출하는 것\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# es = EarlyStopping()\n",
    "es = EarlyStopping(patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 244us/step - loss: 2.2975 - accuracy: 0.0871 - val_loss: 2.2871 - val_accuracy: 0.1467\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 2.2636 - accuracy: 0.1600 - val_loss: 2.2411 - val_accuracy: 0.2400\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 2.2216 - accuracy: 0.1971 - val_loss: 2.2099 - val_accuracy: 0.2533\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 2.1876 - accuracy: 0.2129 - val_loss: 2.1837 - val_accuracy: 0.2200\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 2.1558 - accuracy: 0.2429 - val_loss: 2.1521 - val_accuracy: 0.2833\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 2.1265 - accuracy: 0.2714 - val_loss: 2.1205 - val_accuracy: 0.2767\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 2.0974 - accuracy: 0.2700 - val_loss: 2.0847 - val_accuracy: 0.3267\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 2.0687 - accuracy: 0.2729 - val_loss: 2.0579 - val_accuracy: 0.3300\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 2.0408 - accuracy: 0.2829 - val_loss: 2.0467 - val_accuracy: 0.2900\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 2.0129 - accuracy: 0.2771 - val_loss: 2.0172 - val_accuracy: 0.3000\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.9870 - accuracy: 0.2700 - val_loss: 1.9853 - val_accuracy: 0.3200\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.9631 - accuracy: 0.2771 - val_loss: 1.9697 - val_accuracy: 0.3000\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.9385 - accuracy: 0.2829 - val_loss: 1.9459 - val_accuracy: 0.3133\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.9156 - accuracy: 0.2814 - val_loss: 1.9218 - val_accuracy: 0.3333\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.8948 - accuracy: 0.2986 - val_loss: 1.9061 - val_accuracy: 0.3300\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.8722 - accuracy: 0.2900 - val_loss: 1.8832 - val_accuracy: 0.3533\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.8525 - accuracy: 0.2986 - val_loss: 1.8655 - val_accuracy: 0.3600\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.8328 - accuracy: 0.3114 - val_loss: 1.8651 - val_accuracy: 0.3200\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.8154 - accuracy: 0.3243 - val_loss: 1.8309 - val_accuracy: 0.3600\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7976 - accuracy: 0.3229 - val_loss: 1.8126 - val_accuracy: 0.3767\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7800 - accuracy: 0.3271 - val_loss: 1.8171 - val_accuracy: 0.3400\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.7651 - accuracy: 0.3329 - val_loss: 1.7874 - val_accuracy: 0.3733\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7485 - accuracy: 0.3586 - val_loss: 1.7661 - val_accuracy: 0.3900\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7332 - accuracy: 0.3857 - val_loss: 1.7647 - val_accuracy: 0.3833\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7177 - accuracy: 0.3786 - val_loss: 1.7488 - val_accuracy: 0.3833\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7027 - accuracy: 0.3886 - val_loss: 1.7365 - val_accuracy: 0.3967\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6895 - accuracy: 0.3900 - val_loss: 1.7227 - val_accuracy: 0.4033\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6766 - accuracy: 0.3871 - val_loss: 1.7125 - val_accuracy: 0.4067\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6607 - accuracy: 0.3957 - val_loss: 1.6992 - val_accuracy: 0.4133\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6490 - accuracy: 0.4143 - val_loss: 1.7010 - val_accuracy: 0.3867\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6359 - accuracy: 0.4100 - val_loss: 1.6879 - val_accuracy: 0.4100\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6245 - accuracy: 0.4171 - val_loss: 1.6749 - val_accuracy: 0.4100\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6116 - accuracy: 0.4114 - val_loss: 1.6540 - val_accuracy: 0.4333\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.6014 - accuracy: 0.4214 - val_loss: 1.6542 - val_accuracy: 0.4267\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5884 - accuracy: 0.4257 - val_loss: 1.6489 - val_accuracy: 0.4267\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5769 - accuracy: 0.4329 - val_loss: 1.6240 - val_accuracy: 0.4467\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5673 - accuracy: 0.4343 - val_loss: 1.6372 - val_accuracy: 0.4233\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5559 - accuracy: 0.4243 - val_loss: 1.6260 - val_accuracy: 0.4333\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5481 - accuracy: 0.4429 - val_loss: 1.6047 - val_accuracy: 0.4500\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5388 - accuracy: 0.4500 - val_loss: 1.6171 - val_accuracy: 0.4367\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.5295 - accuracy: 0.4443 - val_loss: 1.5958 - val_accuracy: 0.4433\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5192 - accuracy: 0.4400 - val_loss: 1.5909 - val_accuracy: 0.4500\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5098 - accuracy: 0.4429 - val_loss: 1.5779 - val_accuracy: 0.4467\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5015 - accuracy: 0.4557 - val_loss: 1.5848 - val_accuracy: 0.4467\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4934 - accuracy: 0.4500 - val_loss: 1.5912 - val_accuracy: 0.4467\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4866 - accuracy: 0.4671 - val_loss: 1.5687 - val_accuracy: 0.4500\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4798 - accuracy: 0.4600 - val_loss: 1.5657 - val_accuracy: 0.4467\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4721 - accuracy: 0.4600 - val_loss: 1.5716 - val_accuracy: 0.4400\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4637 - accuracy: 0.4586 - val_loss: 1.5403 - val_accuracy: 0.4800\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4569 - accuracy: 0.4800 - val_loss: 1.5544 - val_accuracy: 0.4567\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4501 - accuracy: 0.4757 - val_loss: 1.5377 - val_accuracy: 0.4667\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4442 - accuracy: 0.4643 - val_loss: 1.5503 - val_accuracy: 0.4667\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4373 - accuracy: 0.4686 - val_loss: 1.5530 - val_accuracy: 0.4633\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4308 - accuracy: 0.4714 - val_loss: 1.5503 - val_accuracy: 0.4600\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4248 - accuracy: 0.4743 - val_loss: 1.5307 - val_accuracy: 0.4700\n",
      "Epoch 56/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 1.4187 - accuracy: 0.4729 - val_loss: 1.5294 - val_accuracy: 0.4633\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4126 - accuracy: 0.4771 - val_loss: 1.5302 - val_accuracy: 0.4733\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4074 - accuracy: 0.4743 - val_loss: 1.5378 - val_accuracy: 0.4700\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4025 - accuracy: 0.4871 - val_loss: 1.5223 - val_accuracy: 0.4800\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3978 - accuracy: 0.4857 - val_loss: 1.5204 - val_accuracy: 0.4767\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3908 - accuracy: 0.4757 - val_loss: 1.5295 - val_accuracy: 0.4733\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3862 - accuracy: 0.4871 - val_loss: 1.5299 - val_accuracy: 0.4633\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3809 - accuracy: 0.4800 - val_loss: 1.5216 - val_accuracy: 0.4667\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3763 - accuracy: 0.4886 - val_loss: 1.5133 - val_accuracy: 0.4800\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3716 - accuracy: 0.4800 - val_loss: 1.5128 - val_accuracy: 0.4733\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3643 - accuracy: 0.4957 - val_loss: 1.5167 - val_accuracy: 0.4733\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3611 - accuracy: 0.4943 - val_loss: 1.4932 - val_accuracy: 0.4700\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3559 - accuracy: 0.5029 - val_loss: 1.5103 - val_accuracy: 0.4667\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3529 - accuracy: 0.4829 - val_loss: 1.4910 - val_accuracy: 0.4833\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3469 - accuracy: 0.5129 - val_loss: 1.4908 - val_accuracy: 0.4700\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3425 - accuracy: 0.4943 - val_loss: 1.4982 - val_accuracy: 0.4767\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3397 - accuracy: 0.5071 - val_loss: 1.4849 - val_accuracy: 0.4767\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3333 - accuracy: 0.4900 - val_loss: 1.5079 - val_accuracy: 0.4633\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3288 - accuracy: 0.5029 - val_loss: 1.5067 - val_accuracy: 0.4767\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3271 - accuracy: 0.4957 - val_loss: 1.4965 - val_accuracy: 0.4733\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3222 - accuracy: 0.5157 - val_loss: 1.4862 - val_accuracy: 0.4967\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3167 - accuracy: 0.5014 - val_loss: 1.4960 - val_accuracy: 0.4667\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3148 - accuracy: 0.5157 - val_loss: 1.5018 - val_accuracy: 0.4833\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3099 - accuracy: 0.5114 - val_loss: 1.4987 - val_accuracy: 0.4900\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3084 - accuracy: 0.5071 - val_loss: 1.4807 - val_accuracy: 0.4800\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3045 - accuracy: 0.5186 - val_loss: 1.4934 - val_accuracy: 0.5167\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2999 - accuracy: 0.5443 - val_loss: 1.4789 - val_accuracy: 0.5300\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2960 - accuracy: 0.5543 - val_loss: 1.4814 - val_accuracy: 0.5100\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2944 - accuracy: 0.5629 - val_loss: 1.4767 - val_accuracy: 0.5067\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2902 - accuracy: 0.5614 - val_loss: 1.4737 - val_accuracy: 0.5200\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2876 - accuracy: 0.5600 - val_loss: 1.4678 - val_accuracy: 0.5200\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2819 - accuracy: 0.5600 - val_loss: 1.4484 - val_accuracy: 0.5233\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2815 - accuracy: 0.5543 - val_loss: 1.4899 - val_accuracy: 0.5267\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2769 - accuracy: 0.5571 - val_loss: 1.4644 - val_accuracy: 0.5200\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2754 - accuracy: 0.5457 - val_loss: 1.4772 - val_accuracy: 0.5100\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2710 - accuracy: 0.5714 - val_loss: 1.4623 - val_accuracy: 0.5133\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2666 - accuracy: 0.5443 - val_loss: 1.4686 - val_accuracy: 0.5167\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2642 - accuracy: 0.5757 - val_loss: 1.4876 - val_accuracy: 0.5000\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2615 - accuracy: 0.5529 - val_loss: 1.4505 - val_accuracy: 0.5200\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2588 - accuracy: 0.5814 - val_loss: 1.4620 - val_accuracy: 0.5167\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2569 - accuracy: 0.5586 - val_loss: 1.4759 - val_accuracy: 0.5233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2534 - accuracy: 0.5557 - val_loss: 1.4726 - val_accuracy: 0.5267\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2498 - accuracy: 0.5686 - val_loss: 1.4608 - val_accuracy: 0.5267\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2495 - accuracy: 0.5686 - val_loss: 1.4594 - val_accuracy: 0.5167\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2451 - accuracy: 0.5529 - val_loss: 1.4605 - val_accuracy: 0.5233\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2410 - accuracy: 0.5686 - val_loss: 1.4845 - val_accuracy: 0.5200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2404 - accuracy: 0.5600 - val_loss: 1.4623 - val_accuracy: 0.5167\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2387 - accuracy: 0.5671 - val_loss: 1.4607 - val_accuracy: 0.5233\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2347 - accuracy: 0.5600 - val_loss: 1.4774 - val_accuracy: 0.5433\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2312 - accuracy: 0.5743 - val_loss: 1.4732 - val_accuracy: 0.5233\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2272 - accuracy: 0.5771 - val_loss: 1.4628 - val_accuracy: 0.5233\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2283 - accuracy: 0.5714 - val_loss: 1.4597 - val_accuracy: 0.5267\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2235 - accuracy: 0.5729 - val_loss: 1.4415 - val_accuracy: 0.5333\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2219 - accuracy: 0.5686 - val_loss: 1.4798 - val_accuracy: 0.5200\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2191 - accuracy: 0.5714 - val_loss: 1.4708 - val_accuracy: 0.5400\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2173 - accuracy: 0.5757 - val_loss: 1.4549 - val_accuracy: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2142 - accuracy: 0.5714 - val_loss: 1.4477 - val_accuracy: 0.5300\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2113 - accuracy: 0.5700 - val_loss: 1.4720 - val_accuracy: 0.5133\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2094 - accuracy: 0.5771 - val_loss: 1.4582 - val_accuracy: 0.5233\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2060 - accuracy: 0.5786 - val_loss: 1.4815 - val_accuracy: 0.5333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2045 - accuracy: 0.5800 - val_loss: 1.4948 - val_accuracy: 0.5300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2003 - accuracy: 0.5829 - val_loss: 1.4543 - val_accuracy: 0.5267\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1967 - accuracy: 0.5714 - val_loss: 1.4798 - val_accuracy: 0.5233\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.1965 - accuracy: 0.5729 - val_loss: 1.4597 - val_accuracy: 0.5200\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1924 - accuracy: 0.5829 - val_loss: 1.4483 - val_accuracy: 0.5367\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.1923 - accuracy: 0.5857 - val_loss: 1.4536 - val_accuracy: 0.5400\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1885 - accuracy: 0.5900 - val_loss: 1.4750 - val_accuracy: 0.5333\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1831 - accuracy: 0.5857 - val_loss: 1.4399 - val_accuracy: 0.5400\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1851 - accuracy: 0.5800 - val_loss: 1.4611 - val_accuracy: 0.5467\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1809 - accuracy: 0.5871 - val_loss: 1.4478 - val_accuracy: 0.5500\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1804 - accuracy: 0.5886 - val_loss: 1.4497 - val_accuracy: 0.5267\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.1777 - accuracy: 0.5971 - val_loss: 1.4562 - val_accuracy: 0.5400\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.1739 - accuracy: 0.5929 - val_loss: 1.4565 - val_accuracy: 0.5533\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1725 - accuracy: 0.5857 - val_loss: 1.4618 - val_accuracy: 0.5467\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1676 - accuracy: 0.5986 - val_loss: 1.4690 - val_accuracy: 0.5367\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1668 - accuracy: 0.5900 - val_loss: 1.4624 - val_accuracy: 0.5433\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1644 - accuracy: 0.6029 - val_loss: 1.4897 - val_accuracy: 0.5400\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1629 - accuracy: 0.6000 - val_loss: 1.4784 - val_accuracy: 0.5433\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1602 - accuracy: 0.5986 - val_loss: 1.4531 - val_accuracy: 0.5367\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1570 - accuracy: 0.5971 - val_loss: 1.4527 - val_accuracy: 0.5400\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.1559 - accuracy: 0.6000 - val_loss: 1.4925 - val_accuracy: 0.5367\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1544 - accuracy: 0.5957 - val_loss: 1.4555 - val_accuracy: 0.5500\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1534 - accuracy: 0.6043 - val_loss: 1.4565 - val_accuracy: 0.5533\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1494 - accuracy: 0.6043 - val_loss: 1.4604 - val_accuracy: 0.5533\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1485 - accuracy: 0.6043 - val_loss: 1.4616 - val_accuracy: 0.5400\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.1450 - accuracy: 0.6043 - val_loss: 1.4923 - val_accuracy: 0.5400\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1445 - accuracy: 0.5957 - val_loss: 1.4665 - val_accuracy: 0.5467\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1401 - accuracy: 0.6071 - val_loss: 1.4819 - val_accuracy: 0.5433\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1393 - accuracy: 0.6043 - val_loss: 1.4674 - val_accuracy: 0.5467\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1351 - accuracy: 0.6057 - val_loss: 1.4762 - val_accuracy: 0.5500\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1352 - accuracy: 0.6071 - val_loss: 1.4552 - val_accuracy: 0.5500\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1328 - accuracy: 0.6014 - val_loss: 1.4558 - val_accuracy: 0.5567\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1307 - accuracy: 0.6057 - val_loss: 1.4766 - val_accuracy: 0.5533\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.1282 - accuracy: 0.6086 - val_loss: 1.4768 - val_accuracy: 0.5467\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.1280 - accuracy: 0.6057 - val_loss: 1.4851 - val_accuracy: 0.5400\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1237 - accuracy: 0.6000 - val_loss: 1.4648 - val_accuracy: 0.5533\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1228 - accuracy: 0.6114 - val_loss: 1.4861 - val_accuracy: 0.5267\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.1224 - accuracy: 0.6143 - val_loss: 1.4675 - val_accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "# early stopping 적용\n",
    "hist = model.fit(xTrain, yTrain, epochs=3000, batch_size=10, validation_data=(xVal, yVal), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax = plt.subplots()\n",
    "\n",
    "# 축을 공유하는 플랏을 만드는 함수\n",
    "acc_ax = loss_ax.twinx()\n",
    "# loss 그래프\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "# acc 그래프\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "# 범례\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "# 축이름\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 랜덤 값을 얻기위한 seed 지정\n",
    "seed = 123\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.loadtxt로 불러오기 => csv를 np.array로 불러오기\n",
    "dataset = np.loadtxt('data/dataset/ThoraricSurgery.csv', delimiter=',')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape  # 470, 18\n",
    "\n",
    "# 데이터 분할\n",
    "x = dataset[:,0:17]\n",
    "y = dataset[:,17]  # 1 : 수술 후 생존 / 0 : 사망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Dense(30,input_dim=17,  activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 0s 436us/step - loss: 0.1491 - accuracy: 0.8511\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 92us/step - loss: 0.1487 - accuracy: 0.8511\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 96us/step - loss: 0.1486 - accuracy: 0.8489\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1469 - accuracy: 0.8532\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1477 - accuracy: 0.8489\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1498 - accuracy: 0.8489\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 96us/step - loss: 0.1487 - accuracy: 0.8511\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1478 - accuracy: 0.8511\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.1481 - accuracy: 0.8489\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.1459 - accuracy: 0.8532\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1506 - accuracy: 0.8468\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 96us/step - loss: 0.1479 - accuracy: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1472 - accuracy: 0.8489\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1479 - accuracy: 0.8511\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1466 - accuracy: 0.8532\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1472 - accuracy: 0.8532\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1468 - accuracy: 0.8532\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1469 - accuracy: 0.8532\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1462 - accuracy: 0.8532\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1465 - accuracy: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1463 - accuracy: 0.8489\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1463 - accuracy: 0.8532\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1467 - accuracy: 0.8532\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1494 - accuracy: 0.8489\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1473 - accuracy: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 94us/step - loss: 0.1478 - accuracy: 0.8426\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 94us/step - loss: 0.1466 - accuracy: 0.8532\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1455 - accuracy: 0.8532\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1467 - accuracy: 0.8489\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1467 - accuracy: 0.8468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22a9a7b1ac8>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 119us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14437511398437175, 0.8553191423416138]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    496\n",
       "0.0    263\n",
       "Name: 8, dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(xy)[8].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data/실습데이터/data-03-diabetes.csv', delimiter=',')\n",
    "\n",
    "xdata = xy[:,:-1]  # (759, 8)\n",
    "# 2차원으로 읽기\n",
    "ydata = xy[:,[-1]]  # (759, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([8,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값\n",
    "hf = tf.sigmoid( tf.matmul(x,w) + b )\n",
    "\n",
    "# loss함수\n",
    "cost = -tf.reduce_mean( y * tf.log(hf) + (1-y) * (tf.log(1-hf)) )\n",
    "\n",
    "# cost 최소화\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5 값이 나오면 1 아니면 0으로 cast\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "\n",
    "# 평균으로 정확도를 구한다.\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0 cost :  0.71645546\n",
      "step :  1000 cost :  0.5783056\n",
      "step :  2000 cost :  0.5428046\n",
      "step :  3000 cost :  0.522\n",
      "step :  4000 cost :  0.50904375\n",
      "step :  5000 cost :  0.5005169\n",
      "step :  6000 cost :  0.49463505\n",
      "step :  7000 cost :  0.49041528\n",
      "step :  8000 cost :  0.48728672\n",
      "step :  9000 cost :  0.4849018\n",
      "step :  10000 cost :  0.48303992\n",
      "[[0.43517378]\n",
      " [0.9305253 ]\n",
      " [0.21276909]\n",
      " [0.9403849 ]\n",
      " [0.2814071 ]\n",
      " [0.734638  ]\n",
      " [0.9442921 ]\n",
      " [0.6298966 ]\n",
      " [0.21975067]\n",
      " [0.49394792]\n",
      " [0.6655098 ]\n",
      " [0.178424  ]\n",
      " [0.2847036 ]\n",
      " [0.33321157]\n",
      " [0.7636914 ]\n",
      " [0.45983672]\n",
      " [0.7256181 ]\n",
      " [0.8767173 ]\n",
      " [0.8022256 ]\n",
      " [0.5524271 ]\n",
      " [0.6760626 ]\n",
      " [0.08871558]\n",
      " [0.6650007 ]\n",
      " [0.6867694 ]\n",
      " [0.3574233 ]\n",
      " [0.93448853]\n",
      " [0.55365187]\n",
      " [0.60434335]\n",
      " [0.7453991 ]\n",
      " [0.41059196]\n",
      " [0.95476604]\n",
      " [0.8409748 ]\n",
      " [0.621994  ]\n",
      " [0.8373132 ]\n",
      " [0.3776161 ]\n",
      " [0.6932457 ]\n",
      " [0.83715796]\n",
      " [0.5725293 ]\n",
      " [0.41365498]\n",
      " [0.37030387]\n",
      " [0.8342134 ]\n",
      " [0.14750344]\n",
      " [0.3923083 ]\n",
      " [0.08253655]\n",
      " [0.5667026 ]\n",
      " [0.94042814]\n",
      " [0.75744206]\n",
      " [0.735075  ]\n",
      " [0.9275096 ]\n",
      " [0.9366285 ]\n",
      " [0.9307513 ]\n",
      " [0.21531135]\n",
      " [0.37550053]\n",
      " [0.9743609 ]\n",
      " [0.19912991]\n",
      " [0.46684673]\n",
      " [0.15886894]\n",
      " [0.72462875]\n",
      " [0.88021445]\n",
      " [0.50310975]\n",
      " [0.956456  ]\n",
      " [0.6904044 ]\n",
      " [0.67440265]\n",
      " [0.86196065]\n",
      " [0.63547987]\n",
      " [0.5713981 ]\n",
      " [0.9526926 ]\n",
      " [0.63009155]\n",
      " [0.8663478 ]\n",
      " [0.64756113]\n",
      " [0.2924488 ]\n",
      " [0.7039337 ]\n",
      " [0.9215952 ]\n",
      " [0.9382323 ]\n",
      " [0.889437  ]\n",
      " [0.81474435]\n",
      " [0.45717782]\n",
      " [0.87313634]\n",
      " [0.91802824]\n",
      " [0.92032427]\n",
      " [0.87388504]\n",
      " [0.84864557]\n",
      " [0.31686687]\n",
      " [0.80494887]\n",
      " [0.57066697]\n",
      " [0.8696528 ]\n",
      " [0.44988042]\n",
      " [0.90222704]\n",
      " [0.94042563]\n",
      " [0.7699369 ]\n",
      " [0.81126165]\n",
      " [0.6354607 ]\n",
      " [0.6885098 ]\n",
      " [0.57680374]\n",
      " [0.912496  ]\n",
      " [0.9779011 ]\n",
      " [0.90192455]\n",
      " [0.53806716]\n",
      " [0.24752995]\n",
      " [0.6056027 ]\n",
      " [0.57185274]\n",
      " [0.9553137 ]\n",
      " [0.79934597]\n",
      " [0.77390575]\n",
      " [0.81843436]\n",
      " [0.6812649 ]\n",
      " [0.92289656]\n",
      " [0.81348217]\n",
      " [0.43180013]\n",
      " [0.4172996 ]\n",
      " [0.9156357 ]\n",
      " [0.8846617 ]\n",
      " [0.44927788]\n",
      " [0.39671075]\n",
      " [0.61784893]\n",
      " [0.8708899 ]\n",
      " [0.8899481 ]\n",
      " [0.91845036]\n",
      " [0.13403615]\n",
      " [0.7474307 ]\n",
      " [0.8370818 ]\n",
      " [0.5980718 ]\n",
      " [0.62979525]\n",
      " [0.854094  ]\n",
      " [0.70201004]\n",
      " [0.82342726]\n",
      " [0.78677243]\n",
      " [0.63296944]\n",
      " [0.4916214 ]\n",
      " [0.48440683]\n",
      " [0.39910305]\n",
      " [0.81981605]\n",
      " [0.93318456]\n",
      " [0.8304326 ]\n",
      " [0.8086693 ]\n",
      " [0.8701336 ]\n",
      " [0.45561028]\n",
      " [0.8094288 ]\n",
      " [0.6997998 ]\n",
      " [0.7458619 ]\n",
      " [0.883136  ]\n",
      " [0.6652559 ]\n",
      " [0.55923307]\n",
      " [0.7599822 ]\n",
      " [0.92147577]\n",
      " [0.7645973 ]\n",
      " [0.43236637]\n",
      " [0.9366995 ]\n",
      " [0.57519865]\n",
      " [0.77366364]\n",
      " [0.27307433]\n",
      " [0.3698136 ]\n",
      " [0.107025  ]\n",
      " [0.24008325]\n",
      " [0.9258183 ]\n",
      " [0.88350576]\n",
      " [0.93622684]\n",
      " [0.13334191]\n",
      " [0.47268707]\n",
      " [0.76729786]\n",
      " [0.6236596 ]\n",
      " [0.8877492 ]\n",
      " [0.40985537]\n",
      " [0.8235358 ]\n",
      " [0.6234455 ]\n",
      " [0.6464439 ]\n",
      " [0.7298791 ]\n",
      " [0.8488565 ]\n",
      " [0.75193596]\n",
      " [0.6320391 ]\n",
      " [0.90962064]\n",
      " [0.88190585]\n",
      " [0.95122343]\n",
      " [0.20482671]\n",
      " [0.82085836]\n",
      " [0.21873453]\n",
      " [0.3802905 ]\n",
      " [0.40489408]\n",
      " [0.8689827 ]\n",
      " [0.7092819 ]\n",
      " [0.9152029 ]\n",
      " [0.9153912 ]\n",
      " [0.5602008 ]\n",
      " [0.15790936]\n",
      " [0.21521363]\n",
      " [0.5346283 ]\n",
      " [0.72505647]\n",
      " [0.5886986 ]\n",
      " [0.8259487 ]\n",
      " [0.60551107]\n",
      " [0.3529904 ]\n",
      " [0.27327842]\n",
      " [0.92692447]\n",
      " [0.3387525 ]\n",
      " [0.8638966 ]\n",
      " [0.9023037 ]\n",
      " [0.71821237]\n",
      " [0.64718723]\n",
      " [0.69148946]\n",
      " [0.51923895]\n",
      " [0.76986384]\n",
      " [0.93906677]\n",
      " [0.7816838 ]\n",
      " [0.82202446]\n",
      " [0.13652122]\n",
      " [0.25358576]\n",
      " [0.9053674 ]\n",
      " [0.198048  ]\n",
      " [0.9448698 ]\n",
      " [0.261144  ]\n",
      " [0.23188949]\n",
      " [0.5010009 ]\n",
      " [0.701427  ]\n",
      " [0.24310109]\n",
      " [0.75457376]\n",
      " [0.7162914 ]\n",
      " [0.8512983 ]\n",
      " [0.68412787]\n",
      " [0.19879133]\n",
      " [0.3140012 ]\n",
      " [0.71472603]\n",
      " [0.5541867 ]\n",
      " [0.9227109 ]\n",
      " [0.9239882 ]\n",
      " [0.70153975]\n",
      " [0.4020638 ]\n",
      " [0.05506948]\n",
      " [0.64196086]\n",
      " [0.33762535]\n",
      " [0.46831027]\n",
      " [0.9411559 ]\n",
      " [0.63549757]\n",
      " [0.94626   ]\n",
      " [0.21671328]\n",
      " [0.1453082 ]\n",
      " [0.3016137 ]\n",
      " [0.75216746]\n",
      " [0.9251095 ]\n",
      " [0.87748986]\n",
      " [0.64287484]\n",
      " [0.73492444]\n",
      " [0.54982024]\n",
      " [0.1743662 ]\n",
      " [0.5732605 ]\n",
      " [0.15570176]\n",
      " [0.61334103]\n",
      " [0.85853124]\n",
      " [0.72101074]\n",
      " [0.6508024 ]\n",
      " [0.94226533]\n",
      " [0.8444189 ]\n",
      " [0.8446584 ]\n",
      " [0.78553146]\n",
      " [0.7943649 ]\n",
      " [0.8641511 ]\n",
      " [0.41342786]\n",
      " [0.3815826 ]\n",
      " [0.5225436 ]\n",
      " [0.83799565]\n",
      " [0.66976064]\n",
      " [0.6859925 ]\n",
      " [0.83286786]\n",
      " [0.36791444]\n",
      " [0.5338987 ]\n",
      " [0.6873499 ]\n",
      " [0.59945977]\n",
      " [0.4937525 ]\n",
      " [0.89319706]\n",
      " [0.7289152 ]\n",
      " [0.9141304 ]\n",
      " [0.6031153 ]\n",
      " [0.7512742 ]\n",
      " [0.84687805]\n",
      " [0.8363633 ]\n",
      " [0.67929775]\n",
      " [0.8840933 ]\n",
      " [0.3583185 ]\n",
      " [0.58900946]\n",
      " [0.6669431 ]\n",
      " [0.31716383]\n",
      " [0.78794384]\n",
      " [0.2914487 ]\n",
      " [0.5900502 ]\n",
      " [0.93883216]\n",
      " [0.76098484]\n",
      " [0.8516623 ]\n",
      " [0.72683495]\n",
      " [0.4971007 ]\n",
      " [0.66659707]\n",
      " [0.4295805 ]\n",
      " [0.47076616]\n",
      " [0.6159448 ]\n",
      " [0.61486423]\n",
      " [0.6956209 ]\n",
      " [0.64370275]\n",
      " [0.2265617 ]\n",
      " [0.664725  ]\n",
      " [0.89086044]\n",
      " [0.4710495 ]\n",
      " [0.5670351 ]\n",
      " [0.73011136]\n",
      " [0.47126842]\n",
      " [0.73180485]\n",
      " [0.56861395]\n",
      " [0.7159994 ]\n",
      " [0.91473174]\n",
      " [0.68154347]\n",
      " [0.65790015]\n",
      " [0.8832644 ]\n",
      " [0.6126557 ]\n",
      " [0.85016894]\n",
      " [0.9334516 ]\n",
      " [0.25879157]\n",
      " [0.7716931 ]\n",
      " [0.20457056]\n",
      " [0.7990866 ]\n",
      " [0.8119823 ]\n",
      " [0.7333752 ]\n",
      " [0.32533956]\n",
      " [0.79454124]\n",
      " [0.691044  ]\n",
      " [0.74713427]\n",
      " [0.17902079]\n",
      " [0.7867619 ]\n",
      " [0.8396847 ]\n",
      " [0.65455425]\n",
      " [0.9456707 ]\n",
      " [0.24941036]\n",
      " [0.6926766 ]\n",
      " [0.9463701 ]\n",
      " [0.21259525]\n",
      " [0.53699416]\n",
      " [0.6773286 ]\n",
      " [0.33093786]\n",
      " [0.15994793]\n",
      " [0.8317499 ]\n",
      " [0.91148365]\n",
      " [0.86256945]\n",
      " [0.5871955 ]\n",
      " [0.70548564]\n",
      " [0.5470487 ]\n",
      " [0.7833742 ]\n",
      " [0.80143416]\n",
      " [0.9312942 ]\n",
      " [0.76347864]\n",
      " [0.764678  ]\n",
      " [0.53540176]\n",
      " [0.9424727 ]\n",
      " [0.9436201 ]\n",
      " [0.75094944]\n",
      " [0.24201927]\n",
      " [0.7097366 ]\n",
      " [0.45656058]\n",
      " [0.7709811 ]\n",
      " [0.17837399]\n",
      " [0.24631226]\n",
      " [0.40676925]\n",
      " [0.67297447]\n",
      " [0.37629533]\n",
      " [0.5650737 ]\n",
      " [0.8621563 ]\n",
      " [0.6369323 ]\n",
      " [0.8824912 ]\n",
      " [0.93969893]\n",
      " [0.67966294]\n",
      " [0.10274351]\n",
      " [0.56230956]\n",
      " [0.8719704 ]\n",
      " [0.8512852 ]\n",
      " [0.6951885 ]\n",
      " [0.3043667 ]\n",
      " [0.87626636]\n",
      " [0.8967876 ]\n",
      " [0.29125682]\n",
      " [0.6054789 ]\n",
      " [0.8302862 ]\n",
      " [0.86255324]\n",
      " [0.8908614 ]\n",
      " [0.9139782 ]\n",
      " [0.85028744]\n",
      " [0.916553  ]\n",
      " [0.71185744]\n",
      " [0.614854  ]\n",
      " [0.54931104]\n",
      " [0.84743667]\n",
      " [0.88013816]\n",
      " [0.22395176]\n",
      " [0.828179  ]\n",
      " [0.87089807]\n",
      " [0.3094056 ]\n",
      " [0.677175  ]\n",
      " [0.87679064]\n",
      " [0.5730344 ]\n",
      " [0.90672886]\n",
      " [0.2549525 ]\n",
      " [0.8376682 ]\n",
      " [0.5603864 ]\n",
      " [0.8997587 ]\n",
      " [0.34387368]\n",
      " [0.7352562 ]\n",
      " [0.71389055]\n",
      " [0.79935706]\n",
      " [0.09670621]\n",
      " [0.23242757]\n",
      " [0.6848634 ]\n",
      " [0.8101177 ]\n",
      " [0.4714495 ]\n",
      " [0.7499474 ]\n",
      " [0.52658045]\n",
      " [0.32822192]\n",
      " [0.87185585]\n",
      " [0.46354795]\n",
      " [0.91468346]\n",
      " [0.79639876]\n",
      " [0.62624073]\n",
      " [0.920619  ]\n",
      " [0.6891752 ]\n",
      " [0.82779807]\n",
      " [0.34358287]\n",
      " [0.24165559]\n",
      " [0.7797859 ]\n",
      " [0.39694908]\n",
      " [0.4038662 ]\n",
      " [0.88849914]\n",
      " [0.8878434 ]\n",
      " [0.9144927 ]\n",
      " [0.9497849 ]\n",
      " [0.6378552 ]\n",
      " [0.9181433 ]\n",
      " [0.3989074 ]\n",
      " [0.38546395]\n",
      " [0.45087093]\n",
      " [0.9441569 ]\n",
      " [0.59408927]\n",
      " [0.14994612]\n",
      " [0.9299535 ]\n",
      " [0.8110114 ]\n",
      " [0.61462045]\n",
      " [0.8393406 ]\n",
      " [0.02409345]\n",
      " [0.9176874 ]\n",
      " [0.7518532 ]\n",
      " [0.76277137]\n",
      " [0.76246285]\n",
      " [0.96414214]\n",
      " [0.6100675 ]\n",
      " [0.8038688 ]\n",
      " [0.7451785 ]\n",
      " [0.8701508 ]\n",
      " [0.2292698 ]\n",
      " [0.64730597]\n",
      " [0.9079011 ]\n",
      " [0.602198  ]\n",
      " [0.75212556]\n",
      " [0.94270384]\n",
      " [0.8579363 ]\n",
      " [0.8879331 ]\n",
      " [0.4946386 ]\n",
      " [0.81410193]\n",
      " [0.9545666 ]\n",
      " [0.77189654]\n",
      " [0.6611805 ]\n",
      " [0.29878706]\n",
      " [0.45447773]\n",
      " [0.54002094]\n",
      " [0.67053914]\n",
      " [0.48124537]\n",
      " [0.7691486 ]\n",
      " [0.5818107 ]\n",
      " [0.7545588 ]\n",
      " [0.82430255]\n",
      " [0.7015084 ]\n",
      " [0.64205366]\n",
      " [0.48534596]\n",
      " [0.5777544 ]\n",
      " [0.9388569 ]\n",
      " [0.84136546]\n",
      " [0.30129176]\n",
      " [0.45542017]\n",
      " [0.54364806]\n",
      " [0.1313557 ]\n",
      " [0.89836454]\n",
      " [0.13314787]\n",
      " [0.905916  ]\n",
      " [0.8716134 ]\n",
      " [0.8420403 ]\n",
      " [0.71102405]\n",
      " [0.89562595]\n",
      " [0.3340201 ]\n",
      " [0.7678219 ]\n",
      " [0.9402667 ]\n",
      " [0.26476973]\n",
      " [0.430507  ]\n",
      " [0.84291416]\n",
      " [0.8865127 ]\n",
      " [0.710058  ]\n",
      " [0.83914304]\n",
      " [0.8176152 ]\n",
      " [0.8149028 ]\n",
      " [0.23334298]\n",
      " [0.77547574]\n",
      " [0.92177516]\n",
      " [0.6193544 ]\n",
      " [0.8327671 ]\n",
      " [0.7268392 ]\n",
      " [0.82403123]\n",
      " [0.8682244 ]\n",
      " [0.9332845 ]\n",
      " [0.5720631 ]\n",
      " [0.39579588]\n",
      " [0.8213567 ]\n",
      " [0.7603357 ]\n",
      " [0.96207625]\n",
      " [0.72847694]\n",
      " [0.7093343 ]\n",
      " [0.4437814 ]\n",
      " [0.7130797 ]\n",
      " [0.93906134]\n",
      " [0.9463452 ]\n",
      " [0.8791764 ]\n",
      " [0.7151199 ]\n",
      " [0.68220556]\n",
      " [0.8181146 ]\n",
      " [0.5183649 ]\n",
      " [0.8127019 ]\n",
      " [0.81989014]\n",
      " [0.9116745 ]\n",
      " [0.6136439 ]\n",
      " [0.6818491 ]\n",
      " [0.9201026 ]\n",
      " [0.49574116]\n",
      " [0.47406244]\n",
      " [0.6885534 ]\n",
      " [0.72315645]\n",
      " [0.71577066]\n",
      " [0.89063144]\n",
      " [0.9117296 ]\n",
      " [0.17423666]\n",
      " [0.15056038]\n",
      " [0.7552794 ]\n",
      " [0.43080798]\n",
      " [0.17942044]\n",
      " [0.8426913 ]\n",
      " [0.90518934]\n",
      " [0.67023534]\n",
      " [0.9344728 ]\n",
      " [0.92263967]\n",
      " [0.74733007]\n",
      " [0.8436767 ]\n",
      " [0.6949324 ]\n",
      " [0.6333256 ]\n",
      " [0.78270894]\n",
      " [0.5985307 ]\n",
      " [0.12803712]\n",
      " [0.89831734]\n",
      " [0.89157593]\n",
      " [0.72753406]\n",
      " [0.9284464 ]\n",
      " [0.85862863]\n",
      " [0.8888246 ]\n",
      " [0.5514895 ]\n",
      " [0.7048212 ]\n",
      " [0.8879969 ]\n",
      " [0.6507968 ]\n",
      " [0.85074055]\n",
      " [0.91510844]\n",
      " [0.559342  ]\n",
      " [0.7993226 ]\n",
      " [0.8661003 ]\n",
      " [0.55820924]\n",
      " [0.5295359 ]\n",
      " [0.0678196 ]\n",
      " [0.25525543]\n",
      " [0.8512683 ]\n",
      " [0.6907569 ]\n",
      " [0.69185424]\n",
      " [0.6272366 ]\n",
      " [0.9481961 ]\n",
      " [0.4482236 ]\n",
      " [0.8076044 ]\n",
      " [0.2562024 ]\n",
      " [0.90501606]\n",
      " [0.4113855 ]\n",
      " [0.73007   ]\n",
      " [0.5497389 ]\n",
      " [0.8977028 ]\n",
      " [0.5836031 ]\n",
      " [0.22975877]\n",
      " [0.8225547 ]\n",
      " [0.9566915 ]\n",
      " [0.33175787]\n",
      " [0.93077815]\n",
      " [0.860384  ]\n",
      " [0.85242337]\n",
      " [0.78900063]\n",
      " [0.42037088]\n",
      " [0.29361254]\n",
      " [0.73349583]\n",
      " [0.173275  ]\n",
      " [0.94409597]\n",
      " [0.32886547]\n",
      " [0.92266035]\n",
      " [0.89141   ]\n",
      " [0.4342945 ]\n",
      " [0.19305196]\n",
      " [0.7287617 ]\n",
      " [0.4707073 ]\n",
      " [0.8150748 ]\n",
      " [0.645371  ]\n",
      " [0.9785297 ]\n",
      " [0.61834234]\n",
      " [0.6508358 ]\n",
      " [0.73815656]\n",
      " [0.8405318 ]\n",
      " [0.07317927]\n",
      " [0.78620887]\n",
      " [0.80537164]\n",
      " [0.8064598 ]\n",
      " [0.6345876 ]\n",
      " [0.46755117]\n",
      " [0.5774639 ]\n",
      " [0.91677177]\n",
      " [0.6591504 ]\n",
      " [0.75718784]\n",
      " [0.8100357 ]\n",
      " [0.82891244]\n",
      " [0.8173619 ]\n",
      " [0.60989547]\n",
      " [0.782209  ]\n",
      " [0.89705104]\n",
      " [0.72670686]\n",
      " [0.9473635 ]\n",
      " [0.79811436]\n",
      " [0.6075783 ]\n",
      " [0.4528851 ]\n",
      " [0.8444508 ]\n",
      " [0.84335124]\n",
      " [0.4660036 ]\n",
      " [0.60840285]\n",
      " [0.25856525]\n",
      " [0.52845347]\n",
      " [0.8395399 ]\n",
      " [0.94674563]\n",
      " [0.8381322 ]\n",
      " [0.69236183]\n",
      " [0.7604747 ]\n",
      " [0.8746977 ]\n",
      " [0.55875444]\n",
      " [0.9196297 ]\n",
      " [0.5593824 ]\n",
      " [0.84955466]\n",
      " [0.2828913 ]\n",
      " [0.0888142 ]\n",
      " [0.2098127 ]\n",
      " [0.3310289 ]\n",
      " [0.7339581 ]\n",
      " [0.78123665]\n",
      " [0.60639066]\n",
      " [0.7712703 ]\n",
      " [0.83644617]\n",
      " [0.46586397]\n",
      " [0.38847953]\n",
      " [0.9252329 ]\n",
      " [0.8793781 ]\n",
      " [0.39847872]\n",
      " [0.7010024 ]\n",
      " [0.16385207]\n",
      " [0.3479814 ]\n",
      " [0.7761179 ]\n",
      " [0.7235946 ]\n",
      " [0.91301864]\n",
      " [0.9775177 ]\n",
      " [0.2181823 ]\n",
      " [0.7509768 ]\n",
      " [0.58534217]\n",
      " [0.44186044]\n",
      " [0.71306556]\n",
      " [0.7075709 ]\n",
      " [0.91227937]\n",
      " [0.6965288 ]\n",
      " [0.4466455 ]\n",
      " [0.6549168 ]\n",
      " [0.13292798]\n",
      " [0.68149424]\n",
      " [0.5236275 ]\n",
      " [0.9050856 ]\n",
      " [0.55923283]\n",
      " [0.5232648 ]\n",
      " [0.80261797]\n",
      " [0.71477973]\n",
      " [0.51101583]\n",
      " [0.74165976]\n",
      " [0.6623266 ]\n",
      " [0.3196434 ]\n",
      " [0.621397  ]\n",
      " [0.86950046]\n",
      " [0.85259426]\n",
      " [0.62571836]\n",
      " [0.82047904]\n",
      " [0.27132463]\n",
      " [0.8578494 ]\n",
      " [0.618528  ]\n",
      " [0.7268444 ]\n",
      " [0.49203798]\n",
      " [0.70152545]\n",
      " [0.81812686]\n",
      " [0.21021819]\n",
      " [0.2670802 ]\n",
      " [0.8495397 ]\n",
      " [0.80713195]\n",
      " [0.82131857]\n",
      " [0.9110613 ]\n",
      " [0.7893176 ]\n",
      " [0.6634929 ]\n",
      " [0.70372856]\n",
      " [0.7231009 ]\n",
      " [0.7029482 ]\n",
      " [0.7765776 ]\n",
      " [0.49643895]\n",
      " [0.3434754 ]\n",
      " [0.8905401 ]\n",
      " [0.7641483 ]\n",
      " [0.6048686 ]\n",
      " [0.2381159 ]\n",
      " [0.8839582 ]\n",
      " [0.80231524]\n",
      " [0.8617737 ]\n",
      " [0.6463553 ]\n",
      " [0.9149618 ]\n",
      " [0.88936514]\n",
      " [0.7704614 ]\n",
      " [0.4532023 ]\n",
      " [0.91017246]\n",
      " [0.91059566]\n",
      " [0.31368658]\n",
      " [0.17220616]\n",
      " [0.7249763 ]\n",
      " [0.36869198]\n",
      " [0.81242645]\n",
      " [0.3115825 ]\n",
      " [0.4324782 ]\n",
      " [0.44682202]\n",
      " [0.72944236]\n",
      " [0.88019645]\n",
      " [0.13370347]\n",
      " [0.39026898]\n",
      " [0.56561846]\n",
      " [0.4728192 ]\n",
      " [0.53826916]\n",
      " [0.77047634]\n",
      " [0.13216612]\n",
      " [0.9204486 ]\n",
      " [0.21478862]\n",
      " [0.8567359 ]\n",
      " [0.7181079 ]\n",
      " [0.74647695]\n",
      " [0.8128613 ]\n",
      " [0.71415037]\n",
      " [0.8984106 ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.76943344\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        _, cv = sess.run([train, cost], feed_dict={x:xdata, y:ydata})\n",
    "        if step % 1000 == 0 :\n",
    "            print('step : ',step, 'cost : ',cv)\n",
    "            \n",
    "    hfv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})\n",
    "    \n",
    "    print(hfv, pv, av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식 종가 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data/실습데이터/data-02-stock_daily.csv', delimiter=',')\n",
    "\n",
    "# 데이터 분할\n",
    "x = xy[:,:-1]    # 732, 4\n",
    "y = xy[:,[-1]]   # 732, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할 70 : 30\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, train_size=0.7, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 추가\n",
    "# model.add(Dense(input_dim=4, units=30, activation='relu'))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "512/512 [==============================] - 0s 338us/step - loss: 743298411072.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 627431300096.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 526536452288.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 438062212480.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "512/512 [==============================] - 0s 139us/step - loss: 358375861216.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "512/512 [==============================] - 0s 121us/step - loss: 293379840896.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 238436422144.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "512/512 [==============================] - 0s 92us/step - loss: 191943616752.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 153742887136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 121574496936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 94991638376.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 73520784296.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 56517702300.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 42962299592.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 31844055572.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 23732036774.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 17247784358.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 12387010707.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 8655951872.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 6023130720.5000 - accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 4231722364.5000 - accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 2904471121.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 1966968413.1250 - accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 1317274928.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 879423006.5625 - accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 564158900.2500 - accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 363589316.3125 - accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 230730744.9844 - accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 144949495.7969 - accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 89977036.0898 - accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 54709341.9062 - accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 32924482.2246 - accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 19413866.1094 - accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 11198199.2876 - accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "512/512 [==============================] - 0s 92us/step - loss: 6526281.5103 - accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "512/512 [==============================] - 0s 88us/step - loss: 3720867.0906 - accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 2087417.7974 - accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 1173487.2099 - accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 669491.8656 - accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 397715.2811 - accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 254953.4604 - accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 178794.6147 - accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 139206.9851 - accuracy: 0.0020\n",
      "Epoch 44/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 116928.3830 - accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 106079.0093 - accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 101194.5969 - accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 98543.5680 - accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 97327.0712 - accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 96611.8151 - accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 96374.6696 - accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 95964.8934 - accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 96000.8333 - accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 95972.0034 - accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 96012.2911 - accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 95963.3953 - accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 95904.3460 - accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 95916.8464 - accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 96018.6282 - accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 96009.9405 - accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 95886.5614 - accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 95908.6126 - accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 95703.8855 - accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 95839.9289 - accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 95906.3619 - accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 95762.7061 - accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 95900.3266 - accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 95755.0623 - accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 95623.8269 - accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 95639.8560 - accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 95597.3468 - accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 95683.8863 - accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 95568.3604 - accuracy: 0.0000e+00\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 66us/step - loss: 95510.7899 - accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 95619.6230 - accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 95603.1900 - accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 95625.9004 - accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 95487.9874 - accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 95358.3038 - accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 95448.9993 - accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 95364.5008 - accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 95286.1538 - accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 95312.2032 - accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 95272.2191 - accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 95282.1569 - accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 95076.5442 - accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 95159.6394 - accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 95121.1825 - accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 95174.1926 - accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 95430.5861 - accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 94932.5636 - accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 95106.3274 - accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 94872.8719 - accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 94945.0691 - accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 94800.9902 - accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 94758.6277 - accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 95114.5808 - accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "512/512 [==============================] - 0s 86us/step - loss: 94737.7848 - accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 94753.0621 - accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 94671.1907 - accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 94556.2790 - accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 94440.5229 - accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 94481.0590 - accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 94605.9346 - accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 94598.8302 - accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "512/512 [==============================] - 0s 86us/step - loss: 94402.5366 - accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 94156.4504 - accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 94328.9389 - accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 94725.1367 - accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "512/512 [==============================] - 0s 94us/step - loss: 94121.7730 - accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "512/512 [==============================] - 0s 92us/step - loss: 94474.5523 - accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 94078.3613 - accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 94008.0314 - accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 93939.2397 - accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 94037.7144 - accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 94003.0928 - accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 94133.9875 - accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 94130.1732 - accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 93733.9379 - accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 93533.6956 - accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 93885.2593 - accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 93442.8665 - accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 93604.6291 - accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 93687.1127 - accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 94059.3328 - accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "512/512 [==============================] - 0s 88us/step - loss: 93426.7717 - accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 93359.8330 - accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 93007.7337 - accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 93116.0166 - accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 92964.8530 - accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 92970.2968 - accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 92844.4973 - accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 92924.4333 - accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 92532.3941 - accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 92777.6159 - accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 93182.5611 - accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 92771.9977 - accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 92614.8706 - accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 92143.7664 - accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 92881.4531 - accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 92439.3893 - accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 92795.8025 - accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 91922.0519 - accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 92132.5011 - accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 95702.8364 - accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 91555.5944 - accuracy: 0.0000e+00\n",
      "Epoch 146/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 70us/step - loss: 92561.9570 - accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 91622.0101 - accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 92867.2067 - accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 91855.2885 - accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 91586.1060 - accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 91141.2096 - accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 90971.5710 - accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 91044.5626 - accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 91127.6355 - accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 90827.1744 - accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 90368.0463 - accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 90375.9020 - accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 90177.0058 - accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 90548.2222 - accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 90375.0393 - accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 90330.8306 - accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 90224.4820 - accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 90354.1768 - accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 90255.5106 - accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 89020.4918 - accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 89492.1272 - accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 89487.1721 - accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 89335.7287 - accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 89893.7249 - accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 88619.7691 - accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 88532.4244 - accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 88965.5915 - accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 89007.4943 - accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 89522.9747 - accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 88389.1742 - accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 88140.0915 - accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 87489.1910 - accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 88430.8288 - accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 87821.9862 - accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 87007.8262 - accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 87346.6328 - accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "512/512 [==============================] - 0s 100us/step - loss: 86989.9648 - accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 86687.4687 - accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 86549.5398 - accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 86861.0043 - accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "512/512 [==============================] - 0s 64us/step - loss: 86863.7845 - accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 86070.7656 - accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 85894.5481 - accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 85507.7741 - accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 85422.0107 - accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 85696.3810 - accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 84471.6093 - accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 85031.4123 - accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 87025.6640 - accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 85509.3261 - accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 84931.6694 - accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 84230.5675 - accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 85870.9073 - accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 84311.1769 - accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 85108.1016 - accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 86713.1153 - accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 84479.8527 - accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 82422.2651 - accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 83208.9990 - accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 82386.1874 - accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 82026.3323 - accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 83066.1448 - accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 81173.6835 - accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 81102.1950 - accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 80870.4711 - accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 81365.9768 - accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 82104.1356 - accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 80597.8623 - accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 80754.7475 - accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 80000.8679 - accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 79786.9243 - accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 78803.0381 - accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 81356.5218 - accuracy: 0.0000e+00\n",
      "Epoch 219/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 78us/step - loss: 77949.2099 - accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 77728.4742 - accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 78160.5647 - accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 77309.9971 - accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 77387.8471 - accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 76934.2476 - accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 78036.6915 - accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 78420.9514 - accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 77993.5230 - accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 76879.7392 - accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 76137.5332 - accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 74954.9169 - accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 75400.5234 - accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 76097.1522 - accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 75033.7385 - accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 74919.1911 - accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 74858.6209 - accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 72580.9939 - accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 73110.4036 - accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 72575.7602 - accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 71583.7574 - accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 72858.1234 - accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 70077.7470 - accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 81933.2469 - accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 72011.9129 - accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 69996.4271 - accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 68654.6253 - accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 70405.5858 - accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 67975.5686 - accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 77111.6924 - accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 69303.4935 - accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 69261.3618 - accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 66449.4103 - accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 68421.8037 - accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 65370.7566 - accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 65154.6981 - accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 64751.4841 - accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "512/512 [==============================] - 0s 90us/step - loss: 64145.9042 - accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "512/512 [==============================] - 0s 94us/step - loss: 64077.0791 - accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 68031.6160 - accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 64367.1338 - accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 66783.4932 - accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 61225.8078 - accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 61990.9899 - accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 63864.2318 - accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 64734.7874 - accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 59577.1666 - accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 75436.7381 - accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 64186.0456 - accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 62770.1109 - accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 60210.2202 - accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 56873.8078 - accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 56070.5583 - accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 57670.9108 - accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "512/512 [==============================] - 0s 86us/step - loss: 56438.8514 - accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 69006.0412 - accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 56309.4266 - accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 58629.0429 - accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 54751.8309 - accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 52906.0260 - accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "512/512 [==============================] - 0s 86us/step - loss: 51974.8644 - accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 51467.8588 - accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "512/512 [==============================] - 0s 86us/step - loss: 51949.8208 - accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 55411.6159 - accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 51753.2687 - accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 47968.6104 - accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 50280.1537 - accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 49317.1570 - accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 48187.6750 - accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 50751.3258 - accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 46440.6596 - accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 45725.3241 - accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 45822.8765 - accuracy: 0.0000e+00\n",
      "Epoch 292/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 66us/step - loss: 51482.8118 - accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 43018.0767 - accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 41942.2566 - accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 43875.3445 - accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "512/512 [==============================] - 0s 64us/step - loss: 43800.6276 - accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 40648.6451 - accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 44640.7796 - accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 43527.4708 - accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 42956.5150 - accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 42597.1446 - accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 42732.0968 - accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 37148.8085 - accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 38491.2483 - accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 37847.0476 - accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 38657.2010 - accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 33916.7500 - accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 52921.0412 - accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 32305.5598 - accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 35174.6689 - accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 31733.0100 - accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 35005.9274 - accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 33539.0005 - accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 32000.8512 - accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 29371.8452 - accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 29684.5176 - accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 30679.7756 - accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 29016.7020 - accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 32960.4472 - accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 41167.8873 - accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 26012.4173 - accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 24286.8364 - accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 31125.7254 - accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 26558.0413 - accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 25198.0634 - accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 24188.5848 - accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 22318.0376 - accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 27965.9532 - accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 22522.2319 - accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 21771.3033 - accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "512/512 [==============================] - 0s 98us/step - loss: 22105.6813 - accuracy: 0.0020\n",
      "Epoch 332/500\n",
      "512/512 [==============================] - 0s 86us/step - loss: 20926.9919 - accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 19623.7315 - accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 20199.0495 - accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 19613.6789 - accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 19386.6203 - accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 18396.0350 - accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 18341.3072 - accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 16749.3514 - accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 17703.2131 - accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 16790.2305 - accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 17095.2086 - accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 16125.4477 - accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 15328.1233 - accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 13778.1673 - accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 15429.2344 - accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 15101.3788 - accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 12789.8496 - accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 11979.6897 - accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 11306.9238 - accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 14054.8014 - accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 13334.9706 - accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 12044.9988 - accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 13432.8579 - accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 13526.2927 - accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 11239.1439 - accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 9782.8560 - accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 8517.8995 - accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 10063.2241 - accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 7445.1823 - accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 7525.7238 - accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 7846.8464 - accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 7475.5535 - accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 6293.8179 - accuracy: 0.0000e+00\n",
      "Epoch 365/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 72us/step - loss: 9190.9457 - accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 5686.9631 - accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 6304.8960 - accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 5112.2472 - accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 5227.8666 - accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 11554.7943 - accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 5001.9249 - accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 7199.4876 - accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 4023.0989 - accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 4963.4119 - accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 5358.4859 - accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 3321.6184 - accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 2973.7478 - accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 4879.9024 - accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 2991.1897 - accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 2674.1158 - accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 2720.3985 - accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 3341.4559 - accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 3560.7045 - accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 2316.1577 - accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 1918.1927 - accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 1618.9723 - accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 4897.3574 - accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 2542.3913 - accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 1938.3317 - accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 1316.8383 - accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 1826.1467 - accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 1682.0618 - accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 1060.8110 - accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 3243.8075 - accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 1033.3490 - accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 1367.7965 - accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 3710.6307 - accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 911.9375 - accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 1096.7287 - accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 629.5409 - accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 938.3536 - accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 828.0610 - accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "512/512 [==============================] - ETA: 0s - loss: 1250.0586 - accuracy: 0.0000e+0 - 0s 86us/step - loss: 679.0317 - accuracy: 0.0020\n",
      "Epoch 404/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 665.4639 - accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "512/512 [==============================] - 0s 100us/step - loss: 386.0355 - accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "512/512 [==============================] - 0s 111us/step - loss: 350.3546 - accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 383.6636 - accuracy: 0.0020\n",
      "Epoch 408/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 1026.2237 - accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 417.6409 - accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 474.4986 - accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 207.0705 - accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 283.5610 - accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 273.9794 - accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "512/512 [==============================] - 0s 105us/step - loss: 187.8433 - accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 156.0366 - accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "512/512 [==============================] - 0s 64us/step - loss: 118.7679 - accuracy: 0.0039\n",
      "Epoch 417/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 157.9588 - accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 163.9086 - accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 152.1450 - accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 121.2679 - accuracy: 0.0020\n",
      "Epoch 421/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 124.8307 - accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 210.6503 - accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 161.3281 - accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 410.0949 - accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 84.3511 - accuracy: 0.0020\n",
      "Epoch 426/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 135.6999 - accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 96.6079 - accuracy: 0.0020\n",
      "Epoch 428/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 89.4833 - accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 95.2122 - accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 103.4792 - accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 169.9578 - accuracy: 0.0020\n",
      "Epoch 432/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 100.1949 - accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 137.2028 - accuracy: 0.0020\n",
      "Epoch 434/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 65.4409 - accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 109.9914 - accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "512/512 [==============================] - 0s 86us/step - loss: 116.6090 - accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 649.4145 - accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "512/512 [==============================] - 0s 90us/step - loss: 246.2939 - accuracy: 0.0039\n",
      "Epoch 439/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 84us/step - loss: 82.4785 - accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 62.2520 - accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 202.2577 - accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 148.2094 - accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 1465.5424 - accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 10727.4336 - accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 4608.2429 - accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "512/512 [==============================] - 0s 92us/step - loss: 1288.2893 - accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "512/512 [==============================] - 0s 82us/step - loss: 58.7648 - accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 70.8059 - accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 542.1367 - accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 769.2668 - accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 456.6609 - accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 1799.7643 - accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 1485.3874 - accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 363.9101 - accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "512/512 [==============================] - 0s 64us/step - loss: 703.5446 - accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "512/512 [==============================] - 0s 64us/step - loss: 263.7687 - accuracy: 0.0039\n",
      "Epoch 457/500\n",
      "512/512 [==============================] - 0s 64us/step - loss: 193.6647 - accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "512/512 [==============================] - 0s 64us/step - loss: 515.5596 - accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "512/512 [==============================] - 0s 64us/step - loss: 125.4514 - accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 86.1349 - accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 54.0748 - accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 91.0054 - accuracy: 0.0020\n",
      "Epoch 463/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 126.0372 - accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 211.3855 - accuracy: 0.0020\n",
      "Epoch 465/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 58.5914 - accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 131.2285 - accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 531.7515 - accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 176.1787 - accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 11555.7809 - accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 1521.3689 - accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 2941.7145 - accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 432.0082 - accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 146.9742 - accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 326.2806 - accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 106.2712 - accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 40001.0651 - accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "512/512 [==============================] - 0s 78us/step - loss: 26230.6421 - accuracy: 0.0020\n",
      "Epoch 478/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 48958.5961 - accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "512/512 [==============================] - 0s 94us/step - loss: 9080.1022 - accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "512/512 [==============================] - 0s 94us/step - loss: 6342.3288 - accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 3107.0002 - accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "512/512 [==============================] - 0s 66us/step - loss: 9096.0127 - accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 9339.5001 - accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 788.1673 - accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "512/512 [==============================] - 0s 68us/step - loss: 3354.8578 - accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 292.4471 - accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "512/512 [==============================] - 0s 72us/step - loss: 1885.4747 - accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 220.1564 - accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 9576.2463 - accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 2288.1910 - accuracy: 0.0020\n",
      "Epoch 491/500\n",
      "512/512 [==============================] - 0s 76us/step - loss: 5601.4569 - accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "512/512 [==============================] - 0s 84us/step - loss: 1857.3353 - accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 1637.2079 - accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 1312.5008 - accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 215862.2119 - accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 876740.7047 - accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "512/512 [==============================] - 0s 74us/step - loss: 359149.4827 - accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 2162.8100 - accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "512/512 [==============================] - 0s 70us/step - loss: 134.4509 - accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "512/512 [==============================] - 0s 80us/step - loss: 103.1745 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(xTrain, yTrain, epochs=500, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[743298411072.0,\n",
       " 627431300096.0,\n",
       " 526536452288.0,\n",
       " 438062212480.0,\n",
       " 358375861216.0,\n",
       " 293379840896.0,\n",
       " 238436422144.0,\n",
       " 191943616752.0,\n",
       " 153742887136.0,\n",
       " 121574496936.0,\n",
       " 94991638376.0,\n",
       " 73520784296.0,\n",
       " 56517702300.0,\n",
       " 42962299592.0,\n",
       " 31844055572.0,\n",
       " 23732036774.0,\n",
       " 17247784358.0,\n",
       " 12387010707.0,\n",
       " 8655951872.0,\n",
       " 6023130720.5,\n",
       " 4231722364.5,\n",
       " 2904471121.0,\n",
       " 1966968413.125,\n",
       " 1317274928.0,\n",
       " 879423006.5625,\n",
       " 564158900.25,\n",
       " 363589316.3125,\n",
       " 230730744.984375,\n",
       " 144949495.796875,\n",
       " 89977036.08984375,\n",
       " 54709341.90625,\n",
       " 32924482.224609375,\n",
       " 19413866.109375,\n",
       " 11198199.287597656,\n",
       " 6526281.510253906,\n",
       " 3720867.090576172,\n",
       " 2087417.7973632812,\n",
       " 1173487.2098999023,\n",
       " 669491.8656311035,\n",
       " 397715.2810611725,\n",
       " 254953.4603652954,\n",
       " 178794.61471414566,\n",
       " 139206.9850769043,\n",
       " 116928.38297367096,\n",
       " 106079.00926208496,\n",
       " 101194.59688568115,\n",
       " 98543.56803131104,\n",
       " 97327.07120513916,\n",
       " 96611.81510162354,\n",
       " 96374.66958618164,\n",
       " 95964.89343643188,\n",
       " 96000.83329772949,\n",
       " 95972.00344085693,\n",
       " 96012.2911453247,\n",
       " 95963.39527893066,\n",
       " 95904.34600830078,\n",
       " 95916.84635162354,\n",
       " 96018.62821960449,\n",
       " 96009.94048690796,\n",
       " 95886.56142425537,\n",
       " 95908.61264038086,\n",
       " 95703.88545227051,\n",
       " 95839.9288597107,\n",
       " 95906.36193084717,\n",
       " 95762.7060623169,\n",
       " 95900.3265838623,\n",
       " 95755.062292099,\n",
       " 95623.82693481445,\n",
       " 95639.8560333252,\n",
       " 95597.3468208313,\n",
       " 95683.88632202148,\n",
       " 95568.3603591919,\n",
       " 95510.78993225098,\n",
       " 95619.62300872803,\n",
       " 95603.1900024414,\n",
       " 95625.90043640137,\n",
       " 95487.98741912842,\n",
       " 95358.3038482666,\n",
       " 95448.9993095398,\n",
       " 95364.50080108643,\n",
       " 95286.15377044678,\n",
       " 95312.20321655273,\n",
       " 95272.21906280518,\n",
       " 95282.15685272217,\n",
       " 95076.5442276001,\n",
       " 95159.63943099976,\n",
       " 95121.18249511719,\n",
       " 95174.19263839722,\n",
       " 95430.58610534668,\n",
       " 94932.56362915039,\n",
       " 95106.32744598389,\n",
       " 94872.87194824219,\n",
       " 94945.0690536499,\n",
       " 94800.99017333984,\n",
       " 94758.62773895264,\n",
       " 95114.58084869385,\n",
       " 94737.78481292725,\n",
       " 94753.0620803833,\n",
       " 94671.1907157898,\n",
       " 94556.2790145874,\n",
       " 94440.52293395996,\n",
       " 94481.05898284912,\n",
       " 94605.93463897705,\n",
       " 94598.83016967773,\n",
       " 94402.53662109375,\n",
       " 94156.45042800903,\n",
       " 94328.93885803223,\n",
       " 94725.13665008545,\n",
       " 94121.7730102539,\n",
       " 94474.55229949951,\n",
       " 94078.3613357544,\n",
       " 94008.0313796997,\n",
       " 93939.23965454102,\n",
       " 94037.71439743042,\n",
       " 94003.09275054932,\n",
       " 94133.98753738403,\n",
       " 94130.17315673828,\n",
       " 93733.9379272461,\n",
       " 93533.6955947876,\n",
       " 93885.25929260254,\n",
       " 93442.86653137207,\n",
       " 93604.62907123566,\n",
       " 93687.1127319336,\n",
       " 94059.33281707764,\n",
       " 93426.77167510986,\n",
       " 93359.83301258087,\n",
       " 93007.73373413086,\n",
       " 93116.0165719986,\n",
       " 92964.85301971436,\n",
       " 92970.29684448242,\n",
       " 92844.49732589722,\n",
       " 92924.43327331543,\n",
       " 92532.39414215088,\n",
       " 92777.61592102051,\n",
       " 93182.5611114502,\n",
       " 92771.99774169922,\n",
       " 92614.87056732178,\n",
       " 92143.76643371582,\n",
       " 92881.45310974121,\n",
       " 92439.38929367065,\n",
       " 92795.80248260498,\n",
       " 91922.05185699463,\n",
       " 92132.50109863281,\n",
       " 95702.8363814354,\n",
       " 91555.59436035156,\n",
       " 92561.95703125,\n",
       " 91622.01012420654,\n",
       " 92867.2067489624,\n",
       " 91855.28845214844,\n",
       " 91586.10596466064,\n",
       " 91141.20957946777,\n",
       " 90971.57098388672,\n",
       " 91044.56261444092,\n",
       " 91127.6354625225,\n",
       " 90827.17444610596,\n",
       " 90368.0463104248,\n",
       " 90375.90195465088,\n",
       " 90177.00576972961,\n",
       " 90548.22220993042,\n",
       " 90375.03932952881,\n",
       " 90330.83059692383,\n",
       " 90224.48198461533,\n",
       " 90354.17677688599,\n",
       " 90255.51057815552,\n",
       " 89020.49175643921,\n",
       " 89492.1272277832,\n",
       " 89487.17214012146,\n",
       " 89335.72874450684,\n",
       " 89893.72491455078,\n",
       " 88619.76914978027,\n",
       " 88532.42443084717,\n",
       " 88965.59150695801,\n",
       " 89007.49434661865,\n",
       " 89522.97466278076,\n",
       " 88389.17416000366,\n",
       " 88140.09152984619,\n",
       " 87489.19100952148,\n",
       " 88430.82876968384,\n",
       " 87821.98617362976,\n",
       " 87007.82621002197,\n",
       " 87346.63275146484,\n",
       " 86989.96475601196,\n",
       " 86687.4687423706,\n",
       " 86549.53981781006,\n",
       " 86861.0043334961,\n",
       " 86863.784450531,\n",
       " 86070.76560974121,\n",
       " 85894.54808807373,\n",
       " 85507.77411651611,\n",
       " 85422.01072311401,\n",
       " 85696.3810043335,\n",
       " 84471.60933685303,\n",
       " 85031.41233062744,\n",
       " 87025.66400146484,\n",
       " 85509.32611083984,\n",
       " 84931.66941833496,\n",
       " 84230.56747055054,\n",
       " 85870.90726470947,\n",
       " 84311.1769065857,\n",
       " 85108.10163116455,\n",
       " 86713.11528015137,\n",
       " 84479.85274505615,\n",
       " 82422.26508331299,\n",
       " 83208.99899291992,\n",
       " 82386.1873550415,\n",
       " 82026.33225631714,\n",
       " 83066.14476013184,\n",
       " 81173.68348693848,\n",
       " 81102.19500732422,\n",
       " 80870.47107696533,\n",
       " 81365.9768371582,\n",
       " 82104.13563537598,\n",
       " 80597.8623085022,\n",
       " 80754.74751281738,\n",
       " 80000.8678817749,\n",
       " 79786.92433547974,\n",
       " 78803.03805541992,\n",
       " 81356.52182769775,\n",
       " 77949.20993041992,\n",
       " 77728.47417449951,\n",
       " 78160.5647354126,\n",
       " 77309.9970741272,\n",
       " 77387.84707641602,\n",
       " 76934.24756240845,\n",
       " 78036.69149017334,\n",
       " 78420.95136642456,\n",
       " 77993.52296829224,\n",
       " 76879.73921966553,\n",
       " 76137.53318786621,\n",
       " 74954.91689682007,\n",
       " 75400.52339172363,\n",
       " 76097.1521987915,\n",
       " 75033.73852539062,\n",
       " 74919.19109916687,\n",
       " 74858.62089920044,\n",
       " 72580.99394226074,\n",
       " 73110.40358734131,\n",
       " 72575.7601852417,\n",
       " 71583.75743865967,\n",
       " 72858.12339401245,\n",
       " 70077.74700546265,\n",
       " 81933.24689102173,\n",
       " 72011.91285133362,\n",
       " 69996.42713165283,\n",
       " 68654.62529373169,\n",
       " 70405.58576965332,\n",
       " 67975.56855010986,\n",
       " 77111.6923828125,\n",
       " 69303.49348449707,\n",
       " 69261.36176872253,\n",
       " 66449.41027450562,\n",
       " 68421.80368804932,\n",
       " 65370.75658416748,\n",
       " 65154.698097229004,\n",
       " 64751.4840965271,\n",
       " 64145.90417480469,\n",
       " 64077.0791015625,\n",
       " 68031.61597442627,\n",
       " 64367.133752822876,\n",
       " 66783.49324035645,\n",
       " 61225.80782699585,\n",
       " 61990.98991012573,\n",
       " 63864.231758117676,\n",
       " 64734.78741455078,\n",
       " 59577.166637420654,\n",
       " 75436.73806762695,\n",
       " 64186.04555892944,\n",
       " 62770.110916137695,\n",
       " 60210.220222473145,\n",
       " 56873.807750701904,\n",
       " 56070.558280944824,\n",
       " 57670.91075706482,\n",
       " 56438.85138320923,\n",
       " 69006.0411529541,\n",
       " 56309.42659378052,\n",
       " 58629.04292678833,\n",
       " 54751.83088684082,\n",
       " 52906.026010513306,\n",
       " 51974.8643989563,\n",
       " 51467.85881233215,\n",
       " 51949.8207988739,\n",
       " 55411.6159324646,\n",
       " 51753.26873207092,\n",
       " 47968.61044883728,\n",
       " 50280.15369796753,\n",
       " 49317.15699386597,\n",
       " 48187.67502784729,\n",
       " 50751.32582473755,\n",
       " 46440.659564971924,\n",
       " 45725.3240609169,\n",
       " 45822.87645339966,\n",
       " 51482.81178665161,\n",
       " 43018.07667732239,\n",
       " 41942.25657463074,\n",
       " 43875.34450531006,\n",
       " 43800.6275806427,\n",
       " 40648.645111083984,\n",
       " 44640.77955245972,\n",
       " 43527.47080993652,\n",
       " 42956.51496505737,\n",
       " 42597.144622802734,\n",
       " 42732.09677886963,\n",
       " 37148.80848693848,\n",
       " 38491.24833774567,\n",
       " 37847.04764175415,\n",
       " 38657.201038360596,\n",
       " 33916.750007629395,\n",
       " 52921.04117202759,\n",
       " 32305.55976676941,\n",
       " 35174.66886138916,\n",
       " 31733.009956359863,\n",
       " 35005.927379608154,\n",
       " 33539.00053405762,\n",
       " 32000.85121536255,\n",
       " 29371.845155715942,\n",
       " 29684.51760673523,\n",
       " 30679.775592803955,\n",
       " 29016.701986312866,\n",
       " 32960.44720840454,\n",
       " 41167.887269973755,\n",
       " 26012.41725540161,\n",
       " 24286.836391448975,\n",
       " 31125.725397109985,\n",
       " 26558.041339874268,\n",
       " 25198.06344985962,\n",
       " 24188.5848236084,\n",
       " 22318.037561416626,\n",
       " 27965.95315361023,\n",
       " 22522.231862068176,\n",
       " 21771.303318977356,\n",
       " 22105.681329727173,\n",
       " 20926.991936683655,\n",
       " 19623.731486320496,\n",
       " 20199.04949951172,\n",
       " 19613.67885017395,\n",
       " 19386.62033176422,\n",
       " 18396.034958839417,\n",
       " 18341.30724811554,\n",
       " 16749.351440429688,\n",
       " 17703.213121414185,\n",
       " 16790.230476379395,\n",
       " 17095.208647727966,\n",
       " 16125.447724342346,\n",
       " 15328.123322486877,\n",
       " 13778.16725730896,\n",
       " 15429.234359264374,\n",
       " 15101.378786087036,\n",
       " 12789.849606513977,\n",
       " 11979.689673900604,\n",
       " 11306.92376613617,\n",
       " 14054.801415920258,\n",
       " 13334.970582485199,\n",
       " 12044.998799324036,\n",
       " 13432.857892513275,\n",
       " 13526.29267168045,\n",
       " 11239.143887043,\n",
       " 9782.855957508087,\n",
       " 8517.899484157562,\n",
       " 10063.224116802216,\n",
       " 7445.182258605957,\n",
       " 7525.723807811737,\n",
       " 7846.846416473389,\n",
       " 7475.553537368774,\n",
       " 6293.8179495334625,\n",
       " 9190.945659637451,\n",
       " 5686.963066577911,\n",
       " 6304.895976066589,\n",
       " 5112.247192174196,\n",
       " 5227.866566896439,\n",
       " 11554.79427742958,\n",
       " 5001.924876213074,\n",
       " 7199.4875593185425,\n",
       " 4023.0989220142365,\n",
       " 4963.41188621521,\n",
       " 5358.485935926437,\n",
       " 3321.6183733940125,\n",
       " 2973.7477934360504,\n",
       " 4879.902392864227,\n",
       " 2991.189729809761,\n",
       " 2674.115820169449,\n",
       " 2720.398490846157,\n",
       " 3341.455921292305,\n",
       " 3560.7045484781265,\n",
       " 2316.1576892137527,\n",
       " 1918.192669570446,\n",
       " 1618.9723131656647,\n",
       " 4897.357432603836,\n",
       " 2542.3912540078163,\n",
       " 1938.3317004442215,\n",
       " 1316.8383021354675,\n",
       " 1826.1467152237892,\n",
       " 1682.0617695450783,\n",
       " 1060.8109658360481,\n",
       " 3243.8074918985367,\n",
       " 1033.3489771485329,\n",
       " 1367.7964836359024,\n",
       " 3710.6307153105736,\n",
       " 911.937538176775,\n",
       " 1096.7287295162678,\n",
       " 629.5409271419048,\n",
       " 938.3535711765289,\n",
       " 828.0610027611256,\n",
       " 679.0317455530167,\n",
       " 665.4639418423176,\n",
       " 386.035488024354,\n",
       " 350.35461363196373,\n",
       " 383.66359417140484,\n",
       " 1026.2236566096544,\n",
       " 417.64092484116554,\n",
       " 474.4986011609435,\n",
       " 207.07048776745796,\n",
       " 283.5610390454531,\n",
       " 273.9793819412589,\n",
       " 187.84329392760992,\n",
       " 156.03655698895454,\n",
       " 118.76788590848446,\n",
       " 157.95884231105447,\n",
       " 163.908565569669,\n",
       " 152.14495650678873,\n",
       " 121.26793798431754,\n",
       " 124.83072615414858,\n",
       " 210.650264903903,\n",
       " 161.32814100780524,\n",
       " 410.0948760211468,\n",
       " 84.35113493725657,\n",
       " 135.69992648623884,\n",
       " 96.60785315558314,\n",
       " 89.48325197771192,\n",
       " 95.21224186941981,\n",
       " 103.4791629370302,\n",
       " 169.95781695097685,\n",
       " 100.19492177292705,\n",
       " 137.20276821777225,\n",
       " 65.44092661887407,\n",
       " 109.99143972247839,\n",
       " 116.60904370993376,\n",
       " 649.4144548252225,\n",
       " 246.2938984669745,\n",
       " 82.47845609486103,\n",
       " 62.25204901956022,\n",
       " 202.2577009089291,\n",
       " 148.20941998064518,\n",
       " 1465.5424336642027,\n",
       " 10727.433550998569,\n",
       " 4608.242880582809,\n",
       " 1288.289265319705,\n",
       " 58.76475140824914,\n",
       " 70.80585572682321,\n",
       " 542.1367388144135,\n",
       " 769.2668078094721,\n",
       " 456.66094344481826,\n",
       " 1799.764298522845,\n",
       " 1485.387439109385,\n",
       " 363.91013146936893,\n",
       " 703.5446197912097,\n",
       " 263.76874156296253,\n",
       " 193.66465360298753,\n",
       " 515.5595896095037,\n",
       " 125.45139466039836,\n",
       " 86.13488181680441,\n",
       " 54.074841575697064,\n",
       " 91.00537777878344,\n",
       " 126.03717724606395,\n",
       " 211.38554152473807,\n",
       " 58.591448321938515,\n",
       " 131.22852073982358,\n",
       " 531.7515190280974,\n",
       " 176.17865162715316,\n",
       " 11555.780852943659,\n",
       " 1521.3688622899354,\n",
       " 2941.714528735727,\n",
       " 432.00821635872126,\n",
       " 146.97423573955894,\n",
       " 326.2806129567325,\n",
       " 106.27117972820997,\n",
       " 40001.0650921464,\n",
       " 26230.64214656502,\n",
       " 48958.59612413496,\n",
       " 9080.10219567269,\n",
       " 6342.328773200512,\n",
       " 3107.0002428889275,\n",
       " 9096.012714382261,\n",
       " 9339.500140119344,\n",
       " 788.1673453003168,\n",
       " 3354.8578169234097,\n",
       " 292.4470955580473,\n",
       " 1885.474712509662,\n",
       " 220.15644246712327,\n",
       " 9576.246318042278,\n",
       " 2288.1910273581743,\n",
       " 5601.456949669868,\n",
       " 1857.335307057947,\n",
       " 1637.2078667879105,\n",
       " 1312.5007554888725,\n",
       " 215862.21193885803,\n",
       " 876740.7046611309,\n",
       " 359149.4827105999,\n",
       " 2162.809966471046,\n",
       " 134.45089813694358,\n",
       " 103.17447812110186]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[15,8])\n",
    "\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "# plt.plot(hist.history['accuracy'], 'b')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 491us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[75.9870267347856, 0.0]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(xTest, yTest, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7388871188476527"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 예측\n",
    "(model.predict(xTest) - yTest).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor flow 로 선형 회귀 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data/실습데이터/data-02-stock_daily.csv', delimiter=',')\n",
    "\n",
    "# 데이터 분할\n",
    "x = xy[:,:-1]    # 732, 4\n",
    "y = xy[:,[-1]]   # 732, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할 70 : 30\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, train_size=0.7, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([4,1], mean=0.01, stddev=0.01))\n",
    "b =  tf.Variable(tf.random_normal([1]))\n",
    "x = tf.placeholder(tf.float32, shape=[None,4])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.matmul(x, w) + b\n",
    "hf = tf.clip_by_value(hf, 1e-10, 1.0)\n",
    "cost = tf.reduce_mean(tf.square(hf - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0step \n",
      " 오차 : 428063.375\n",
      "1000step \n",
      " 오차 : 428063.375\n",
      "2000step \n",
      " 오차 : 428063.375\n",
      "3000step \n",
      " 오차 : 428063.375\n",
      "4000step \n",
      " 오차 : 428063.375\n",
      "5000step \n",
      " 오차 : 428063.375\n",
      "6000step \n",
      " 오차 : 428063.375\n",
      "7000step \n",
      " 오차 : 428063.375\n",
      "8000step \n",
      " 오차 : 428063.375\n",
      "9000step \n",
      " 오차 : 428063.375\n",
      "10000step \n",
      " 오차 : 428063.375\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        _, hfv, cv = sess.run([train, hf, cost], feed_dict={x:xTrain, y:yTrain})\n",
    "        \n",
    "        if step % 1000 == 0 :\n",
    "            print('{}step \\n 오차 : {}'.format(step, cv))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = pd.read_csv('data/실습데이터/trees.csv')\n",
    "xy = np.array(xy)\n",
    "\n",
    "x = xy[:,:-1]\n",
    "y = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할 70 : 30\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, train_size=0.7, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([2,1], mean=0.01, stddev=0.01))\n",
    "b =  tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.matmul(x, w) + b\n",
    "# hf = tf.clip_by_value(hf, 1e-10, 1.0)\n",
    "cost = tf.reduce_mean(tf.square(hf - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.0001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0step \n",
      " 오차 : 1061.63037109375\n",
      "1000step \n",
      " 오차 : 708.6178588867188\n",
      "2000step \n",
      " 오차 : 478.6383972167969\n",
      "3000step \n",
      " 오차 : 327.34881591796875\n",
      "4000step \n",
      " 오차 : 227.01162719726562\n",
      "5000step \n",
      " 오차 : 160.0042724609375\n",
      "6000step \n",
      " 오차 : 114.981689453125\n",
      "7000step \n",
      " 오차 : 84.56138610839844\n",
      "8000step \n",
      " 오차 : 63.8965950012207\n",
      "9000step \n",
      " 오차 : 49.78135299682617\n",
      "10000step \n",
      " 오차 : 40.0835075378418\n",
      "11000step \n",
      " 오차 : 33.37816619873047\n",
      "12000step \n",
      " 오차 : 28.708663940429688\n",
      "13000step \n",
      " 오차 : 25.430587768554688\n",
      "14000step \n",
      " 오차 : 23.108463287353516\n",
      "15000step \n",
      " 오차 : 21.446813583374023\n",
      "16000step \n",
      " 오차 : 20.244491577148438\n",
      "17000step \n",
      " 오차 : 19.364011764526367\n",
      "18000step \n",
      " 오차 : 18.710954666137695\n",
      "19000step \n",
      " 오차 : 18.220157623291016\n",
      "20000step \n",
      " 오차 : 17.846431732177734\n"
     ]
    }
   ],
   "source": [
    "cost_list = []\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(20001):\n",
    "        _, hfv, cv = sess.run([train, hf, cost], feed_dict={x:xTrain, y:yTrain})\n",
    "        \n",
    "        cost_list.append(cv)\n",
    "        \n",
    "        if step % 1000 == 0 :\n",
    "            print('{}step \\n 오차 : {}'.format(step, cv))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22ad7f50e88>]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cost_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
