{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 정하기\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight와 bias를 랜덤값으로 설정\n",
    "# ydata = xdata * w +b\n",
    "\n",
    "w = tf.Variable(tf.random_normal([1], name='weight'))\n",
    "b = tf.Variable(tf.random_normal([1], name='bias'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y 값을 받아올 placeholder 구성\n",
    "\n",
    "# tf.placeholder(데이터 타입, shape=)\n",
    "x = tf.placeholder(tf.float32, shape=[None])\n",
    "y = tf.placeholder(tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형식과 cost함수를 설정\n",
    "## 가설함수 노드\n",
    "hf = x * w + b\n",
    "# (예측값 - 실제값)^2 의 합들의 평균\n",
    "cost = tf.reduce_mean(tf.square(hf - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이져 및 학습률 설정\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# cost를 최소화 하도록 수정하는 함수\n",
    "train = opt.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 실행\n",
    "## 세션 실행\n",
    "sess = tf.Session()\n",
    "# 변수를 사용하기 위한 초기화\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34.090366 [-1.4497697] [-0.31781602]\n",
      "100 0.21868162 [-0.23169614] [1.5418066]\n",
      "200 0.13513193 [0.03177993] [1.4259217]\n",
      "300 0.083503366 [0.23889075] [1.3348132]\n",
      "400 0.05159996 [0.40169883] [1.2631935]\n",
      "500 0.03188562 [0.5296811] [1.2068942]\n",
      "600 0.019703357 [0.63028646] [1.1626376]\n",
      "700 0.012175504 [0.7093713] [1.127848]\n",
      "800 0.007523723 [0.77153945] [1.1005002]\n",
      "900 0.004649184 [0.8204093] [1.0790021]\n",
      "1000 0.002872918 [0.85882527] [1.0621032]\n",
      "1100 0.001775284 [0.88902384] [1.0488186]\n",
      "1200 0.0010970227 [0.9127625] [1.0383759]\n",
      "1300 0.0006778997 [0.93142325] [1.030167]\n",
      "1400 0.00041889554 [0.9460925] [1.0237141]\n",
      "1500 0.00025885602 [0.9576235] [1.0186414]\n",
      "1600 0.00015995596 [0.96668863] [1.0146537]\n",
      "1700 9.8839984e-05 [0.9738143] [1.0115192]\n",
      "1800 6.107768e-05 [0.9794156] [1.009055]\n",
      "1900 3.7742455e-05 [0.9838186] [1.0071182]\n",
      "2000 2.3324204e-05 [0.98727983] [1.0055957]\n"
     ]
    }
   ],
   "source": [
    "# 모델을 몇 번 실행할 것인가 ?\n",
    "for step in range(2001):\n",
    "    # _는 값을 무시한다. \n",
    "    _, cv, bv, wv = sess.run([train, cost, b, w], feed_dict={x:[1,2,3] ,\n",
    "                               y:[2,3,4]})\n",
    "    if step % 100 == 0 :\n",
    "        print(step, cv, bv, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.043237]\n",
      "[11.043237 11.546035]\n",
      "[11.043237 11.546035 12.048832]\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "print(sess.run(hf, feed_dict={x:[10]}))\n",
    "print(sess.run(hf, feed_dict={x:[10,10.5]}))\n",
    "print(sess.run(hf, feed_dict={x:[10,10.5,11]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight [-0.9999995], bias : [0.99999833], cost : 2.5579538e-12\n"
     ]
    }
   ],
   "source": [
    "# 변수값 초기화\n",
    "w = tf.Variable([100.], tf.float32)\n",
    "b = tf.Variable([-10.], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 모델 생성\n",
    "# hf = 100 * x - 10\n",
    "hf = x * w + b\n",
    "# cost = loss\n",
    "cost = tf.reduce_sum(tf.square(hf-y))\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = opt.minimize(cost)\n",
    "\n",
    "xtrain = [1,2,3,4,5]\n",
    "ytrain = [0,-1,-2,-3,-4]\n",
    "\n",
    "# 트레이닝\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:xtrain, y:ytrain})\n",
    "    \n",
    "wv, bv, cv = sess.run([w, b, cost], {x:xtrain ,y:ytrain})\n",
    "\n",
    "print('weight %s, bias : %s, cost : %s' %(wv,bv,cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 연습문제\n",
    "\n",
    "x = [1,3,5]\n",
    "y = [10,28,40]\n",
    "\n",
    "# b는 무시\n",
    "w = tf.placeholder(tf.float32)\n",
    "\n",
    "hf = x * w\n",
    "loss = tf.reduce_mean(tf.square(hf - y))\n",
    "\n",
    "# opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "# train = opt.minimize(cost)\n",
    "\n",
    "# 선형 회귀모델 작성\n",
    "# 시각화 -> weight 값이 -3 ~ 5 까지 0.1씩 증가시켜 가면서 cost 값의 변화를 출력\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "lv = []\n",
    "cv = []\n",
    "for i in list(np.arange(-60, 75, 0.1)):\n",
    "    l = sess.run(loss, feed_dict={w:i})\n",
    "    cv.append(i)\n",
    "    lv.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dc9f2305c8>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(cv, lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 경사하강법에서 update 구문 작성\n",
    "xdata = [1,2,3]\n",
    "ydata = [1,2,3]\n",
    "\n",
    "w = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "hf = x * w\n",
    "cost = tf.reduce_mean(tf.square(hf - y))\n",
    "\n",
    "# 경사하강법 구현\n",
    "lr = 0.1\n",
    "\n",
    "grdient = tf.reduce_mean((w * x - y) * x)  # 미분\n",
    "descent = w - lr * grdient\n",
    "# tensorflow에서는 할당을 할 때 assign 함수로만 가능하다.\n",
    "update = w.assign(descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.8093711] 0.59619296\n",
      "1 [0.8983313] 0.16958368\n",
      "2 [0.9457767] 0.048237104\n",
      "3 [0.9710809] 0.013720776\n",
      "4 [0.98457646] 0.0039027936\n",
      "5 [0.99177414] 0.0011101322\n",
      "6 [0.99561286] 0.00031576783\n",
      "7 [0.9976602] 8.981933e-05\n",
      "8 [0.9987521] 2.5547723e-05\n",
      "9 [0.99933445] 7.2669877e-06\n",
      "10 [0.99964505] 2.0669447e-06\n",
      "11 [0.9998107] 5.878943e-07\n",
      "12 [0.999899] 1.6723531e-07\n",
      "13 [0.9999461] 4.7552575e-08\n",
      "14 [0.9999713] 1.35488945e-08\n",
      "15 [0.9999847] 3.8586307e-09\n",
      "16 [0.99999183] 1.0968755e-09\n",
      "17 [0.99999565] 3.1215208e-10\n",
      "18 [0.9999977] 8.887113e-11\n",
      "19 [0.99999875] 2.4941235e-11\n",
      "20 [0.99999934] 7.461883e-12\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21):\n",
    "    _, cv, wv = sess.run([update, cost, w], feed_dict={x:xdata, y:ydata})\n",
    "    print(step, wv, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1data = [73,93,90,95,72]  # 5명 모의고사 점수\n",
    "x2data = [80,88,92,98,66]\n",
    "x3data = [75,92,90,100,70]\n",
    "\n",
    "ydata = [152,185,180,195,140]  # 5명 수능 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf = x * w + b\n",
    "w1 = tf.Variable(tf.random_normal([1]))\n",
    "w2 = tf.Variable(tf.random_normal([1]))\n",
    "w3 = tf.Variable(tf.random_normal([1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hf - y))\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(1e-5)\n",
    "train = opt.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50209.082 [-47.2463   -55.498383 -55.94022  -58.94895  -42.617058]\n",
      "100 2.2632785 [151.6981  182.76897 181.41922 196.7566  138.9286 ]\n",
      "200 2.2197587 [151.66731 182.7937  181.41187 196.74374 138.95772]\n",
      "300 2.1783183 [151.63727 182.81778 181.4047  196.73111 138.98608]\n",
      "400 2.1387858 [151.60803 182.8413  181.39775 196.71872 139.01381]\n",
      "500 2.1011376 [151.57956 182.86423 181.39105 196.70657 139.04085]\n",
      "600 2.0652616 [151.5518  182.88658 181.38454 196.69466 139.06721]\n",
      "700 2.0310302 [151.52477 182.90839 181.3782  196.68294 139.09296]\n",
      "800 1.9984124 [151.49846 182.92967 181.37212 196.67146 139.11809]\n",
      "900 1.9673065 [151.47281 182.95042 181.36618 196.66019 139.14258]\n",
      "1000 1.9376526 [151.44785 182.97066 181.36044 196.64912 139.16649]\n",
      "1100 1.9093659 [151.42351 182.99037 181.35486 196.63824 139.18982]\n",
      "1200 1.8824135 [151.39981 183.00961 181.34949 196.6276  139.21259]\n",
      "1300 1.856665 [151.37677 183.02843 181.34431 196.61714 139.23483]\n",
      "1400 1.8321002 [151.3543  183.04672 181.33925 196.60683 139.2565 ]\n",
      "1500 1.8086859 [151.3324  183.06459 181.33437 196.59674 139.27763]\n",
      "1600 1.7863239 [151.3111  183.08202 181.32965 196.58682 139.2983 ]\n",
      "1700 1.7649968 [151.29033 183.099   181.32509 196.57707 139.31844]\n",
      "1800 1.7446188 [151.27013 183.11557 181.32066 196.56749 139.33809]\n",
      "1900 1.7251556 [151.25046 183.13174 181.3164  196.55807 139.3573 ]\n",
      "2000 1.7065947 [151.2313  183.1475  181.31229 196.54883 139.376  ]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cv, hfv, _ = sess.run([cost, hf, train], feed_dict={x1:x1data, x2:x2data, x3:x3data, y:ydata})\n",
    "    if step % 100 == 0:\n",
    "        print(step, cv, hfv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행렬로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = [[73,93,90,95,72],  # 5명 모의고사 점수\n",
    "        [80,88,92,98,66],\n",
    "        [75,92,90,100,70]]\n",
    "ydata = [[152],[185],[180],[195],[140]]  # 5명 수능 점수\n",
    "\n",
    "# 배열로 만들고 전치\n",
    "xdata = np.array(xdata).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape  # 5,3\n",
    "np.shape(ydata)  # 5,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf = x * w + b\n",
    "# (None,3) * (3,1) + 1\n",
    "\n",
    "# 행렬곱 함수 matmul\n",
    "hf = tf.matmul(x, w) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hf - y))\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(1e-5)\n",
    "\n",
    "train = opt.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " cost:54736.4375,\n",
      " hf:[[-50.437664]\n",
      " [-70.100464]\n",
      " [-64.62681 ]\n",
      " [-68.77898 ]\n",
      " [-55.45664 ]]\n",
      "\n",
      "100 \n",
      " cost:23.729286193847656,\n",
      " hf:[[157.10413]\n",
      " [178.72977]\n",
      " [183.11307]\n",
      " [198.1131 ]\n",
      " [134.17798]]\n",
      "\n",
      "200 \n",
      " cost:22.62679672241211,\n",
      " hf:[[156.93933]\n",
      " [178.85626]\n",
      " [183.06706]\n",
      " [198.062  ]\n",
      " [134.32472]]\n",
      "\n",
      "300 \n",
      " cost:21.57847023010254,\n",
      " hf:[[156.77867]\n",
      " [178.97961]\n",
      " [183.02223]\n",
      " [198.01218]\n",
      " [134.46786]]\n",
      "\n",
      "400 \n",
      " cost:20.581632614135742,\n",
      " hf:[[156.62202]\n",
      " [179.09988]\n",
      " [182.97852]\n",
      " [197.96346]\n",
      " [134.6074 ]]\n",
      "\n",
      "500 \n",
      " cost:19.633686065673828,\n",
      " hf:[[156.4693 ]\n",
      " [179.2172 ]\n",
      " [182.93594]\n",
      " [197.91594]\n",
      " [134.74353]]\n",
      "\n",
      "600 \n",
      " cost:18.73245620727539,\n",
      " hf:[[156.32042]\n",
      " [179.33156]\n",
      " [182.89449]\n",
      " [197.86955]\n",
      " [134.87627]]\n",
      "\n",
      "700 \n",
      " cost:17.875385284423828,\n",
      " hf:[[156.17525]\n",
      " [179.44308]\n",
      " [182.85405]\n",
      " [197.82422]\n",
      " [135.00569]]\n",
      "\n",
      "800 \n",
      " cost:17.060413360595703,\n",
      " hf:[[156.0337 ]\n",
      " [179.55183]\n",
      " [182.81465]\n",
      " [197.77997]\n",
      " [135.13191]]\n",
      "\n",
      "900 \n",
      " cost:16.285533905029297,\n",
      " hf:[[155.89574]\n",
      " [179.65788]\n",
      " [182.77629]\n",
      " [197.73677]\n",
      " [135.255  ]]\n",
      "\n",
      "1000 \n",
      " cost:15.548593521118164,\n",
      " hf:[[155.7612 ]\n",
      " [179.7613 ]\n",
      " [182.7389 ]\n",
      " [197.69458]\n",
      " [135.37506]]\n",
      "\n",
      "1100 \n",
      " cost:14.847936630249023,\n",
      " hf:[[155.63005]\n",
      " [179.86214]\n",
      " [182.70248]\n",
      " [197.65338]\n",
      " [135.49213]]\n",
      "\n",
      "1200 \n",
      " cost:14.181661605834961,\n",
      " hf:[[155.50218]\n",
      " [179.96046]\n",
      " [182.66699]\n",
      " [197.61316]\n",
      " [135.6063 ]]\n",
      "\n",
      "1300 \n",
      " cost:13.548090934753418,\n",
      " hf:[[155.37753]\n",
      " [180.05637]\n",
      " [182.63243]\n",
      " [197.57388]\n",
      " [135.71764]]\n",
      "\n",
      "1400 \n",
      " cost:12.945643424987793,\n",
      " hf:[[155.25601]\n",
      " [180.14987]\n",
      " [182.59874]\n",
      " [197.53554]\n",
      " [135.82622]]\n",
      "\n",
      "1500 \n",
      " cost:12.372751235961914,\n",
      " hf:[[155.13753]\n",
      " [180.24106]\n",
      " [182.56593]\n",
      " [197.49806]\n",
      " [135.9321 ]]\n",
      "\n",
      "1600 \n",
      " cost:11.827971458435059,\n",
      " hf:[[155.02202]\n",
      " [180.32999]\n",
      " [182.53397]\n",
      " [197.46147]\n",
      " [136.03535]]\n",
      "\n",
      "1700 \n",
      " cost:11.309940338134766,\n",
      " hf:[[154.90941]\n",
      " [180.41669]\n",
      " [182.50284]\n",
      " [197.42574]\n",
      " [136.13608]]\n",
      "\n",
      "1800 \n",
      " cost:10.817340850830078,\n",
      " hf:[[154.79962]\n",
      " [180.50125]\n",
      " [182.47252]\n",
      " [197.39084]\n",
      " [136.23428]]\n",
      "\n",
      "1900 \n",
      " cost:10.348902702331543,\n",
      " hf:[[154.69258]\n",
      " [180.58368]\n",
      " [182.44295]\n",
      " [197.35674]\n",
      " [136.33006]]\n",
      "\n",
      "2000 \n",
      " cost:9.903470993041992,\n",
      " hf:[[154.58827]\n",
      " [180.66411]\n",
      " [182.41417]\n",
      " [197.32347]\n",
      " [136.42348]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    _,cv,hfv,wv = sess.run([train, cost, hf, w], feed_dict={x:xdata, y:ydata})\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print('{} \\n cost:{},\\n hf:{}'.format(step, cv, hfv), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>71</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1    2    3\n",
       "0   73  80   75  152\n",
       "1   93  88   93  185\n",
       "2   89  91   90  180\n",
       "3   96  98  100  196\n",
       "4   73  66   70  142\n",
       "5   53  46   55  101\n",
       "6   69  74   77  149\n",
       "7   47  56   60  115\n",
       "8   87  79   90  175\n",
       "9   79  70   88  164\n",
       "10  69  70   73  141\n",
       "11  70  65   74  141\n",
       "12  93  95   91  184\n",
       "13  79  80   73  152\n",
       "14  70  73   78  148\n",
       "15  93  89   96  192\n",
       "16  78  75   68  147\n",
       "17  81  90   93  183\n",
       "18  88  92   86  177\n",
       "19  78  83   77  159\n",
       "20  82  86   90  177\n",
       "21  86  82   89  175\n",
       "22  78  83   85  175\n",
       "23  76  83   71  149\n",
       "24  96  93   95  192"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data-01-test-score.csv', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array(data.iloc[:,0:3])  # 25, 4\n",
    "ydata = np.array(data.iloc[:,3])    # 25, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cost:6624.603515625\n",
      "hf:[[ 81.116234]\n",
      " [ 99.268105]\n",
      " [ 97.02109 ]\n",
      " [103.692566]\n",
      " [ 77.85727 ]\n",
      " [ 54.72843 ]\n",
      " [ 74.3123  ]\n",
      " [ 50.379726]\n",
      " [ 90.860435]\n",
      " [ 80.070274]\n",
      " [ 74.15183 ]\n",
      " [ 73.19443 ]\n",
      " [102.24626 ]\n",
      " [ 87.96404 ]\n",
      " [ 74.71418 ]\n",
      " [ 98.70881 ]\n",
      " [ 86.72205 ]\n",
      " [ 87.45096 ]\n",
      " [ 97.518326]\n",
      " [ 86.743286]\n",
      " [ 88.03219 ]\n",
      " [ 91.13821 ]\n",
      " [ 84.34565 ]\n",
      " [ 86.45872 ]\n",
      " [103.492   ]]\n",
      "100\n",
      "cost:1120.642822265625\n",
      "hf:[[150.69766 ]\n",
      " [183.04391 ]\n",
      " [179.47798 ]\n",
      " [193.65565 ]\n",
      " [141.65443 ]\n",
      " [102.03212 ]\n",
      " [141.85406 ]\n",
      " [100.727486]\n",
      " [169.38713 ]\n",
      " [153.17648 ]\n",
      " [139.10255 ]\n",
      " [137.36409 ]\n",
      " [187.27197 ]\n",
      " [158.42447 ]\n",
      " [142.6062  ]\n",
      " [183.86227 ]\n",
      " [153.67552 ]\n",
      " [168.57468 ]\n",
      " [178.53015 ]\n",
      " [159.24379 ]\n",
      " [167.19792 ]\n",
      " [169.8803  ]\n",
      " [159.76566 ]\n",
      " [156.23329 ]\n",
      " [190.21626 ]]\n",
      "200\n",
      "cost:1116.41162109375\n",
      "hf:[[150.56085 ]\n",
      " [183.0134  ]\n",
      " [179.36555 ]\n",
      " [193.68822 ]\n",
      " [141.53792 ]\n",
      " [102.20389 ]\n",
      " [142.07365 ]\n",
      " [101.158554]\n",
      " [169.58058 ]\n",
      " [153.71228 ]\n",
      " [139.19481 ]\n",
      " [137.57451 ]\n",
      " [186.99834 ]\n",
      " [157.98428 ]\n",
      " [142.8642  ]\n",
      " [183.96712 ]\n",
      " [153.10948 ]\n",
      " [168.90395 ]\n",
      " [178.224   ]\n",
      " [158.98418 ]\n",
      " [167.41833 ]\n",
      " [169.99545 ]\n",
      " [159.92023 ]\n",
      " [155.72968 ]\n",
      " [190.08966 ]]\n",
      "300\n",
      "cost:1112.4847412109375\n",
      "hf:[[150.43202]\n",
      " [182.98174]\n",
      " [179.25803]\n",
      " [193.72011]\n",
      " [141.42284]\n",
      " [102.36614]\n",
      " [142.28676]\n",
      " [101.57677]\n",
      " [169.76308]\n",
      " [154.22362]\n",
      " [139.28381]\n",
      " [137.77466]\n",
      " [186.7358 ]\n",
      " [157.56123]\n",
      " [143.1134 ]\n",
      " [184.06606]\n",
      " [152.56377]\n",
      " [169.22408]\n",
      " [177.93102]\n",
      " [158.73643]\n",
      " [167.63171]\n",
      " [170.10432]\n",
      " [160.07076]\n",
      " [155.24811]\n",
      " [189.96645]]\n",
      "400\n",
      "cost:1108.839111328125\n",
      "hf:[[150.31079 ]\n",
      " [182.94907 ]\n",
      " [179.1552  ]\n",
      " [193.75133 ]\n",
      " [141.30925 ]\n",
      " [102.519356]\n",
      " [142.49353 ]\n",
      " [101.98253 ]\n",
      " [169.9352  ]\n",
      " [154.7116  ]\n",
      " [139.36967 ]\n",
      " [137.96503 ]\n",
      " [186.48384 ]\n",
      " [157.15463 ]\n",
      " [143.3541  ]\n",
      " [184.15936 ]\n",
      " [152.0376  ]\n",
      " [169.53534 ]\n",
      " [177.65065 ]\n",
      " [158.5     ]\n",
      " [167.83833 ]\n",
      " [170.20724 ]\n",
      " [160.21732 ]\n",
      " [154.78761 ]\n",
      " [189.84648 ]]\n",
      "500\n",
      "cost:1105.4527587890625\n",
      "hf:[[150.19676]\n",
      " [182.91547]\n",
      " [179.05685]\n",
      " [193.78185]\n",
      " [141.19716]\n",
      " [102.66397]\n",
      " [142.69423]\n",
      " [102.37624]\n",
      " [170.09741]\n",
      " [155.17725]\n",
      " [139.45253]\n",
      " [138.14606]\n",
      " [186.24208]\n",
      " [156.76381]\n",
      " [143.58664]\n",
      " [184.24731]\n",
      " [151.53026]\n",
      " [169.83798]\n",
      " [177.38234]\n",
      " [158.2744 ]\n",
      " [168.0384 ]\n",
      " [170.30446]\n",
      " [160.36006]\n",
      " [154.34732]\n",
      " [189.72972]]\n",
      "600\n",
      "cost:1102.30615234375\n",
      "hf:[[150.0896 ]\n",
      " [182.88106]\n",
      " [178.96283]\n",
      " [193.81172]\n",
      " [141.08662]\n",
      " [102.80041]\n",
      " [142.88904]\n",
      " [102.7583 ]\n",
      " [170.25026]\n",
      " [155.62161]\n",
      " [139.53249]\n",
      " [138.31819]\n",
      " [186.01007]\n",
      " [156.38814]\n",
      " [143.81131]\n",
      " [184.33017]\n",
      " [151.04102]\n",
      " [170.1323 ]\n",
      " [177.12558]\n",
      " [158.05913]\n",
      " [168.23216]\n",
      " [170.39627]\n",
      " [160.49908]\n",
      " [153.92633]\n",
      " [189.61601]]\n",
      "700\n",
      "cost:1099.3812255859375\n",
      "hf:[[149.98895 ]\n",
      " [182.84592 ]\n",
      " [178.8729  ]\n",
      " [193.84094 ]\n",
      " [140.97762 ]\n",
      " [102.929085]\n",
      " [143.07816 ]\n",
      " [103.129074]\n",
      " [170.39417 ]\n",
      " [156.0456  ]\n",
      " [139.60968 ]\n",
      " [138.48183 ]\n",
      " [185.78743 ]\n",
      " [156.02701 ]\n",
      " [144.02841 ]\n",
      " [184.40822 ]\n",
      " [150.5692  ]\n",
      " [170.41849 ]\n",
      " [176.87985 ]\n",
      " [157.85374 ]\n",
      " [168.41982 ]\n",
      " [170.48296 ]\n",
      " [160.63448 ]\n",
      " [153.52379 ]\n",
      " [189.50536 ]]\n",
      "800\n",
      "cost:1096.6612548828125\n",
      "hf:[[149.89447 ]\n",
      " [182.81013 ]\n",
      " [178.78691 ]\n",
      " [193.86952 ]\n",
      " [140.87016 ]\n",
      " [103.05037 ]\n",
      " [143.2617  ]\n",
      " [103.488914]\n",
      " [170.52959 ]\n",
      " [156.45012 ]\n",
      " [139.68416 ]\n",
      " [138.63737 ]\n",
      " [185.57373 ]\n",
      " [155.6798  ]\n",
      " [144.23819 ]\n",
      " [184.48164 ]\n",
      " [150.11412 ]\n",
      " [170.69684 ]\n",
      " [176.64471 ]\n",
      " [157.65778 ]\n",
      " [168.60161 ]\n",
      " [170.56473 ]\n",
      " [160.76631 ]\n",
      " [153.13889 ]\n",
      " [189.39758 ]]\n",
      "900\n",
      "cost:1094.130615234375\n",
      "hf:[[149.80585]\n",
      " [182.77377]\n",
      " [178.70467]\n",
      " [193.89748]\n",
      " [140.76428]\n",
      " [103.16463]\n",
      " [143.43991]\n",
      " [103.8382 ]\n",
      " [170.65695]\n",
      " [156.83607]\n",
      " [139.75607]\n",
      " [138.7852 ]\n",
      " [185.3686 ]\n",
      " [155.34598]\n",
      " [144.44095]\n",
      " [184.55072]\n",
      " [149.67514]\n",
      " [170.96751]\n",
      " [176.41965]\n",
      " [157.47083]\n",
      " [168.77768]\n",
      " [170.64186]\n",
      " [160.89473]\n",
      " [152.77086]\n",
      " [189.29266]]\n",
      "1000\n",
      "cost:1091.7750244140625\n",
      "hf:[[149.72278]\n",
      " [182.73694]\n",
      " [178.626  ]\n",
      " [193.92482]\n",
      " [140.65997]\n",
      " [103.27223]\n",
      " [143.61293]\n",
      " [104.17724]\n",
      " [170.77664]\n",
      " [157.20427]\n",
      " [139.82549]\n",
      " [138.92567]\n",
      " [185.17172]\n",
      " [155.025  ]\n",
      " [144.6369 ]\n",
      " [184.61563]\n",
      " [149.25168]\n",
      " [171.23077]\n",
      " [176.20427]\n",
      " [157.29248]\n",
      " [168.94824]\n",
      " [170.71457]\n",
      " [161.0198 ]\n",
      " [152.41898]\n",
      " [189.19052]]\n",
      "1100\n",
      "cost:1089.5814208984375\n",
      "hf:[[149.64503 ]\n",
      " [182.6997  ]\n",
      " [178.5508  ]\n",
      " [193.95155 ]\n",
      " [140.55727 ]\n",
      " [103.373505]\n",
      " [143.78093 ]\n",
      " [104.506355]\n",
      " [170.8891  ]\n",
      " [157.55553 ]\n",
      " [139.89253 ]\n",
      " [139.05916 ]\n",
      " [184.98274 ]\n",
      " [154.71635 ]\n",
      " [144.82634 ]\n",
      " [184.67662 ]\n",
      " [148.84314 ]\n",
      " [171.48683 ]\n",
      " [175.99818 ]\n",
      " [157.12238 ]\n",
      " [169.11351 ]\n",
      " [170.7831  ]\n",
      " [161.14165 ]\n",
      " [152.08255 ]\n",
      " [189.09105 ]]\n",
      "1200\n",
      "cost:1087.5379638671875\n",
      "hf:[[149.57227]\n",
      " [182.66208]\n",
      " [178.47887]\n",
      " [193.97769]\n",
      " [140.45615]\n",
      " [103.46876]\n",
      " [143.94405]\n",
      " [104.82589]\n",
      " [170.99461]\n",
      " [157.89056]\n",
      " [139.95724]\n",
      " [139.18591]\n",
      " [184.80128]\n",
      " [154.4195 ]\n",
      " [145.00943]\n",
      " [184.73384]\n",
      " [148.44894]\n",
      " [171.73587]\n",
      " [175.8009 ]\n",
      " [156.9601 ]\n",
      " [169.27362]\n",
      " [170.84758]\n",
      " [161.26028]\n",
      " [151.76085]\n",
      " [188.99417]]\n",
      "1300\n",
      "cost:1085.6331787109375\n",
      "hf:[[149.5043  ]\n",
      " [182.62422 ]\n",
      " [178.4101  ]\n",
      " [194.00327 ]\n",
      " [140.35664 ]\n",
      " [103.55831 ]\n",
      " [144.1025  ]\n",
      " [105.136116]\n",
      " [171.09361 ]\n",
      " [158.21017 ]\n",
      " [140.01978 ]\n",
      " [139.30634 ]\n",
      " [184.62714 ]\n",
      " [154.13406 ]\n",
      " [145.18651 ]\n",
      " [184.78754 ]\n",
      " [148.0686  ]\n",
      " [171.97815 ]\n",
      " [175.61214 ]\n",
      " [156.80536 ]\n",
      " [169.42882 ]\n",
      " [170.90833 ]\n",
      " [161.37589 ]\n",
      " [151.45332 ]\n",
      " [188.89987 ]]\n",
      "1400\n",
      "cost:1083.8570556640625\n",
      "hf:[[149.44081 ]\n",
      " [182.5861  ]\n",
      " [178.3443  ]\n",
      " [194.02824 ]\n",
      " [140.25871 ]\n",
      " [103.642426]\n",
      " [144.25632 ]\n",
      " [105.43733 ]\n",
      " [171.18636 ]\n",
      " [158.515   ]\n",
      " [140.08014 ]\n",
      " [139.42067 ]\n",
      " [184.45987 ]\n",
      " [153.8595  ]\n",
      " [145.35768 ]\n",
      " [184.83783 ]\n",
      " [147.70154 ]\n",
      " [172.21379 ]\n",
      " [175.43143 ]\n",
      " [156.65775 ]\n",
      " [169.57916 ]\n",
      " [170.96542 ]\n",
      " [161.48845 ]\n",
      " [151.15926 ]\n",
      " [188.808   ]]\n",
      "1500\n",
      "cost:1082.199951171875\n",
      "hf:[[149.38159 ]\n",
      " [182.54784 ]\n",
      " [178.28139 ]\n",
      " [194.05266 ]\n",
      " [140.16237 ]\n",
      " [103.721405]\n",
      " [144.40575 ]\n",
      " [105.72983 ]\n",
      " [171.27321 ]\n",
      " [158.80571 ]\n",
      " [140.13846 ]\n",
      " [139.52922 ]\n",
      " [184.29932 ]\n",
      " [153.5954  ]\n",
      " [145.52322 ]\n",
      " [184.88493 ]\n",
      " [147.34729 ]\n",
      " [172.44302 ]\n",
      " [175.2585  ]\n",
      " [156.51697 ]\n",
      " [169.7249  ]\n",
      " [171.0191  ]\n",
      " [161.5981  ]\n",
      " [150.87811 ]\n",
      " [188.71855 ]]\n",
      "1600\n",
      "cost:1080.6533203125\n",
      "hf:[[149.32643]\n",
      " [182.50943]\n",
      " [178.22122]\n",
      " [194.0765 ]\n",
      " [140.06763]\n",
      " [103.7955 ]\n",
      " [144.55087]\n",
      " [106.01387]\n",
      " [171.35445]\n",
      " [159.08293]\n",
      " [140.19481]\n",
      " [139.63225]\n",
      " [184.14511]\n",
      " [153.34134]\n",
      " [145.6833 ]\n",
      " [184.92899]\n",
      " [147.00534]\n",
      " [172.66603]\n",
      " [175.09297]\n",
      " [156.38275]\n",
      " [169.86613]\n",
      " [171.0695 ]\n",
      " [161.70491]\n",
      " [150.60931]\n",
      " [188.63142]]\n",
      "1700\n",
      "cost:1079.2088623046875\n",
      "hf:[[149.27513]\n",
      " [182.47096]\n",
      " [178.1637 ]\n",
      " [194.09982]\n",
      " [139.97449]\n",
      " [103.86497]\n",
      " [144.69185]\n",
      " [106.28974]\n",
      " [171.4304 ]\n",
      " [159.3473 ]\n",
      " [140.24924]\n",
      " [139.73004]\n",
      " [183.99704]\n",
      " [153.09694]\n",
      " [145.83815]\n",
      " [184.97017]\n",
      " [146.6753 ]\n",
      " [172.883  ]\n",
      " [174.93457]\n",
      " [156.25478]\n",
      " [170.00307]\n",
      " [171.11685]\n",
      " [161.80898]\n",
      " [150.35233]\n",
      " [188.54657]]\n",
      "1800\n",
      "cost:1077.859375\n",
      "hf:[[149.22746]\n",
      " [182.43246]\n",
      " [178.10866]\n",
      " [194.12262]\n",
      " [139.88292]\n",
      " [103.93004]\n",
      " [144.8288 ]\n",
      " [106.55768]\n",
      " [171.50128]\n",
      " [159.5994 ]\n",
      " [140.30185]\n",
      " [139.82281]\n",
      " [183.85483]\n",
      " [152.8618 ]\n",
      " [145.98792]\n",
      " [185.0086 ]\n",
      " [146.35666]\n",
      " [173.09407]\n",
      " [174.78294]\n",
      " [156.13275]\n",
      " [170.13577]\n",
      " [171.16125]\n",
      " [161.91034]\n",
      " [150.10664]\n",
      " [188.46393]]\n",
      "1900\n",
      "cost:1076.597900390625\n",
      "hf:[[149.18324 ]\n",
      " [182.394   ]\n",
      " [178.05605 ]\n",
      " [194.14488 ]\n",
      " [139.79294 ]\n",
      " [103.99096 ]\n",
      " [144.96184 ]\n",
      " [106.817955]\n",
      " [171.56741 ]\n",
      " [159.83975 ]\n",
      " [140.35268 ]\n",
      " [139.91081 ]\n",
      " [183.71826 ]\n",
      " [152.63554 ]\n",
      " [146.1328  ]\n",
      " [185.04445 ]\n",
      " [146.04903 ]\n",
      " [173.29944 ]\n",
      " [174.63783 ]\n",
      " [156.01643 ]\n",
      " [170.26445 ]\n",
      " [171.20287 ]\n",
      " [162.0091  ]\n",
      " [149.87175 ]\n",
      " [188.38344 ]]\n",
      "2000\n",
      "cost:1075.418212890625\n",
      "hf:[[149.14226 ]\n",
      " [182.35556 ]\n",
      " [178.0057  ]\n",
      " [194.16663 ]\n",
      " [139.7045  ]\n",
      " [104.0479  ]\n",
      " [145.0911  ]\n",
      " [107.070755]\n",
      " [171.629   ]\n",
      " [160.06888 ]\n",
      " [140.40181 ]\n",
      " [139.99428 ]\n",
      " [183.58707 ]\n",
      " [152.41783 ]\n",
      " [146.27296 ]\n",
      " [185.07784 ]\n",
      " [145.75197 ]\n",
      " [173.49925 ]\n",
      " [174.49892 ]\n",
      " [155.90552 ]\n",
      " [170.38919 ]\n",
      " [171.24182 ]\n",
      " [162.10529 ]\n",
      " [149.64719 ]\n",
      " [188.30502 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w = tf.Variable(tf.random_normal([3,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf = tf.matmul(x,w) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hf - y))\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(1e-5)\n",
    "train = opt.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "for step in range(2001):\n",
    "    _, cv, hfv = sess.run([train, cost, hf], feed_dict={x:xdata, y:ydata})\n",
    "    \n",
    "    if step % 100 == 0 :\n",
    "        print('{}\\ncost:{}\\nhf:{}'.format(step, cv, hfv))\n",
    "    \n",
    "    if step == 2000 :\n",
    "        ypred = hfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[178.41196]], dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hf, feed_dict={x:[[90,90,90]]})  # 178로 예상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "ydata = [[0],[0],[0],[1],[1],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid 활성화 함수\n",
    "hf = tf.sigmoid(tf.matmul(x,w) + b)\n",
    "\n",
    "cost = -tf.reduce_mean( y * tf.log(hf) + (1 - y) * tf.log(1 - hf) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt와 train을 한 노드로 구성\n",
    "train = tf.train.GradientDescentOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계치를 0.5로\n",
    "#                     조건          데이터타입     => 1.0 or 0.0\n",
    "predicted = tf.cast(hf > 0.5, dtype=tf.float32)\n",
    "\n",
    "# tf.equal 안에 들어온 값이 같으면 True 다르면 False\n",
    "accuracy = tf.cast(tf.equal(predicted, y), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 step \n",
      " cost : 4.341135\n",
      "1000 step \n",
      " cost : 0.6972429\n",
      "2000 step \n",
      " cost : 0.6337049\n",
      "3000 step \n",
      " cost : 0.5923927\n",
      "4000 step \n",
      " cost : 0.5630381\n",
      "5000 step \n",
      " cost : 0.54092497\n",
      "6000 step \n",
      " cost : 0.523343\n",
      "7000 step \n",
      " cost : 0.5086995\n",
      "8000 step \n",
      " cost : 0.49603057\n",
      "9000 step \n",
      " cost : 0.484736\n",
      "10000 step \n",
      " cost : 0.4744313\n",
      "11000 step \n",
      " cost : 0.46486446\n",
      "12000 step \n",
      " cost : 0.45586613\n",
      "13000 step \n",
      " cost : 0.4473209\n",
      "14000 step \n",
      " cost : 0.43914816\n",
      "15000 step \n",
      " cost : 0.43129098\n",
      "16000 step \n",
      " cost : 0.42370823\n",
      "17000 step \n",
      " cost : 0.41636983\n",
      "18000 step \n",
      " cost : 0.40925336\n",
      "19000 step \n",
      " cost : 0.40234172\n",
      "20000 step \n",
      " cost : 0.39562145\n",
      "예측값 : [[0.17549132]\n",
      " [0.22155122]\n",
      " [0.69717467]\n",
      " [0.62818426]\n",
      " [0.8045498 ]\n",
      " [0.94811827]],\n",
      " 예측분류 : [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]],\n",
      " 판단 : [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(20001):\n",
    "        _, hfv, cv = sess.run([train, hf, cost], feed_dict={x:xdata, y:ydata})\n",
    "        if step % 1000 == 0:\n",
    "            print('%s step \\n cost : %s' % (step,cv))\n",
    "            \n",
    "    hv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})\n",
    "    print('예측값 : %s,\\n 예측분류 : %s,\\n 판단 : %s'%(hv, pv, av))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>369</td>\n",
       "      <td>6</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>406</td>\n",
       "      <td>6</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>447</td>\n",
       "      <td>8</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
       "0    293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   \n",
       "1      1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   \n",
       "2      8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   \n",
       "3     14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   \n",
       "4     17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   \n",
       "..   ...  ..   ...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "465   98   6  3.04  2.40   2   0   0   0   1   0  11   0   0   0   1   0  76   \n",
       "466  369   6  3.88  2.72   1   0   0   0   1   0  12   0   0   0   1   0  77   \n",
       "467  406   6  5.36  3.96   1   0   0   0   1   0  12   0   0   0   0   0  62   \n",
       "468   25   8  4.32  3.20   0   0   0   0   0   0  11   0   0   0   0   0  58   \n",
       "469  447   8  5.20  4.10   0   0   0   0   0   0  12   0   0   0   0   0  49   \n",
       "\n",
       "     17  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     0  \n",
       "..   ..  \n",
       "465   0  \n",
       "466   0  \n",
       "467   0  \n",
       "468   1  \n",
       "469   0  \n",
       "\n",
       "[470 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/dataset/ThoraricSurgery.csv', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array(data.iloc[:,:17])\n",
    "ydata = np.array(data.iloc[:,-1]).reshape(470,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "xdata = scaler.fit_transform(xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,17])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([17, 1], mean=0.01, stddev=0.01), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.sigmoid(tf.matmul(x, w) + b)\n",
    "\n",
    "cost = -tf.reduce_mean( y * tf.log(hf) + (1 - y) * tf.log(1 - hf) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계치를 0.5로\n",
    "#                     조건          데이터타입     => 1.0 or 0.0\n",
    "predicted = tf.cast(hf > 0.45, dtype=tf.float32)\n",
    "\n",
    "# tf.equal 안에 들어온 값이 같으면 True 다르면 False\n",
    "accuracy = tf.cast(tf.equal(predicted, y), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Step \n",
      " Cost : \n",
      "0.77841395\n",
      "10000 Step \n",
      " Cost : \n",
      "0.4047715\n",
      "20000 Step \n",
      " Cost : \n",
      "0.3935637\n",
      "30000 Step \n",
      " Cost : \n",
      "0.38924652\n",
      "40000 Step \n",
      " Cost : \n",
      "0.3864512\n",
      "정확도 : 85.1063829787234\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(40001):\n",
    "        _, cv = sess.run([train, cost], feed_dict={x:xdata, y:ydata})\n",
    "        if step % 10000 == 0 :\n",
    "            print('%s Step \\n Cost : \\n%s' %(step, cv))\n",
    "            \n",
    "    hv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})\n",
    "    \n",
    "    acc = av.sum() / av.shape[0] * 100\n",
    "    # 예측값 : %s,\\n 예측분류 : %s,\\n \n",
    "    print('정확도 : %s'%(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>369</td>\n",
       "      <td>6</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>406</td>\n",
       "      <td>6</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>447</td>\n",
       "      <td>8</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
       "0    293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   \n",
       "1      1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   \n",
       "2      8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   \n",
       "3     14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   \n",
       "4     17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   \n",
       "..   ...  ..   ...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "465   98   6  3.04  2.40   2   0   0   0   1   0  11   0   0   0   1   0  76   \n",
       "466  369   6  3.88  2.72   1   0   0   0   1   0  12   0   0   0   1   0  77   \n",
       "467  406   6  5.36  3.96   1   0   0   0   1   0  12   0   0   0   0   0  62   \n",
       "468   25   8  4.32  3.20   0   0   0   0   0   0  11   0   0   0   0   0  58   \n",
       "469  447   8  5.20  4.10   0   0   0   0   0   0  12   0   0   0   0   0  49   \n",
       "\n",
       "     17  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     0  \n",
       "..   ..  \n",
       "465   0  \n",
       "466   0  \n",
       "467   0  \n",
       "468   1  \n",
       "469   0  \n",
       "\n",
       "[470 rows x 18 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/dataset/ThoraricSurgery.csv', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array(data.iloc[:,:17])\n",
    "ydata = np.array(data.iloc[:,-1]).reshape(470,1)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "xdata = scaler.fit_transform(xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(xdata,ydata, train_size=0.7, random_state = 777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,17])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "# cost의 nan을 방지하기 위해 weight 의 평균과 표준편차를 정해준다.\n",
    "w = tf.Variable(tf.random_normal([17, 1], mean=0.01, stddev=0.01), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.sigmoid(tf.matmul(x, w) + b)\n",
    "\n",
    "cost = -tf.reduce_mean( y * tf.log(hf) + (1 - y) * tf.log(1 - hf) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계치를 0.5로\n",
    "#                     조건          데이터타입     => 1.0 or 0.0\n",
    "predicted = tf.cast(hf > 0.45, dtype=tf.float32)\n",
    "\n",
    "# tf.equal 안에 들어온 값이 같으면 True 다르면 False\n",
    "accuracy = tf.cast(tf.equal(predicted, y), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Step \n",
      " Cost : \n",
      "0.86008245\n",
      "1000 Step \n",
      " Cost : \n",
      "0.65655875\n",
      "2000 Step \n",
      " Cost : \n",
      "0.5597251\n",
      "3000 Step \n",
      " Cost : \n",
      "0.50726646\n",
      "4000 Step \n",
      " Cost : \n",
      "0.47686008\n",
      "5000 Step \n",
      " Cost : \n",
      "0.4581333\n",
      "6000 Step \n",
      " Cost : \n",
      "0.4459894\n",
      "7000 Step \n",
      " Cost : \n",
      "0.43775842\n",
      "8000 Step \n",
      " Cost : \n",
      "0.4319578\n",
      "9000 Step \n",
      " Cost : \n",
      "0.42772397\n",
      "10000 Step \n",
      " Cost : \n",
      "0.4245323\n",
      "11000 Step \n",
      " Cost : \n",
      "0.42205352\n",
      "12000 Step \n",
      " Cost : \n",
      "0.4200744\n",
      "13000 Step \n",
      " Cost : \n",
      "0.41845393\n",
      "14000 Step \n",
      " Cost : \n",
      "0.41709617\n",
      "15000 Step \n",
      " Cost : \n",
      "0.41593498\n",
      "16000 Step \n",
      " Cost : \n",
      "0.41492358\n",
      "17000 Step \n",
      " Cost : \n",
      "0.4140285\n",
      "18000 Step \n",
      " Cost : \n",
      "0.41322544\n",
      "19000 Step \n",
      " Cost : \n",
      "0.41249627\n",
      "20000 Step \n",
      " Cost : \n",
      "0.41182736\n",
      "21000 Step \n",
      " Cost : \n",
      "0.41120836\n",
      "22000 Step \n",
      " Cost : \n",
      "0.4106313\n",
      "23000 Step \n",
      " Cost : \n",
      "0.41008982\n",
      "24000 Step \n",
      " Cost : \n",
      "0.40957898\n",
      "25000 Step \n",
      " Cost : \n",
      "0.40909472\n",
      "26000 Step \n",
      " Cost : \n",
      "0.4086338\n",
      "27000 Step \n",
      " Cost : \n",
      "0.40819353\n",
      "28000 Step \n",
      " Cost : \n",
      "0.40777162\n",
      "29000 Step \n",
      " Cost : \n",
      "0.40736634\n",
      "30000 Step \n",
      " Cost : \n",
      "0.40697607\n",
      "예측값 : [[0.12508488]\n",
      " [0.21635947]\n",
      " [0.21111533]\n",
      " [0.22857028]\n",
      " [0.1211991 ]\n",
      " [0.18063748]\n",
      " [0.21429357]\n",
      " [0.06036678]\n",
      " [0.1012817 ]\n",
      " [0.192976  ]\n",
      " [0.08720189]\n",
      " [0.26193178]\n",
      " [0.23003578]\n",
      " [0.14700904]\n",
      " [0.05473655]\n",
      " [0.28955325]\n",
      " [0.15745127]\n",
      " [0.07175559]\n",
      " [0.15370676]\n",
      " [0.10064313]\n",
      " [0.16376734]\n",
      " [0.22011742]\n",
      " [0.15370542]\n",
      " [0.16314775]\n",
      " [0.06465355]\n",
      " [0.13579321]\n",
      " [0.07933438]\n",
      " [0.08192113]\n",
      " [0.05594006]\n",
      " [0.12124589]\n",
      " [0.08720815]\n",
      " [0.09171695]\n",
      " [0.2492961 ]\n",
      " [0.11428383]\n",
      " [0.18583432]\n",
      " [0.40353906]\n",
      " [0.20307326]\n",
      " [0.20375854]\n",
      " [0.15682453]\n",
      " [0.19327754]\n",
      " [0.1860125 ]\n",
      " [0.09197772]\n",
      " [0.192074  ]\n",
      " [0.06233656]\n",
      " [0.24211374]\n",
      " [0.17098245]\n",
      " [0.09124586]\n",
      " [0.11147302]\n",
      " [0.08484241]\n",
      " [0.10223511]\n",
      " [0.28793544]\n",
      " [0.17566037]\n",
      " [0.19283774]\n",
      " [0.23636389]\n",
      " [0.15424955]\n",
      " [0.18657759]\n",
      " [0.08867875]\n",
      " [0.20695937]\n",
      " [0.18430567]\n",
      " [0.17159739]\n",
      " [0.06343377]\n",
      " [0.15368238]\n",
      " [0.09756216]\n",
      " [0.14037389]\n",
      " [0.27477974]\n",
      " [0.08408269]\n",
      " [0.19152442]\n",
      " [0.260511  ]\n",
      " [0.05141082]\n",
      " [0.09023905]\n",
      " [0.16278312]\n",
      " [0.14354247]\n",
      " [0.2280811 ]\n",
      " [0.2326811 ]\n",
      " [0.12890622]\n",
      " [0.15957505]\n",
      " [0.08473769]\n",
      " [0.07510141]\n",
      " [0.13460872]\n",
      " [0.23645622]\n",
      " [0.22624725]\n",
      " [0.10653147]\n",
      " [0.1230841 ]\n",
      " [0.19243339]\n",
      " [0.1898888 ]\n",
      " [0.1343714 ]\n",
      " [0.16109353]\n",
      " [0.11365712]\n",
      " [0.15845859]\n",
      " [0.15333042]\n",
      " [0.23363143]\n",
      " [0.17526603]\n",
      " [0.1276035 ]\n",
      " [0.15343848]\n",
      " [0.03612763]\n",
      " [0.16909829]\n",
      " [0.23213494]\n",
      " [0.10408068]\n",
      " [0.16517219]\n",
      " [0.1785343 ]\n",
      " [0.26705897]\n",
      " [0.25734985]\n",
      " [0.25358424]\n",
      " [0.08223614]\n",
      " [0.11624771]\n",
      " [0.07887092]\n",
      " [0.11303744]\n",
      " [0.14532545]\n",
      " [0.09206542]\n",
      " [0.22445285]\n",
      " [0.18544215]\n",
      " [0.17492843]\n",
      " [0.11301816]\n",
      " [0.19451371]\n",
      " [0.08170161]\n",
      " [0.0720692 ]\n",
      " [0.34126085]\n",
      " [0.26579493]\n",
      " [0.22644511]\n",
      " [0.16747916]\n",
      " [0.21102002]\n",
      " [0.11615753]\n",
      " [0.10592666]\n",
      " [0.14063048]\n",
      " [0.12511146]\n",
      " [0.25759846]\n",
      " [0.08586743]\n",
      " [0.08403873]\n",
      " [0.11368746]\n",
      " [0.16859215]\n",
      " [0.13019305]\n",
      " [0.13927165]\n",
      " [0.1645318 ]\n",
      " [0.1418213 ]\n",
      " [0.12881559]\n",
      " [0.2129339 ]\n",
      " [0.10096753]\n",
      " [0.18046167]\n",
      " [0.15223984]\n",
      " [0.23445752]\n",
      " [0.03894953]],\n",
      " 예측분류 : [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]],\n",
      " 정확도 : 86.52482269503547\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(30001):\n",
    "        _, cv = sess.run([train, cost], feed_dict={x:xtrain, y:ytrain})\n",
    "        if step % 1000 == 0 :\n",
    "            print('%s Step \\n Cost : \\n%s' %(step, cv))\n",
    "    \n",
    "    # test 데이터셋으로 모델 평가\n",
    "    hv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xtest, y:ytest})\n",
    "    \n",
    "    acc = av.sum() / av.shape[0] * 100\n",
    "    \n",
    "    print('예측값 : %s,\\n 예측분류 : %s,\\n 정확도 : %s'%(hv, pv, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
