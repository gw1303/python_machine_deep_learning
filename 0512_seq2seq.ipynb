{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "챗봇 : 베이즈이론 기반에서 시작 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>I've never ridden a horse.</td>\n",
       "      <td>Je ne suis jamais monté à cheval.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>I've never ridden a horse.</td>\n",
       "      <td>Je ne suis jamais monté sur un cheval.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>I've never seen Tom drunk.</td>\n",
       "      <td>Je n'ai jamais vu Tom ivre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>I've never seen a rainbow.</td>\n",
       "      <td>Je n'ai jamais vu d'arc-en-ciel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>I've never seen you laugh.</td>\n",
       "      <td>Je ne t’ai jamais vu rire.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              eng                                     fra\n",
       "0                             Go.                                    Va !\n",
       "1                             Hi.                                 Salut !\n",
       "2                             Hi.                                  Salut.\n",
       "3                            Run!                                 Cours !\n",
       "4                            Run!                                Courez !\n",
       "...                           ...                                     ...\n",
       "69995  I've never ridden a horse.       Je ne suis jamais monté à cheval.\n",
       "69996  I've never ridden a horse.  Je ne suis jamais monté sur un cheval.\n",
       "69997  I've never seen Tom drunk.             Je n'ai jamais vu Tom ivre.\n",
       "69998  I've never seen a rainbow.        Je n'ai jamais vu d'arc-en-ciel.\n",
       "69999  I've never seen you laugh.              Je ne t’ai jamais vu rire.\n",
       "\n",
       "[70000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/fra-eng/fra.txt', sep='\\t', header=None, names=['eng','fra','-'])\n",
    "df.shape # (175623, 3)\n",
    "df = df[:70000]\n",
    "df = df.iloc[:,:2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Va ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Cours ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Courez ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>I've never ridden a horse.</td>\n",
       "      <td>\\t Je ne suis jamais monté à cheval. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>I've never ridden a horse.</td>\n",
       "      <td>\\t Je ne suis jamais monté sur un cheval. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>I've never seen Tom drunk.</td>\n",
       "      <td>\\t Je n'ai jamais vu Tom ivre. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>I've never seen a rainbow.</td>\n",
       "      <td>\\t Je n'ai jamais vu d'arc-en-ciel. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>I've never seen you laugh.</td>\n",
       "      <td>\\t Je ne t’ai jamais vu rire. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              eng  \\\n",
       "0                             Go.   \n",
       "1                             Hi.   \n",
       "2                             Hi.   \n",
       "3                            Run!   \n",
       "4                            Run!   \n",
       "...                           ...   \n",
       "69995  I've never ridden a horse.   \n",
       "69996  I've never ridden a horse.   \n",
       "69997  I've never seen Tom drunk.   \n",
       "69998  I've never seen a rainbow.   \n",
       "69999  I've never seen you laugh.   \n",
       "\n",
       "                                                fra  \n",
       "0                                        \\t Va ! \\n  \n",
       "1                                     \\t Salut ! \\n  \n",
       "2                                      \\t Salut. \\n  \n",
       "3                                     \\t Cours ! \\n  \n",
       "4                                    \\t Courez ! \\n  \n",
       "...                                             ...  \n",
       "69995       \\t Je ne suis jamais monté à cheval. \\n  \n",
       "69996  \\t Je ne suis jamais monté sur un cheval. \\n  \n",
       "69997             \\t Je n'ai jamais vu Tom ivre. \\n  \n",
       "69998        \\t Je n'ai jamais vu d'arc-en-ciel. \\n  \n",
       "69999              \\t Je ne t’ai jamais vu rire. \\n  \n",
       "\n",
       "[70000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # fra 앞 뒤에 \\t \\n 추가\n",
    "# # ver.1\n",
    "# for i in range(len(df['fra'])) :\n",
    "#     df['fra'][i] = '\\t ' + df['fra'][i] + ' \\n'\n",
    "# df\n",
    "\n",
    "# # ver.2 // 더 빠름\n",
    "# temp = []\n",
    "# for i in df['eng'] :\n",
    "#     temp.append('\\t '+i+' \\n')\n",
    "# df['fra'] = temp\n",
    "# df\n",
    "\n",
    "# ver.3 // 제일 간결하고 빠른듯\n",
    "df['fra'] = df['fra'].apply(lambda x : '\\t '+x+' \\n')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글자단위 토큰화\n",
    "engVocab = set()\n",
    "fraVocab = set()\n",
    "\n",
    "for line in df.eng :\n",
    "    for c in line :\n",
    "        engVocab.add(c)\n",
    "        \n",
    "for line in df.fra :\n",
    "    for c in line :\n",
    "        fraVocab.add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 106\n"
     ]
    }
   ],
   "source": [
    "engVocabSize = len(engVocab) +1\n",
    "fraVocabSize = len(fraVocab) +1\n",
    "\n",
    "print(engVocabSize,fraVocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " '&': 6,\n",
       " \"'\": 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '/': 11,\n",
       " '0': 12,\n",
       " '1': 13,\n",
       " '2': 14,\n",
       " '3': 15,\n",
       " '4': 16,\n",
       " '5': 17,\n",
       " '6': 18,\n",
       " '7': 19,\n",
       " '8': 20,\n",
       " '9': 21,\n",
       " ':': 22,\n",
       " '?': 23,\n",
       " 'A': 24,\n",
       " 'B': 25,\n",
       " 'C': 26,\n",
       " 'D': 27,\n",
       " 'E': 28,\n",
       " 'F': 29,\n",
       " 'G': 30,\n",
       " 'H': 31,\n",
       " 'I': 32,\n",
       " 'J': 33,\n",
       " 'K': 34,\n",
       " 'L': 35,\n",
       " 'M': 36,\n",
       " 'N': 37,\n",
       " 'O': 38,\n",
       " 'P': 39,\n",
       " 'Q': 40,\n",
       " 'R': 41,\n",
       " 'S': 42,\n",
       " 'T': 43,\n",
       " 'U': 44,\n",
       " 'V': 45,\n",
       " 'W': 46,\n",
       " 'X': 47,\n",
       " 'Y': 48,\n",
       " 'Z': 49,\n",
       " 'a': 50,\n",
       " 'b': 51,\n",
       " 'c': 52,\n",
       " 'd': 53,\n",
       " 'e': 54,\n",
       " 'f': 55,\n",
       " 'g': 56,\n",
       " 'h': 57,\n",
       " 'i': 58,\n",
       " 'j': 59,\n",
       " 'k': 60,\n",
       " 'l': 61,\n",
       " 'm': 62,\n",
       " 'n': 63,\n",
       " 'o': 64,\n",
       " 'p': 65,\n",
       " 'q': 66,\n",
       " 'r': 67,\n",
       " 's': 68,\n",
       " 't': 69,\n",
       " 'u': 70,\n",
       " 'v': 71,\n",
       " 'w': 72,\n",
       " 'x': 73,\n",
       " 'y': 74,\n",
       " 'z': 75,\n",
       " 'ç': 76,\n",
       " 'é': 77,\n",
       " '’': 78,\n",
       " '€': 79}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engVocab = sorted(list(engVocab))\n",
    "fraVocab = sorted(list(fraVocab))\n",
    "\n",
    "dict(zip(engVocab, range(1,len(engVocab)+1)))\n",
    "dict(zip(fraVocab, range(1,len(fraVocab)+1)))\n",
    "\n",
    "engToIndex = dict([(c,i+1) for i,c in enumerate(engVocab)])\n",
    "fraToIndex = dict([(c,i+1) for i,c in enumerate(fraVocab)])\n",
    "engToIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩\n",
    "# 영어문장 인코딩\n",
    "encoderInput = []\n",
    "for line in df['eng'] :\n",
    "    t = []\n",
    "    for char in line :\n",
    "        t.append(engToIndex[char])\n",
    "    encoderInput.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 정수 인코딩\n",
    "# 영어문장 인코딩\n",
    "encoderInput = []\n",
    "for line in df['eng'] :\n",
    "    t = []\n",
    "    for char in line :\n",
    "        t.append(engToIndex[char])\n",
    "    encoderInput.append(t)\n",
    "    \n",
    "#encoderInput\n",
    "\n",
    "# 프랑스어 문장 인코딩\n",
    "decoderInput = []\n",
    "for line in df['fra'] :\n",
    "    t = []\n",
    "    for char in line :\n",
    "        t.append(fraToIndex[char])\n",
    "    decoderInput.append(t)\n",
    "    \n",
    "#decoderInput\n",
    "\n",
    "# 프랑스어 문장 출력\n",
    "decoderFra = []\n",
    "for line in df['fra'] :\n",
    "    t = []\n",
    "    i = 0\n",
    "    for char in line :\n",
    "        if i > 0 :\n",
    "            t.append(fraToIndex[char])\n",
    "        i+=1\n",
    "    decoderFra.append(t)\n",
    "    \n",
    "#decoderFra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 문장 -> 정수 변환 => 패딩\n",
    "# 각 언어별로 가장 긴 글자로 구성된 문장 길이로 통일\n",
    "maxEngLen = max([len(line) for line in df['eng']])\n",
    "maxFraLen = max([len(line) for line in df['fra']])\n",
    "\n",
    "# 패딩 라이브러리\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoderInput = pad_sequences(encoderInput, maxlen=maxEngLen, padding='post')\n",
    "decoderInput = pad_sequences(decoderInput, maxlen=maxFraLen, padding='post')\n",
    "decoderFra = pad_sequences(decoderFra, maxlen=maxFraLen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩 // cost를 구하기위해\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 3차원 배열로 바뀜\n",
    "encoderInput = to_categorical(encoderInput)\n",
    "decoderInput = to_categorical(decoderInput)\n",
    "decoderFra = to_categorical(decoderFra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 26, 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(encoderInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝시 이전 상태의 실제값을 현재 상태의 디코더 입력으로 해야함. (예측값 X)\n",
    "from keras.layers import LSTM, Dense, Input, Embedding\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "# functional api LSTM설계\n",
    "# ex> ip = Input(shape=(50,1)) / feature : 1개, time-step(시점) : 50개\n",
    "# lt = LSTM(출력)(입력)\n",
    "# d1 = Dense(10, activation='relu')(lt)\n",
    "# d2 = Dense(1, activation='sigmoid')(d1)\n",
    "# model(inputs=ip, outputs=d2)\n",
    "\n",
    "# 인코더 인풋\n",
    "encoderInputs = Input(shape=(None,engVocabSize))\n",
    "# 디코더 인풋  = (None, 프랑스어 문자 종류수)  // decoderInput.shape[2]\n",
    "decoderInputs = Input(shape=(None,fraVocabSize))\n",
    "\n",
    "# 인코더 LSTM 셀\n",
    "encoderLSTM = LSTM(units=256, return_state=True)\n",
    "# return_state : 마지막 상태정보를 다음 입력 상태점보로 전달할 것인가\n",
    "\n",
    "# 디코더 LSTM 셀\n",
    "decoderLSTM = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "\n",
    "# 인코더 LSTM 셀의 입력 정의\n",
    "_, stateH, stateC = encoderLSTM(encoderInputs)\n",
    "#             히든상태(위),셀상태(옆)\n",
    "encoderStates = [stateH, stateC]  # 컨텍스트 벡터\n",
    "\n",
    "decoderOutputs, _, _ = decoderLSTM(decoderInputs, initial_state=encoderStates)\n",
    "\n",
    "decoderSoftmax = Dense(fraVocabSize, activation='softmax')\n",
    "decoderOutputs = decoderSoftmax(decoderOutputs)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoderInputs, decoderInputs], decoderOutputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56000 samples, validate on 14000 samples\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 297s 5ms/step - loss: 0.2104 - val_loss: 0.3625\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 285s 5ms/step - loss: 0.2058 - val_loss: 0.3650\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 286s 5ms/step - loss: 0.2017 - val_loss: 0.3645\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 283s 5ms/step - loss: 0.1977 - val_loss: 0.3668\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 297s 5ms/step - loss: 0.1941 - val_loss: 0.3691\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 298s 5ms/step - loss: 0.1907 - val_loss: 0.3702\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 296s 5ms/step - loss: 0.1873 - val_loss: 0.3713\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 289s 5ms/step - loss: 0.1842 - val_loss: 0.3739\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 293s 5ms/step - loss: 0.1813 - val_loss: 0.3760\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 298s 5ms/step - loss: 0.1785 - val_loss: 0.3769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1503fed8f48>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoderInput, decoderInput], y=decoderFra, batch_size=64, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./seq2seqmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, None, 80)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, None, 106)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, 256), (None, 345088      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  [(None, None, 256),  371712      input_12[0][0]                   \n",
      "                                                                 lstm_11[0][1]                    \n",
      "                                                                 lstm_11[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 106)    27242       lstm_12[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 744,042\n",
      "Trainable params: 744,042\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "seq2seq 동작\n",
    "1) 입력 문장 -> 인코더 -> 은닉 상태, 셀 상태 얻어냄\n",
    "2) 상태 정보와 Start 시그널(\\t)을 디코더로 전달\n",
    "3) 다음 문자를 예측 stop 시그널(\\n)이 등잘할 때 까지 반복\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전날 저장한 모델 불러오기 ( 25 epoch 수행)\n",
    "from keras.models import *\n",
    "model = load_model('./seq2seqmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 생성\n",
    "from keras.layers import Input\n",
    "\n",
    "decoderStateInputHidden = Input(shape=(256,))\n",
    "decoderStateInputCell = Input(shape=(256,))\n",
    "decoderStateInputs = [decoderStateInputHidden, decoderStateInputCell]\n",
    "\n",
    "decoderOutputs, stateHidden, stateCell = decoderLSTM(decoderInputs, initial_state=decoderStateInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 테스트\n",
    "for i in [10, 100, 200, 300, 400] :\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 제너레이션\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "text = '''과수원에 있는 배가 맛있다\n",
    "그의 배는 많이 나왔다\n",
    "가는 길에 배를 탔고 오는 길에도 배를 탔다\n",
    "문일주는 던창이다\n",
    "김우진은 흡연충이다\n",
    "권순빈은 거창이다'''\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "\n",
    "vocSize = len(t.word_index) + 1\n",
    "# 1_15까지 존재, 원핫인코딩하면 인덱스가 0부터 시작 배열의 크기를 단어집합의 크기보다 +1만큼\n",
    "\n",
    "\n",
    "# 문장 분리해서 저장\n",
    "seqs = list()\n",
    "\n",
    "for line in text.split('\\n') :\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)) :\n",
    "        seq = encoded[:i+1]\n",
    "        seqs.append(seq)\n",
    "seqs\n",
    "\n",
    "# 문장의 최대 길이 저장 변수\n",
    "maxLen = max(len(i) for i in seqs)\n",
    "\n",
    "seqs = pad_sequences(seqs, maxlen=maxLen, padding='pre')\n",
    "seqs  # 맨 마지막 컬럼값이 y\n",
    "\n",
    "# x,y 데이터 나누기\n",
    "seqs = np.array(seqs)\n",
    "x = seqs[:,:-1]\n",
    "y = seqs[:,[-1]]\n",
    "\n",
    "# y값 원핫인코딩\n",
    "y = to_categorical(y, num_classes=vocSize)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.0833 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 3.0734 - accuracy: 0.1250\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 3.0634 - accuracy: 0.1250\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 3.0532 - accuracy: 0.1250\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 3.0427 - accuracy: 0.1250\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 3.0319 - accuracy: 0.1250\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 3.0208 - accuracy: 0.1250\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 3.0093 - accuracy: 0.1250\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.9973 - accuracy: 0.1250\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.9849 - accuracy: 0.1250\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.9719 - accuracy: 0.1250\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.9585 - accuracy: 0.1250\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.9445 - accuracy: 0.1250\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 2.9300 - accuracy: 0.1250\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 126us/step - loss: 2.9150 - accuracy: 0.1250\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.8995 - accuracy: 0.1250\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 2.8836 - accuracy: 0.1250\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.8674 - accuracy: 0.1250\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.8508 - accuracy: 0.1250\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.8339 - accuracy: 0.1250\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.8167 - accuracy: 0.1875\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 2.7992 - accuracy: 0.1875\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.7811 - accuracy: 0.1875\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 62us/step - loss: 2.7628 - accuracy: 0.1875\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.7440 - accuracy: 0.1875\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.7246 - accuracy: 0.1875\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 63us/step - loss: 2.7047 - accuracy: 0.1875\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 2.6841 - accuracy: 0.1875\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 2.6628 - accuracy: 0.1875\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 62us/step - loss: 2.6409 - accuracy: 0.1875\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.6183 - accuracy: 0.1875\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.5949 - accuracy: 0.2500\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.5711 - accuracy: 0.2500\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.5468 - accuracy: 0.2500\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 2.5220 - accuracy: 0.2500\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.4968 - accuracy: 0.2500\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.4712 - accuracy: 0.3125\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 2.4453 - accuracy: 0.3125\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.4192 - accuracy: 0.3125\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 63us/step - loss: 2.3931 - accuracy: 0.3125\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.3670 - accuracy: 0.3125\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.3411 - accuracy: 0.3750\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.3154 - accuracy: 0.3750\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.2901 - accuracy: 0.3750\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.2653 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.2409 - accuracy: 0.6250\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 2.2172 - accuracy: 0.6250\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.1939 - accuracy: 0.6875\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.1714 - accuracy: 0.6875\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 2.1496 - accuracy: 0.6875\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.1283 - accuracy: 0.6875\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 2.1076 - accuracy: 0.6875\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.0875 - accuracy: 0.8125\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 2.0677 - accuracy: 0.8125\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.0483 - accuracy: 0.8125\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 63us/step - loss: 2.0291 - accuracy: 0.8125\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 2.0100 - accuracy: 0.8125\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.9912 - accuracy: 0.8125\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 1.9725 - accuracy: 0.8125\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.9539 - accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.9353 - accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.9168 - accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.8984 - accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.8800 - accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.8617 - accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.8435 - accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.8253 - accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 1.8070 - accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.7888 - accuracy: 0.7500\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.7706 - accuracy: 0.7500\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.7523 - accuracy: 0.7500\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 1.7340 - accuracy: 0.7500\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 250us/step - loss: 1.7156 - accuracy: 0.7500\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.6973 - accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.6789 - accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.6606 - accuracy: 0.7500\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.6423 - accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 1.6240 - accuracy: 0.7500\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.6057 - accuracy: 0.7500\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.5875 - accuracy: 0.8125\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.5693 - accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 1.5510 - accuracy: 0.8125\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.5329 - accuracy: 0.8125\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.5148 - accuracy: 0.8125\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 1.4967 - accuracy: 0.8125\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 62us/step - loss: 1.4787 - accuracy: 0.8125\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 1.4607 - accuracy: 0.8125\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.4428 - accuracy: 0.8125\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.4250 - accuracy: 0.8125\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.4073 - accuracy: 0.8125\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.3896 - accuracy: 0.8125\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.3720 - accuracy: 0.8125\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.3546 - accuracy: 0.8125\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 1.3372 - accuracy: 0.8125\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.3200 - accuracy: 0.8125\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.3030 - accuracy: 0.8125\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.2861 - accuracy: 0.8125\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.2693 - accuracy: 0.8125\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 63us/step - loss: 1.2527 - accuracy: 0.8125\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.2363 - accuracy: 0.8125\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.2201 - accuracy: 0.8125\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.2041 - accuracy: 0.8125\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 62us/step - loss: 1.1883 - accuracy: 0.8125\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 1.1726 - accuracy: 0.8750\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.1572 - accuracy: 0.8750\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.1420 - accuracy: 0.8750\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.1270 - accuracy: 0.8750\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 62us/step - loss: 1.1122 - accuracy: 0.8750\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 1.0976 - accuracy: 0.8750\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.0832 - accuracy: 0.8750\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.0691 - accuracy: 0.8750\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.0552 - accuracy: 0.8750\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.0415 - accuracy: 0.8750\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.0280 - accuracy: 0.8750\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.0147 - accuracy: 0.8750\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 1.0017 - accuracy: 0.8750\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.9889 - accuracy: 0.8750\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.9762 - accuracy: 0.8750\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.9638 - accuracy: 0.8750\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.9516 - accuracy: 0.8750\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 126us/step - loss: 0.9396 - accuracy: 0.8750\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.9278 - accuracy: 0.8750\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.9162 - accuracy: 0.8750\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 63us/step - loss: 0.9048 - accuracy: 0.8750\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 0.8935 - accuracy: 0.8750\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.8825 - accuracy: 0.8750\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 62us/step - loss: 0.8716 - accuracy: 0.8750\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.8610 - accuracy: 0.8750\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.8505 - accuracy: 0.8750\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.8401 - accuracy: 0.8750\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.8300 - accuracy: 0.8750\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.8200 - accuracy: 0.8750\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.8101 - accuracy: 0.8750\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.8004 - accuracy: 0.8750\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.7909 - accuracy: 0.8750\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 0.7816 - accuracy: 0.8750\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.7723 - accuracy: 0.8750\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 0.7632 - accuracy: 0.8750\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.7543 - accuracy: 0.8750\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.7455 - accuracy: 0.8750\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.7368 - accuracy: 0.8750\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.7283 - accuracy: 0.8750\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.7199 - accuracy: 0.8750\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.7116 - accuracy: 0.8750\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 0.7034 - accuracy: 0.8750\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6953 - accuracy: 0.8750\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6874 - accuracy: 0.9375\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.6796 - accuracy: 0.9375\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.6718 - accuracy: 0.9375\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6642 - accuracy: 0.9375\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6567 - accuracy: 0.9375\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.6493 - accuracy: 0.9375\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 126us/step - loss: 0.6420 - accuracy: 0.9375\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6347 - accuracy: 0.9375\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6276 - accuracy: 0.9375\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6206 - accuracy: 0.9375\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6136 - accuracy: 0.9375\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6068 - accuracy: 0.9375\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.6000 - accuracy: 0.9375\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5933 - accuracy: 0.9375\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5867 - accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.5801 - accuracy: 0.9375\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5736 - accuracy: 0.9375\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5673 - accuracy: 0.9375\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5609 - accuracy: 0.9375\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5547 - accuracy: 0.9375\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5485 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 63us/step - loss: 0.5424 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5364 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.5304 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5245 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.5186 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.5129 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5071 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5015 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4959 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4903 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 126us/step - loss: 0.4848 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4794 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4740 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.4687 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4634 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 187us/step - loss: 0.4582 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4531 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4480 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.4429 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4379 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4330 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4281 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4232 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4184 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 62us/step - loss: 0.4137 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.4090 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.4043 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.3997 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 124us/step - loss: 0.3951 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.3906 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.3861 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 62us/step - loss: 0.3817 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.3773 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f692554e48>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "# 모델구성\n",
    "model = Sequential()\n",
    "#                   입력차원, 출력차원, 8-1\n",
    "model.add(Embedding(vocSize, 10, input_length=maxLen-1))\n",
    "\n",
    "model.add(SimpleRNN(32))  # 각 단어의 임베딩 벡터가 10차원, 32개의 히든 상태\n",
    "\n",
    "model.add(Dense(vocSize, activation='softmax'))\n",
    "\n",
    "# 모델학습 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x, y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문일주는 던창이다\n",
      "김우진은 흡연충이다\n",
      "권순빈은 거창이다\n"
     ]
    }
   ],
   "source": [
    "def sentGen(model, tokenizer, text, n) :\n",
    "    word = text\n",
    "    sent = ''\n",
    "    \n",
    "    for _ in range(n) :\n",
    "        # 토큰화\n",
    "        encoded = tokenizer.texts_to_sequences([text])[0]  # 해당 text의 index\n",
    "        # 패딩\n",
    "        encoded = pad_sequences([encoded], maxlen=7, padding='pre')\n",
    "        # 예측\n",
    "        res = model.predict_classes(encoded)\n",
    "        \n",
    "        for w, i in tokenizer.word_index.items() :\n",
    "            if i == res :  # 예측단어와 인덱스가 동일하면\n",
    "                break\n",
    "        text = text + ' ' + w\n",
    "        sent = sent + ' ' + w\n",
    "    sent = word + sent\n",
    "    \n",
    "    return sent\n",
    "        \n",
    "print(sentGen(model, t, '문일주는', 1))  # 입력문장 뒤에 등장하는 n개의 단어 예측\n",
    "print(sentGen(model, t, '김우진은', 1))\n",
    "print(sentGen(model, t, '권순빈은', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'배를': 1,\n",
       " '과수원에': 2,\n",
       " '있는': 3,\n",
       " '배가': 4,\n",
       " '맛있다': 5,\n",
       " '그의': 6,\n",
       " '배는': 7,\n",
       " '많이': 8,\n",
       " '나왔다': 9,\n",
       " '가는': 10,\n",
       " '길에': 11,\n",
       " '탔고': 12,\n",
       " '오는': 13,\n",
       " '길에도': 14,\n",
       " '탔다': 15}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./ENG_FRA_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장: Hi.\n",
      "정답:  Salut ! \n",
      "번역기: L--’’’mnnnééUU $u0ttwkkkÊÊWWWWjjjjjjjjjjjjjjjjj‘r!y»Tgggœ,çù\n",
      "\n",
      "\n",
      "입력문장: I lied.\n",
      "정답:  J'ai menti. \n",
      "번역기: L--’’’mnnnééUU $u0ttwkkkÊÊWWWWjjjjjjjjjjjjjjjjj‘r!y»Tgggœ,çù\n",
      "\n",
      "\n",
      "입력문장: Come in.\n",
      "정답:  Entre. \n",
      "번역기: L--’’’mnnnééUU $u0ttwkkkÊÊWWWWjjjjjjjjjjjjjjjjj‘r!y»Tgggœ,çù\n",
      "\n",
      "\n",
      "입력문장: Skip it.\n",
      "정답:  Pas grave. \n",
      "번역기: L--’’’mnnnééUU $u0ttwkkkÊÊWWWWjjjjjjjjjjjjjjjjj‘r!y»Tgggœ,çù\n",
      "\n",
      "\n",
      "입력문장: I did OK.\n",
      "정답:  Je m'en suis bien sortie. \n",
      "번역기: L--’’’mnnnééUU $u0ttwkkkÊÊWWWWjjjjjjjjjjjjjjjjj‘r!y»Tgggœ,çù\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoderModel = Model(inputs=encoderInputs, outputs=encoderStates)\n",
    "\n",
    "# 디코더\n",
    "decoderStateInputHidden = Input(shape=(256,))\n",
    "decoderStateInputCell = Input(shape=(256,))\n",
    "decoderStateInputs = [decoderStateInputHidden, decoderStateInputCell]\n",
    "\n",
    "decoderOutputs, stateHidden, stateCell = decoderLSTM(decoderInputs, initial_state=decoderStateInputs)\n",
    "decoderStates = [stateHidden, stateCell]\n",
    "decoderOutputs = decoderSoftmax(decoderOutputs)\n",
    "\n",
    "decoderModel = Model(inputs=[decoderInputs]+decoderStateInputs, outputs=[decoderOutputs]+decoderStates)\n",
    "\n",
    "indexToEng = dict((i,c) for c,i in engToIndex.items())\n",
    "indexToFra = dict((i,c) for c,i in fraToIndex.items())\n",
    "\n",
    "def decodeSeq(inputSeq): # (1, 26, 80)\n",
    "    \n",
    "    statesValue = encoderModel.predict(inputSeq)\n",
    "    # print(statesValue)\n",
    "    # print(np.shape(statesValue))\n",
    "    \n",
    "    targetSeq = np.zeros((1,1,fraVocabSize)) # 1,1,106\n",
    "    targetSeq[0,0,fraToIndex['\\t']] = 1 # 원핫인코딩\n",
    "    \n",
    "    stop = False\n",
    "    decodedSent=\"\"\n",
    "    while not stop: # \"\\n\"문자를 만날때까지 반복\n",
    "        \n",
    "        output, h, c = decoderModel.predict([targetSeq]+statesValue)\n",
    "        # 예측값을 프랑스 문자로 변환\n",
    "        tokenIndex = np.argmax(output[0,-1,:]) \n",
    "        predChar = indexToFra[tokenIndex]\n",
    "        \n",
    "        # 현시점 예측문자가 예측문장에 추가\n",
    "        decodedSent+=predChar\n",
    "        \n",
    "        if (predChar==\"\\n\" or len(decodedSent)>maxFraLen):\n",
    "            stop = True\n",
    "            \n",
    "        # 현시점 예측결과가 다음 시점에 입력으로 \n",
    "        targetSeq = np.zeros((1,1,fraVocabSize))\n",
    "        targetSeq[0,0,tokenIndex] = 1\n",
    "        \n",
    "        # 현시점 상태를 다음 시점 상태로 사용\n",
    "        statesValue = [h,c]\n",
    "    \n",
    "    return decodedSent # 번역결과\n",
    "\n",
    "for seqIndex in [1,50,100,200,300]:\n",
    "    \n",
    "    inputSeq = encoderInput[seqIndex:seqIndex+1]\n",
    "    # print(np.shape(inputSeq)) # (1, 26, 80)\n",
    "    decodedSeq = decodeSeq(inputSeq)\n",
    "    \n",
    "    print(\"입력문장:\", df.eng[seqIndex])\n",
    "    print(\"정답:\", df.fra[seqIndex][1:len(df.fra[seqIndex])-1]) # \"\\t\", \"\\n\" 제거\n",
    "    print(\"번역기:\", decodedSeq[:len(decodedSeq)-1])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/korquad2.1_train_00.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "드라마 예고범의 감독은 누구일까?\n",
      "심규언은 17대 지방 선거에서 몇 표를 득표하였는가?\n",
      "장기이식으로 인해 얻을 수 있는 효과는?\n",
      "'망언' 논란을 야기한 천안함 사태에 대한 이윤성의 발언은 무엇이며 어떤 비판을 받았나요?\n",
      "칸나바로가 도핑 테스트를 해서 양성 반응을 나타낸 년도는 몇년도일까?\n",
      "비디 아이가 2010년 11월 15일에 공개한 노래의 이름은 무엇일까요?\n",
      "제20대 총선에서 인천광역시 중구동구강화군옹진군에서 각 후표자별 득표는?\n",
      "레자 샤 팔라비의 치적은 무엇이 있나요?\n",
      "호안끼엠 호수에 서식하는 대형 거북의 이름은 어디에서 유래되었는가?\n",
      "감자는 식물의 어느 부분이 변태한 거야?\n",
      "홍진이 1919년 4월 한성 임시정부에서 맡은 직위는 뭐야?\n",
      "축산물안전관리인증원지부는 설립이 되어진 연도가 과연 언제일까요?\n",
      "미르모 퐁퐁퐁의 등장인물들 중 블랙망토단의 일본명은 무엇인가?\n",
      "배우 유태웅이 강 수사관 역으로 출연한 영화의 이름은 무엇일까요?\n",
      "디지몬 어드벤처 V테이머01의 주인공은 누구인가?\n",
      "웹 브라우저를 만드는 데 기반을 제공하는 오픈 소스 응용 프로그램 프레임워크의 이름은?\n",
      "장기의 점수제 방식 대국에서 기물들은 어떤 가치를 가질까?\n",
      "20회차로 12월19일에 방송된 서브 타이틀은 무엇인가?\n",
      "정승화는 1987년이후 어떤삶을 살다가 생을 마감하였을까?\n",
      "정성룡이 2011년에 이적한 팀은 어디입니까?\n",
      "87년 태풍 셸마의 근원이 되는 열대저기압은 언제 발생하였을까?\n",
      "김용춘의 생애는 어떠했는가?\n",
      " 올림픽 스노보드 동계 청소년올림픽 메달 갯수는 무엇인가요?\n",
      "윤기견의 아버지의 이름은 무엇인가?\n",
      "주인공 플란트가 살고 있는 섬 이름은?\n",
      "흑사병 의사의 역사는 무엇이 있을까?\n",
      "이종일의 가족은 누가 있을까?\n",
      "대한항공 902편은 어떤 방법으로, 왜 격추당했어?\n",
      "야크 존의 국적은?\n",
      "네이피어 마을은 어떠한 역사를 가지고 있는가?\n",
      "가상 주소를 사용했을때 메모리 접근시간이 두배로 늘어나는\n",
      "단점을 보완하기 위해 도입된것은 무엇인가?\n",
      "빅터 빅토리아가 여장을 한 남자가 아니라 원래 여자임을 눈치채고 의심하는 사람은 누구입니까?\n",
      "윈도우 구성요소중 제어판의 도입시점은 언제인가?\n",
      "왕세자탄강진하도 병풍에 대해서 간략히 묘사해본다면?\n",
      "인제읍의 법정리 가아리는 어떤 행정리로 분리되는가?\n",
      "유로파 리그 장소가 재배포되는 경우는 어떨 때일까?\n",
      "에어포항이 정식적으로 운영하기 시작한 해는 언제일까?\n",
      "스트링이라고도 부르는 테니스 라켓 줄의 명칭은?\n",
      "매리너 9호가 화성에 착륙한 해는 언제일까?\n",
      "후쿠시마 리라가 연기한 영화는 무엇이 있을까?\n",
      "붕당의 출현 배경에는 누가 있을까?\n",
      "캘리포니아주의 샌타클래라의 평균최고기온이 가장 낮은 월은 언제인가?\n",
      "UEFA 유럽 축구 선수권 대회 본선에서 슬로바키아가 처음으로 16강에 진출한 해는 몇년도 입니까?\n",
      "푸미폰 아둔야뎃은 초기에 어떤 삶을 살았을까?\n",
      "대한민국 법정근로시간는 주몇시간인가?\n",
      "푸른거탑의 제로의 AGB 닐슨 시청률은 어떻게 되는가?\n",
      "뱅글스쿨의 방영목록 중에서, 제목에 처음으로 욜라의 이름이 등장한 회차는?\n",
      "종로가 조선시대에 처음으로 불린 이름은 뭐야?\n",
      "한강의 구간은 어떻게 구분되어 있는가?\n",
      "용감한가족 방영한 회차중 가장높은 시청률은??\n",
      "영양군의 연도별 인구변화는 어떠한가요?\n",
      "생문 군계 도식은 무엇일까?\n",
      "고기현이 처음으로 올림픽에 참가한 년도는 언제일까?\n",
      "스프리스의 자체 브랜드는 무엇이 있을까?\n",
      "1937년 ~ 1945년 사이 일본 육군사관학교의 주요 사건들은 무엇인가?\n",
      "코부쿠로의 구성원 중 코부치 켄타로의 혈액형은?\n",
      "1968년 AFC 아시안컵에서 1위를 한 팀은 어디인가요?\n",
      "현재까지 발견된 행성의 대부분은 어떤 행성인가?\n",
      "문자 코드에서 히라가나 반복부호를 상징하는 유니코드는?\n",
      "에트투리아의 도시는 어떻게 구성되어있는가?\n",
      "코난의 원래 이름은 뭐야?\n",
      "동결 중인 이슬비의 METAR은 무엇인가?\n",
      "안빈 이씨가 죽고 나서 묻힌 주는 어디인가?\n",
      "서대문역이 폐역된 이후로 그 주변이 어떻게 변했어?\n",
      "샤리아와 신학은 어떻게 대립하였는가?\n",
      "2016년 4월 국회의원 선거에서 새누리당의 당선자들이 논란이 되고 있는 이유는 무엇일까?\n",
      "남북이 함께 올림픽을 열겠다고 예정한 년도는 언제인가?\n",
      "샤이니 멤버 태민이 작사로 참여한 곡들은 뭐가있어?\n",
      "개그콘서트 최장수 코너이자 개그맨 김병만이 활약한 코너의 이름은?\n",
      "사모아어에서 강세는 보통 단어의 어디에 오는가?\n",
      "20세기 후반 혼돈이론의 역사는 어떻게 되는가?\n",
      "라살 사회민주주의의 특징은 무엇인가?\n",
      "전국의사총연합의 특징은 어떻게 되는가?\n",
      "드라마 계백에서 해수 역을 맡은 배우의 이름은 무엇인가?\n",
      "브록 레스너는 2019년 펼쳐진 머니 인 더 뱅크에서 어떤 성적을 거두었는가?\n",
      "마이클 맥클리어가 '생명이 없는 황무지'라고 표현한 베트남의 지역은 어디인가?\n",
      "스카디의 첫번째 남편은 누구일까?\n",
      "라파예트 후작의 파리 귀환부터 미국 독립 전쟁 참전까지의 삶은 어떠했어?\n",
      "2012년 MLB에서 유일하게 너클볼을 던지는 투수 누구일까?\n",
      "와이맥스의 유형 중 휴대성을 지원하지 않는 것의 명칭은?\n",
      "쓰키다역의 2006년도 1일평균 이용 인원 현황수는?\n",
      "육성재가 2015년 5월 10일 복면가왕에 출연해 부른 곡 <오래전 그날>의 원곡자는 누구인가요?\n",
      "신경민은 제19대 국회의원을 언제동안 했을까?\n",
      "유럽의 나라별 린치사건과 사례는 무엇이 있는가?\n",
      "무선전신의 발명가는 누구인가?\n",
      "신오사카역은 오사카 중심부로부터 얼마나 떨어져 있을까?\n",
      "배우 한기중은 드라마 장영실에서 어떤 배역을 맡았을까?\n",
      "김소영이 SBS플러스 채널에서 고정MC를 맡고 있는 프로그램의 이름은 무엇일까?\n",
      "제헌 국회의원 선거 충남지역에서 최소득표로 당선된 사람은?\n",
      "브라운이 사망한 해는 언제야?\n",
      "수학적 개념인 프랙탈을 이용한 미술의 한 영역의 이름은?\n",
      "영화 은행나무 침대는 어떤 부문들에서 상을 탔을까?\n",
      "가수 씰의 데뷔곡 제목은 무엇입니까?\n",
      "GOT7의 메인보컬 영재가 2015년 10월 9일 출연하여 김연우의 <이미 넌 고마운 사람>을 부른 프로그램은 무엇인가요?\n",
      "김진표 정치인이 행정고시에 합격한 연도는?\n",
      "짐바브웨 축구 국가대표팀은 FIFA월드컵 예선에서 어떠한 성적을 거두어 왔을까?\n",
      "99 프로게이머 코리아 오픈의 사용맵 중에 인원이 가장 적은 것은 무엇일까?\n",
      "생트푸아 전투과정에서 프랑스함대는 어떤상황에서 왜 항복했을까?\n",
      "대한민국의 위원회 종류는 무엇이 있는가?\n",
      "아지노모도가 처음 만들어진 날로부터 100년이 되는 날은 언제일까?\n",
      "기사십자 철십자장은 어떻게 만들어졌나요?\n",
      "LG칼택스정유 여자 배구단이 속한 구단의 최근 이름은 무엇인가?\n",
      "광주서석초등학교의 37대 교장이 취임한 날짜는 언제인가?\n",
      "10월 혁명에서 군사혁명위원회가 만들어진 과정과 그 이후의 일들은 어떻게 전개되었나요?\n",
      "샤를 드 골은 사형 선고를 언제 받았을까?\n",
      "8-9세기에 이르는 불가리아의 역사는 어떤일을 겪었을까?\n",
      "배우 손진영이 손진영 역으로 출연한 시트콤의 이름은 무엇인가?\n",
      "여성과 남성이 생물학적으로 차이가 있으며 역할이 다르기에 여성에게 남성과 같은 권리를 줄 수 없다는 주장을 한 사람은 누구인가?\n",
      "칸나이 전투에서 카르타고 군이 사용한 전법의 이름은 무엇인가?\n",
      "이명박 정부부터 문재인 정부까지 역대 방송통신위원회 위원장에는 어떤 사람이 임명되었는가?\n",
      "구리아가 조지아 연대기에서 처음으로 등장한 년대는 몇 년대인가?\n",
      "1982년 한국시리즈에서 삼성 라이온즈는  OB베어스와의 첫경기에서 어떤 결과를 내었는가?\n",
      "배우 정아미가 지수 엄마 역을 맡은 영화는?\n",
      "쿠바의 역사와 관련하여 아프리카계 쿠바인들의 반란으로 인해 3천여 명이 살해된 해는 언제인가?\n",
      "섬유모세포의 막에는 몇 퍼센트의 피막 홈이 있을까?\n",
      "국립중앙의료원의 연혁은 어떻게 되는가?\n",
      "어글리 베티 시즌 3 6화의 제목은 무엇인가?\n",
      "세월호 침몰 사고에 대해 SBS 그것이 알고 싶다와 관련된 논란은 무엇일까?\n",
      "2008년 5월 조제 보싱와는 어떤 클럽으로 이적하였을까?\n",
      "전기냉장고는 어떤 구성용품들로 작동되나요?\n",
      "아이돌마스터 신데렐라 걸즈 애니메이션 프로젝트는 어떤 캐릭터의 솔로곡을 담고 있는가?\n",
      "조시 베켓은 몇년도에 은퇴하였을까?\n",
      "중국 역사에서 첫번째로 고정된 수도라고 할 수 있는 도시는?\n",
      "드로그바에 관한 유명한 일화에는 어떤 것들이 있을까?\n",
      "오스트레일리아 퍼스 공항 제2 터미널의 운항 노선은 어떨까?\n",
      "김재로는 지춘추관사로서 무엇을 편찬하는 데 참가했을까?\n",
      "킬러의 보디가드에서 독재자인 블러드슬라프 두코비치의 재판은 어디서 열릴 예정인가?\n",
      "폴 티베츠가 대장으로 있던 원자폭탄 투하 부대의 이름이 뭐지?\n",
      "2000년에 열린 AFC 아시안컵 조별리그에서 B조의 경기결과는 어떻게 되었나요?\n",
      "서울남부와 북청주 사이를 운행하는 새서울고속의 운행노선은 어느 곳을 경유하는가?\n",
      "박원규 박사와 관련된 보도의 내용은 무엇인가?\n",
      "황산벌 전투에서 소정방이 김유신의 지각을 이유로 참수하려고 했던 사람은 누구였을까?\n",
      "계명대 역 주변 중학교의 이름은?\n",
      "2016년 하계 올림픽 개막식의 리허설은 몇 월부터 시작했어?\n",
      "영화 감독 리비아 퍼스와 결혼하고 영화 발몽에도 출연했던 영화배우는 누구야?\n",
      "1987년 한국시리즈 플레이오프 결과는 어땠어?\n",
      "2017년에 방영된 드라마 도둑놈, 도둑님의 회차별 전국, 서울 (수도권) 시청률은 어떻게 되는가?\n",
      "독립운동가 김용환의 할아버지의 이름은 뭐야?\n",
      "워런 G. 하딩이 사망했을 때 그의 나이는 몇 세였습니까?\n",
      "시장이 생성되지 않는다면 발생할 수 있는 일은 무엇일까?\n",
      "김태균이 2015년에 SBS에서 내레이션한 작품은?\n",
      "혜민은 어떻게 살아 온 사람이야?\n",
      "인천 송도에 있는 헨트 대학교 글로벌 캠퍼스의 역사는 어떻게 되는가?\n",
      "수나라가 고구려를 침략하기 위해 거병한 해는 언제인가?\n",
      "스틸러스에서 주장을 맡은 해는 몇년 인가?\n",
      "김승현이 지금까지 출연한 영화들과 맡은 배역은?\n",
      "파이널 파이트2에서 마더콤플렉스인 브라켄은 어디의 대장이였을까?\n",
      "17년 바르셀로나 테러에 조의를 표한 각국 주요인물들은 누구일까?\n",
      "정유재란이 발생한 해는 언제야\n",
      "문화도시 베르겐은 어떤 곳이고 베르겐의 유명 명소로는 어떤 것들이 있어?\n",
      "바리공주 설화가 영향을 많이 받은 종교는 무엇인가?\n",
      "더 유즈드가 밴드의 이름을 덤 럭으로 바꾸게 된 건 몇 년도야?\n",
      "한국의 30위까지의 면적 순 섬 목록은 어떨까?\n",
      "피티야 군주를 시해한 사람은?\n",
      "북아메리카 최초의 영국 식민지 제임스타운 건설 이후 독립전쟁시기에는 어떤 저술들이 많이나왔어? \n",
      "QEMU가 가상 구현하는 시스템은 무엇이 있는가?\n",
      "2010 KBS 연기대상에서 청소년 연기상을 수상한 배우는 누구인가?\n",
      "세계랠리선수권대회에서 사용해야하는 경주용자동차로 엔진에 터보차저가 달려있는 것은 어떤것일까?\n",
      "요한 수난곡의 작곡가는 누구야?\n",
      "신칸센 E5계 전동차의 최고 영업 속도는 시속 몇 km 입니까?\n",
      "한재석이 2015년 출연한 드라마의 제목은 무엇인가요?\n",
      "와이고수의 게시판은 어떻게 구성되어 있는가?\n",
      "몽골 내셔널 프리미어리그 2016 시즌 참가 팀 중 데렌을 연고지로 하는 팀은 어디인가?\n",
      "중세교회는 교회 밖을 어떠한 세계로 인식했을까?\n",
      "이정민은 롯데에서 2016년 몇번 경기를 치뤘는가?\n",
      "나이저 모건의 2007년 2루타의 개수는?\n",
      "1990년 아시안 게임에서 역도선수 김병찬이 획득한 메달은 무엇일까요?\n",
      "순항미사일이 표적까지 비행하기 위해 받아야하는 것은 무엇인가요?\n",
      "틸란드시아 이오난타가 번식하기 위한 2가지 방법은 무엇일까?\n",
      "미조구치 겐지가 여성참정권이 인정되던 시기 촬영한 영화는 무엇일까요?\n",
      "덴게키 문고에서 인기 라이트노벨 작가의 1회 타이틀은 무엇인가?\n",
      "미주리주 경제가 향상된 게 몇년대야?\n",
      "아리야스 모모카가 광고 출연한 햄버거 회사는 어디인가?\n",
      "북한과 연관이있는 연구부는 어디인가?\n",
      "2015년 10월 교육부 장관이었던 사람의 이름은?\n",
      "포항시 남구 법정동 중 대잠동은 어느 행정동인가?\n",
      "[한칸후]에 의하면 사카이 히로치카의 입장에서 마쓰다이라 야스치카는 어떤 친족관계였을까?\n",
      "제 7연대를 이끌던 인물은 누구인가?\n",
      "1966년 FIFA월드컵 예선 이탈리아와 북한의 경기에서 결승골을 넣은 선수는?\n",
      "LATAM 브라질은 현재의 사명으로 언제 변경했을까?\n",
      "'짱구는 못말려'의 등장인물인 짱구의 친구 유리가 들고 다니는 인형은 어떤 동물일까?\n",
      "김보연이 데뷔한 것은 몇 년도인가?\n",
      "야곱이 라반 밑에서 무보수로 봉사한 이유는 무엇일까?\n",
      "2018년 여우주연상을 수상한 시상식의 이름은 무엇인가?\n",
      "폐불의 의미는 무엇이고, 북조에서 폐불이 일어난 이유는 뭐야?\n",
      "맥스웰-볼츠만 붐포는 어떤 이론의 근간이 되었니?\n",
      "구한말에는 금강군은 어떤 군에 속해있었을까?\n",
      "야구선수 임정호가 NC소속으로 3년동안 어떤 기록을 세웠나?\n",
      "용인송담대학교를 졸업해서 의료관련직업에 취업하려면 어떤 단과대를 가야할까\n",
      "2018년 중국 지방선거에서 당선된 직할시장은 몇명인가?\n",
      "칼초 카타니아가 1964년 참가한 코파 델레 알피에서 거둔 성적은?\n",
      "중립국 감독위원회란 무엇이고 역사는 어떻게 되는가?\n",
      "아레사 프랭클린의 히트곡 Respect가 녹음된 년도는 언제야?\n",
      "소녀시대의 앨범 훗의 두 번째 트랙에 수록된 곡의 장르는 무엇일까?\n",
      "월지의 왕이 살해된 해는 언제야?\n",
      "간토 대지진은 몇 년도에 발생했는가?\n",
      "서울역 주변 동쪽에는 어떤 시설이 있는가?\n",
      "SBS의 나 홀로 집에 3 한글 더빙에서 성우 성완경이 맡은 배역은 무엇인가?\n",
      "작은 크기의 새우는 주로 무엇을 먹이로 먹는가?\n",
      "충청대학교에서 군사관련학과들은 어느 계열에 속해 있는가?\n",
      "클로즈드 볼트 방식을 사용하는 소총 중 이름이 K로 시작하는 소총은?\n",
      "교토상가FC의 전신은 무엇인가?\n",
      "송태조가 배주석병권을 단행한 년도는?\n",
      "크라스노다르의 1월 평균 강우 일수는 며칠일까요?\n",
      "본질이 없는 민주주의를 비판하고 유럽의 도덕성을 동물 무리로 비유한 사람은?\n",
      "피오가 2018년에 찍은 광고는 어떤 브랜드인가?\n",
      "루이스 수아레스 미라몬테스 선수는 몇년에 데뷔하였는가?\n",
      "빙허각 이씨의 아버지는 이름이 무엇일까?\n",
      "민영익이 민승호의 양자로 들어가게 된 배경은 뭐야?\n",
      "신라 김춘추의 아버지는 누구인가?\n",
      "조르조 바사리의 가장 유명한 작품이 학자들에게 좋게 평가되는 이유는?\n",
      "2013년 4월에 개봉한 대한민국 영화 중 가장 이름이 긴 영화는?\n",
      "MIAT 몽골 항공이 1998년에 도입한 항공기는 무엇일까?\n",
      "2000년에 방영된 순풍산부인과에서 정다빈은 어떤 역할을 맡았을까요?\n",
      "2014년 월드컵 결승전에서 연장전 막판 메시의 프리킥 결과는 어땠어?\n",
      "대한민국의 가수 겸 배우인 이장우는 지금까지 어떤 상을 수상했을까?\n",
      "T.I.의 Trap Muzik은 미국에 발매되고 첫 주에 몇 장이 팔렸을까?\n",
      "윤두준이 2011년 출연한 MBC시트콤의 제목은 무엇입니까?\n",
      "이 건물의 3층은 어떠한 시설이 있는가?\n",
      "바보를 뜻하는 춍이라는 단어가 한국인을 지칭하는 호칭으로 어디서 등장하기 시작했을까?\n",
      "권오중이 2005년 수상을 한 작품의 이름은 무엇인가?\n",
      "헨리 1세의 딸이자 조프루아 백작의 아내인 사람은 누구인가?\n",
      "어린 진돗개에게는 장난감으로 무엇을 주는게 좋을까?\n",
      "서울 필하모닉의 주요 활동은 어떻게 되는가?\n",
      "그랜트가 말한 마돈나의 장점은 무엇인지 서술하시오\n",
      "봄밤에 등장하는 외자의 이름을 가진 사람은 누구인가\n",
      "별명이 FLEV인 감독 이름은?\n",
      "백철이 1927년에 졸업한 학교는 어디인가?\n",
      "유재훈은 행정고시 몇회차때 합격했을까?\n",
      "허핑턴 포스트가 매드맨에서 집중했던 장면은?\n",
      "팀 호턴스라는 도넛가게가 첫 등장을 한 연도는?\n",
      "최항의 아버지 이름은?\n",
      "일연의 저서 중 제승법수는 총 몇 권으로 이루어져 있나요?\n",
      "라종일(1940)의 아들의 이름은 무엇일까?\n",
      "대한민국 제2회 산림조합 조합장 선거에서 대전세종충남지역본부 소속이었던 당선인에는 누가 있을까?\n",
      "조선민주주의인민공화국이 계속해서 핵을 만드려고 탈퇴한 조약이 뭐야?\n",
      "도가와 도교는 어느관계라고 말할 수있어?\n",
      "카자흐스탄에서 기념주화로 발행한 동전의 종류는 무엇이 있을까?\n",
      "쓰쿠요미노 미코토와 관련된 일본 신화는 어떤 내용이야?\n",
      "동성제약이 창립 60주년을 맞이한 해는 언제일까요?\n",
      "엔초 페라리 역사의 시작이 어떻게 되니?\n",
      "제3차 아베 신조 내각은 어떤 특징을 가지고 있나요?\n",
      "교황 그레고리오 10세는 어떻게 교황이 되었을까?\n",
      "횃불트리니티신학대학원의 모든 신학교육 강좌는 어떤 언어로 진행됩니까?\n",
      "인도를 배경으로 한 달마 이야기에서 여자는 어느 나라에 있다가 인도로 가게 돼?\n",
      "곽시양이 출연한 영화 작품으로 무엇이 있는가?\n",
      "코난이 다니는 학교는 어디야?\n",
      "공교회제도에서의 성직자제도는 어떻게 형성되어 있어?\n",
      "독일 노동자당의 설립 과정은?\n",
      "곡산역의 2012년 경의 중앙선 일평균 승차 승객수는?\n",
      "조지가 인버네스 백작이란 칭호를 부여받은 년도는 몇년도야?\n",
      "2015년 12월 기준으로 김해여객의 총 보유 노선수는 몇개인가?\n",
      "원기폭발 간바루거의 등장인물에는 누가 있을까?\n",
      "NHK판 하게타카의 줄거리는 무엇일까?\n",
      "르완다 내전에서 분쟁의 중심이 된 두 부족세력의 이름은 무엇인가?\n",
      "꼬마버스 타요는2기에는 어떤 에피소드가 있었을까?\n",
      "황수신은 수양이 왕위에 오른 후 어떤 행보를 보였을까?\n",
      "한 주에 1,000원 미만이며 종종 투기의 대상으로 인식되기도 하는 주식을 일컫는 말은?\n",
      "로버트 월폴의 생애 중 월폴이 총리로 장기 집권을 운영한 해는 총 몇 년인가?\n",
      "라이슬로이퍼가 용병으로 고용됐을 때의 전술 방식은 어떠한가?\n",
      "임찬규의 2013년 승률은 얼마나 될까?\n",
      "페블 테크놀로지가 2012년 런칭한 캠페인은 무엇일까요?\n",
      "2016년 조선민주주의인민공화국 축구 대표팀이 AFC U-16에서 일으킨 사건은 어떤 내용인가?\n",
      "범증은 어떻게 함곡관을 돌파했는가?\n",
      "1936년 하계 올림픽의 메달집계 현황은?\n",
      "MBC 경남 창원라디오 프로그램별 라디오 방송 정보는 어떠한가요?\n",
      "이명규는 몇 회의 사법고시에 합격했는가?\n",
      "아이팟 터치 3세대의 출시일은 언제인가요?\n",
      "남양홍씨 본관의 역사는 어떻게 되는가?\n",
      "후무스는 무슨 용도로 쓰여?\n",
      "프랑수아 미테랑이 1981년 속해있던 정당은 어디야?\n",
      "북옥저의 다른 이름은?\n",
      "WWE 나이트 오브 챔피언스의 역대 개최지는 어디가 있을까?\n",
      "벨 412 를 운용하는 나라 중 군대가 아닌 경찰 조직에서 사용하는 곳은?\n",
      "그리스인 지역 사회가 쇠퇴한 연도는 ?\n",
      "방사성폐기물을 무단 폐기한 사례로는 어떤 것이 있어?\n",
      "2002년 FIFA 월드컵 F조에서 1승 1무 1패를 기록한 팀은 어느 팀인가?\n",
      "다자이후시의 지역적 특성은 무엇일까?\n",
      "DSP미디어가 그룹 '카드'의 공식 채널을 개설한 날짜는 언제야?\n",
      "소마젤란 은하를 처음 관측한 나라는 어디야?\n",
      "볼트 접합의 종류는 무엇이 있을까요?\n",
      "대한민국 고속도로 10개년 계획이 설립된 것은 몇 년도였습니까?\n",
      "가수 '산들'이 지금까지 참여했던 음반에는 무엇이 있을까?\n",
      "가필드가 연기 수업을 받은 곳은?\n",
      "포항제철지곡초등학교에서 처음으로 졸업한 학생 수는?\n",
      "곤자쿠 이야기집에서 내용 진행을 위해 사용한 구성 방식은 무엇일까?\n",
      "오제도는 사후 어디에 묻혔어?\n",
      "여주고등학교의 초대 임창선 교장은 언제 취임했을까?\n",
      "나치 독일과 일제 사이에 맺어진 아시아 지역의 분할에 관한 조약은 추축국의 전략에 어떤 영향을 주었나요?\n",
      "기획자는 누구인가?\n",
      "KBO 리그의 투수관련 개인 통산기록에는 어떤 것들이 있나요? \n",
      "Dali, Van, Picasso는 무엇을 무단 샘플링 한 것일까?\n",
      "에비게일 브레슬린은 2007년 아이오와 영화 비평과 협회에서 어떤 상을 받았을까?\n",
      "TJ미디어에서 출시된 와우 시리즈 제품모델의 출시와 단종 시기는 언제인가?\n",
      "한국의 가수이자 배우 'Z.HERA'가 출연한 텔레비전 작품에는 뭐가 있을까?\n",
      "위안부 협상에 대한 일본의 입장은?\n",
      "페스카마 15호는 언제 만들어졌을까?\n",
      "칼초 카타니아로 이적한 이후로 모리모토 다카유키는 어떤 경력을 쌓았고 어떤 시련을 겪었습니까?\n",
      "쟈니로얄은 몇 년도에 첫 앨범을 발매했을까?\n",
      "미국의 국가 2절에서 가장 마지막 단어는 뭐야?\n",
      "삼립식품의 호빵 제품개발은 어떻게 이루어 졌어?\n",
      "해달의 천적은 무엇이 있는가?\n",
      "현 종로구청정은 누구야?\n",
      "말펜사 공항의 1B 터미널을 이용하는 항공사들의 여객기는 목적지가 어디입니까? \n",
      "부산 구서동에 위치한 브니엘예술중학교의 16대교장 성명은?\n",
      "아이리스장의 부모님은 어느나라사람일까?\n",
      "UEFA 챔피언스리그 2003-04 8강전에서 첼시와 아스날 간의 경기에서 1, 2차전 합친 최종 결과는?\n",
      "콩고 민주 공화국의 대외 관계는 무엇이 있을까?\n",
      "리그 오브 레전드 챔피언십 스프링 시즌과 서머시즌의 대회 연도별 우승팀의 MVP선수 목록은 어떠한가요?\n",
      "쿠바 독립 전쟁이 시작된 날짜는 언제야?\n",
      "르네상스 시대를 지나 18세기에 이르기까지 독일에서는 이발외과 의사들은 무엇을 운영하는 일도 있었을까?\n",
      "대한민국의 거점국립대학의 리스트는?\n",
      "야구선수 유동훈이 처음 입단한 년도는 언제야?\n",
      "제59회 NHK 홍백가합전 1부의 출장가수는 누가 있는가?\n",
      "취징시의 1월 최고기온기록은 몇도인가요?\n",
      "TEKKEN CRASH Season2의 참가팀은 누구야?\n",
      "영화 12몽키즈에서 제프리역을 연기한 배우는?\n",
      "레더 랭킹 시스템이 새로 보완되어 나오기 전에 폐지되었던 년도는 언제야?\n",
      "일리걸리즘이 등장하기 시작한 연대는?\n",
      "와일드 카드로선발되면서  우리나라 최다득점으로 우승으로 받은 혜택은\n",
      "올림픽 펜싱 남자 에페 개인전의 역대 메달리스트는 어떨까?\n",
      "1949년 왕십리와 홍제원 구간을 운행하던 서울 시내버스는 어디를 경유할까?\n",
      "난바의 범위는 어떻게 되는가?\n",
      "유희왕 듀얼몬스터즈의 주제가는 누가 한국어로 바꿨을까?\n",
      "이형근이 육군 제8사단장을 맡게된 날짜는 언제인가?\n",
      "조선 덕종은 몇살 때 요절했을까?\n",
      "루한스크의 1월 최고기온기록은 무엇일까?\n",
      "연제고등학교가 첫 졸업식을 한 때는 언제인가?\n",
      "와카에 등장한 도네의 참의미에 대한 가설은 무엇이 있을까?\n",
      "이철민의 드라마 출연작과 역할은 뭐가 있어?\n",
      "대통합민주신당의 역대 재보궐선거 결과 정보는 어때?\n",
      "스마트러닝의 개념 및 특징은 무엇이며 그것을 연구한 사람은 누구인가?\n",
      "도스에서 드라이브 포맷을 하기 위해선 어떤 키보드 입력이 필요해?\n",
      "2008년 전민수의 소속 팀은 어디일까?\n",
      "분트 연구 이후 심리학 패러다임은 어떻게 변화되었어?\n",
      "EXP EDITION 멤버 전체의 Mnet '너의 목소리가 보여' 출연일자는 언제인가?\n",
      "상속 결격자의 요건은 어떻게 되는가?\n",
      "독립문역 주변에 위치한 시장의 이름은 무엇입니까?\n",
      "중국 불탑건립의 시작은 몇 세기인가요?\n",
      "샤 루흐의 생일은 언제일까?\n",
      "캐서린 제노비스라는 여성이 살해 당한 사건이 발생한 것은 언제입니까?\n",
      "페르미는 무엇으로 물리학을 접하게 되었을까?\n",
      "FC 제니트 상트페테르부르크의 코칭 스태프는 누구누구인가?\n",
      "군중 십자군이 패배하기까지의 과정은 어떻게 되나요?\n",
      "은하철도 999에 영감을 준 작품이 뭐지?\n",
      "가수 트와이스는 골든 디스크 시상식에서 어떤 상들을 받았을까?\n",
      "프랑코 정권의 경제가 피폐해진데에는 어떠한 배경이 있는가\n",
      "호남고속도로 나들목 서대전 분기점과 접속되는 노선의 이름은 무엇입니까?\n",
      "1993년에 창단된 서울방송고등학교 여성축구부는 몇년도에 해체된거야?\n",
      "컴퓨터 드라이브의 지역 코드는 어떻게 처리될까?\n",
      "퍼블리시티권 이라는 용어가 몇 년도에 처음 사용 됐나요?\n",
      "베트남 다낭의 역사는 어떻게 돼?\n",
      "제3차 마케도니아 전쟁에서 루키우스 아이밀리우스는 무엇을 했을까?\n",
      "최남선의 <불함문화론>이 지어진 연도는?\n",
      "동래원예고등학교의 학과중 유통과 관련된 학과는?\n",
      "정호의 동생 이름은 무엇인가?\n",
      "헹 상린의 정치적 생애에 관해 설명하자면?\n",
      "청양 장곡사 철조약사여래좌상 및 석조대좌는 몇 세기 즈음에 지어진 것으로 추정되는가?\n",
      "김선교가 경기도 양평군 양서면장으로 지냈던 년도는 언제일까?\n",
      "15년도부터 연재 중인 올뉴 울버린의 작화는 누가 담당 중일까?\n",
      "2003년에 제24회 청룡영화상에서 영화 클래식으로 감독상을 탄 사람은 누구인가?\n",
      "한유의 경향을 물려받은 수제자는 누구일까?\n",
      "양파수프를 맛있게 만들려면 어떻게 해야되는가?\n",
      "경제 세계화는 어디에서 주로 볼 수 있나?\n",
      "M14 지뢰의 무게는 몇 g이니?\n",
      "적소라는 의미를 1차적으로 구체화시키는 세 가지 요소는 무엇일까?\n",
      "덕원군이 지원했던 선운사의 역사는?\n",
      "천문학자들이 S2의 공전 운동을 관찰하여 알아낸것은 무엇이지?\n",
      "세어셔 로넌은 대중매체에게 어떠한 평가를 받았는가?\n",
      "우즈베키스탄이 히로시마 아시안 게임에서 딴 메달은?\n",
      "히나타자카46의 CD 데뷔일은 언제일까?\n",
      "신용 VaRdm의 개념은 무엇인가요?\n",
      "한국 최초의 경차의 브랜드 명은?\n",
      "하원의원으로 당선되어 대표로 활동한 주의 이름은?\n",
      "예능 하하랜드의 모든 시리즈 방송정보는?\n",
      "양구군의 역대 군수는 누구인가?\n",
      "티오피미디어에 소속된 틴탑의 멤버는 누가 있을까?\n",
      "정미숙이 게임 그랜드 체이스에서 연기한 캐릭터는 누구인가?\n",
      "아프로디테가 인간의 눈을 창조할 때 사용한 4가지 물질은?\n",
      "근접무기 칼은 어떤 약점들을 가지고 있는가?\n",
      "손수현은 2016년에 무슨 CF를 찍었는가?\n",
      "연산군이 즉위한 후 훈구 대신과 사림의 위세는 어떤 변화를 겪게 되었는가?\n",
      "후포항 어항구의 정보는?\n",
      "이세돌 기사는 바둑 몇 단인가?\n",
      "수메르인들은 어떤 활동들을 하였는가?\n",
      "밤나무가 원래부터 재배 되었던 두 나라는 어디인가?\n",
      "장폴 사르트르는 파리의 계급 중 어떤 계급에 속하였는가?\n",
      "2005년 세계2번째 견섬유 생산국은?\n",
      "김인태 선수의 역대 최고 타율은 얼마였을까?\n",
      "환곡이 문란하게 된 이유는 뭐야?\n",
      "남흥여객은 몇 개의 시외버스 노선을 보유할까?\n",
      "푸르니에가 교황으로 뽑혔던 연도는 언제인가?\n",
      "에코빌리지 즐거운  !의 회차별 방송정보는 어떻게 되나요?\n",
      "BEJ48의 멤버 쑹쓰센의 생년월일은?\n",
      "뉴욕 지하철에서 메트로카드를 처음 사용한 때는 언제일까?\n",
      "달 리아타는 누구때문에 멸망해?\n",
      "리포저 훈련의 개념과 목적은 무엇인가?\n",
      "도요토미 히데요시는 일본의 군사력을 키우기 위해 어떠한 노력을 기울였는가?\n",
      "은석초등학교의 초대 교장 선생님은 누구일까요?\n",
      "충청남도의 독립기념관 주소는 무엇인가?\n",
      "이삼평은 일본으로 끌려간 후 무슨 이름으로 불렸어?\n",
      "헌터리아의 디지털 싱글 앨범 중 1집 헌터리아의 발매 연월일은 언제인가?\n",
      "XHTML은 점차 어떤식으로 발전했어?\n",
      "라플라스가 내무부의 장관으로 일하게 된 것은 몇년도부터인가?\n",
      "독일 고속버스의 화장실은 어떤 문제점이 있을까?\n",
      "달항아리 아가리는 몇도정도나 기울어져 있는줄 알아? \n",
      "1999년에 데뷔한 롤러코스터는 몇 년도에 해체했어?\n",
      "붉은 수수밭 한국판에서 구아(궁리)역을 맡은 성우의 이름은?\n",
      "금강초롱꽃은 몇 cm일까?\n",
      "배우 강혜정이 2007년에 출연한 영화의 이름은?\n",
      "심기섭 씨가 민주자유당의 주요 정책에 자문을 맡게 된 해는 언제일까?\n",
      "광한루의 명칭은 누가 지었을까요?\n",
      "동물 농장에 나왔던 모세는 어떤 동물인가?\n",
      "등애의 지휘로 손준군을 몰아낼 때의 지위는 무엇일까?\n",
      "큰곰자리 알파를 힌두교인들은 무엇이라고 부르는가?\n",
      "장시성에서는 무슨 재료를 음식에 많이 사용할까?\n",
      "강하엽병에 가장 유명한 작전은 무슨전투인가요?\n",
      "금치훈장에서 직함을 표기할 때 가장 마지막에 적는 요소는 뭐야?\n",
      "'아스테릭스'에서 고트족 마을의 대장역을 맡은 등장인물의 이름은?\n",
      "한큐전철에서 전석 우선 좌석을 도입하기 시작한 해는 언제일까?\n",
      "2016년 방영된 TV 애니메이션 아빠 어릴 적엔의 회차별 방송일 및 부제는 무엇일까?\n",
      "김성훈은 몇 년도에 삼성 라이온즈를 입단했을까?\n",
      "노모 히데오가 LA 다저스 팀에 입단한 것은 몇 년도입니까?\n",
      "1801년 전에 유니언 잭은 미국 국기 어느쪽에 있었는가?\n",
      "위덕대학교에서 가장 많은 학과가 속해 있는 학부는 무엇인가?\n",
      "일제강점기부터 한국전쟁 이전까지의 광화문의 운명은?\n",
      "1951년 아시안 게임의 경기 종목 중에서 자전거를 타는 경기를 무엇이라 하는가?\n",
      "드라마 맨발의 청춘에서 장영필의 배역을 맡은 배우는 누구일까?\n",
      "배우 박보영이 제일 처음 출연한 공익 광고의 기업명은 무엇일까요?\n",
      "야마구치 데쓰야가 2007년부터 속해있던 팀 이름은 무엇인가?\n",
      "과천시의 넓이는 얼마야?\n",
      "배드 로봇 프로덕션스의 TV시리즈는 무엇이 있을까?\n",
      "서태지와 아이들의 노래인 시대유감은 몇 집 앨범의 수록곡인가?\n",
      "퍼머넌트 웨이브란 무슨 의미일까?\n",
      "배우 윤진서의 데뷔작은 뭐야,\n",
      "용골자리 에타는 태양질량의 몇배로 관측되나요?\n",
      "제1차 세계 대전이 끝난 날은 어느 해의 11월 11일인가?\n",
      "빅데이터로 보는 세상에서 KBS광주가 송출하는 방송의 타이틀명은 어떻게 될까?\n",
      "호찌민 지하철의 1호선의 역은 총 몇개인가요?\n",
      "마리오 바르가스 요사가 집필한 소설에는 어떤 것들이 있는가?\n",
      "1582년에 노부나가를 죽인 사람은 누구야?\n",
      "80년 전쟁은 몇 년도에 일어났니?\n",
      "남상국은 대학교 졸업후 어떤기업에 입사하나요?\n",
      "2016년 KBO 포스트시즌에서 와일드카드 결정전의 경기상황과 결과는 어땠을까?\n",
      "유엔 안전 보장 이사회 이사국 중 2019년 기준 현재 비상임이사국인 국가들의 정보는 무엇인가?\n",
      "한국창조과학회의 결성 목적과 가치관, 주요 이력은 무엇이며 이들을 바라보는 외부의 평가는 어떻습니까?\n",
      "항암효과를 가지고 있는 버섯의 물질은 뭐야?\n",
      "란제리 소녀시대의 1회 대한민국 시청률은 몇 퍼센트인가요?\n",
      "카스시에 위치한 아팍호자의 묘의 다른 명칭은 무엇인가?\n",
      "클레어 패터슨의 생애는 어땠을까?\n",
      "버마의 쌀 감소의 원인과 그 결과, 앞으로의 예측 상황은 어떠한가?\n",
      "US 여자 오픈이 창설된 연도는 언제인가?\n",
      "견양검의 아버지 이름은 무엇인가?\n",
      "박희양은 몇 년도에 한국병합기념장을 받았니?\n",
      "카타히라 리나의 정규앨범 발매일별 앨범 정보는 어떠한가요?\n",
      "왓슨이 레드 라이더를 게시판에 배포하며 책정한 가격은?\n",
      "2004년 7월 축구선수 조니 에번스를 스카웃한 프로 팀은 어디인가?\n",
      "단어 myrmecology를 만든사람은 누구인가?\n",
      "문부식의 배우자는?\n",
      "오현경이 2016년 진행한 TV조선의 프로그램은 무엇인가?\n",
      "제2차 고구려와 당나라의 전쟁은 어떤역사를 가지고 있을까?\n",
      "북한에서 조선어철자법이 제정된 해가 언제야?\n",
      "2010년 FIFA 월드컵 남미 지역 예선에서 코스타리카와 우르과이의 대륙간 플레이오프 경기의 결과는 어땠을까?\n",
      "이스포츠 감독 이지훈이 리그 오브 레전드 팀을 창단한 연도는 언제인가?\n",
      "낙원상가가 완공된 날짜는 언제인가요?\n",
      "동광양시의 이름이 바뀐 날짜는 언제인가?\n",
      "여성성경학교를 세운 날짜는 언제인가?\n",
      "가수 대성이 넷플릭스에서 출연한 방송의 이름은?\n",
      "양곤 관구의 역사 중 흐모비와 한타웨이가 바고 관구에서 양곤 관구로 편입된 해는 언제인가?\n",
      "하버드 대학교 메인 캠퍼스와 하버드 야드, 그리고 그 인근 지역에는 어떤 시설들이 위치해 있습니까?\n",
      "한국프로농구 포스트시즌 2011의 팀별 경기 결과와 최종순위는 어떠한가요?\n",
      "일본은 2차 세계대전에서 진 후, 어디 땅을 소련에게 돌려줬어?\n",
      "수도경작은 어떤 지역에서만 사용되었을까?\n",
      "순조의 후궁인 숙의 박씨의 생애는 어땠습니까?\n",
      "중화인민공화국의 진찌 고속공로의 요금은 1km당 얼마야?\n",
      "음주운전 혐의가 있는 사람을 귀가조치함으로 직무유기죄로 징역3월에 집행유예1년을 선고받은 송모경위가 항소하자 벌금 500만원으로 형량을 낮춘 부장판사의 이름은 무엇인가?\n",
      "한국의 DJ렉스는 어떤 분야의 뮤지션인가?\n",
      "대전 시티즌의 2018년 당시 코칭스태프는 누구일까?\n",
      "막스 슈티르너는 철학에 대해 어떤 견해를 가지고 있었을까?\n",
      "고효율 비디오 코딩에서 고화질 영상을 암호화가 가능하기 위해 좀 더 충분한 사양을 정하고 있는 티어는 무엇일까?\n",
      "사랑앵무를 강제로 목욕 시키면 어느 현상이 발생하는가?\n",
      "이케부쿠로 역의 운행노선 중 사이쿄 선을 운영하는 철도회사의 이름은 무엇인가?\n",
      "한국에서의 닛산 바네트 라인업은 무엇이 있는가?\n",
      "'모두! 초능력자야!'의 제1화 방송일은 언제인가?\n",
      "게임큐브를 판매할 때 내세웠던 판매전략은 무엇일까?\n",
      "Ms.의 사용법은 어떻게 되는가?\n",
      "지금 뱅 앤 올룹슨의 수석 디자이너는 누구야?\n",
      "레바논의 종교는 어떻게 되는가?\n",
      "1898년 미국과 스페인 전쟁 때 디모인에는 어떤 기지가 있었어?\n",
      "국민대표회의가 일어날때 임시정부 내무총장은 누구였어?\n",
      "한국의 불교는 어떤 역사를 가지고 있을까?\n",
      "김중권은 김대중 정부 때에 어떤 직위에 박탈되었을까?\n",
      "미공군의 관측기 이름은 어떤 조약에서 따와서 만들었어?\n",
      "1966년 미국 공연에서 귀국한 이후 비틀즈 멤버들은 각자 어떤 일을 하며 시간을 보냈는가?\n",
      "2015년 인구조사를 기준으로 화 씨 성을 가진 사람은 총 몇 명인가?\n",
      "2004년 스페인 마드리드 공격에 따른 정부의 발표와 실제 여론의 생각은 어때?\n",
      "노동자 독재 운영 시스템이 조금씩 잦아지는 해는 언제부터 언제까지일까?\n",
      "소닉 어드벤처 2에서 ARK가 발사되어 파괴 될뻔한 행성은?\n",
      "월요기획 1기는 언제 방송을 시작했을까?\n",
      "2014년 아시안 게임 축구 여자 조별 리그에서 A조의 경기결과는 어떠한가? \n",
      "성수대교 붕괴로 입은 피해는 어느정도였어?\n",
      "관룡사 중 임진왜란 때 불타지 않은 건물의 이름은 뭐야?\n",
      "알자지라 클럽이 세 번 이상 우승한 대회의 이름은?\n",
      "2012년 유럽 그랑프리 결승 결과는?\n",
      "정소공주의 가족 관계는 어떻게 이루어져 있어?\n",
      "고베시에서 열리는 고베 루미나리에 축제는 언제 개최되는가?\n",
      "올림피아코스 FC의 문양과 유니폼은 어떻게 변화했을까?\n",
      "베토벤이 자신의 교향곡 7번을 만들때 머물던 도시의 이름은 무엇일까?\n",
      "루르드 샘물의 성분 분석은 언제 이루어졌을까?\n",
      "람보르기니가 에어로디나미코를 제작한 것은 언제일까?\n",
      "전도봉은 어느 고등학교를 졸업했을까?\n",
      "박한별은 2006년 드라마 환상의 커플에 출연했을때 배역의 이름은 무엇인가요?\n",
      "송지영은 언제 제11대 국회 의원을 했을까?\n",
      "현영민이 데뷔한 연도는 언제인가?\n",
      "달랏은 행정구역이 몇 방까지 있는가?\n",
      "혈액이 하는 일들은 뭐가 있지?\n",
      "도산서원의 역사는?\n",
      "네 무덤에 침을 뱉어라 2의 세트 책임자는 누구일까?\n",
      "반응 속도 법칙에서 전이상태 후에 반응하는 물질이 무엇인가요?\n",
      "1880년 출생의 한국 독립운동가이면서 1919년 대한민국 임시정부의 국무총리 겸 외무총장을 역임한 이 사람은 누구인가?\n",
      "제2차 세계 대전 후에 세르비아의 상황은 어땠어?\n",
      "김해시내버스의 운행정보는?\n",
      "에스토니아의 국제 대회 예선 성적 중에 최고 기록은 승패가 어떻게 돼?\n",
      "자의왕후의 부친의 이름은 뭐야?\n",
      "드라마 해를 품은 달에서 혜각도사 역을 맡은 배우는 누구인가?\n",
      "스픽스의 특징은 무엇일까?\n",
      "카플란 인터내셔널 컬리지의 제휴 대학교는 어떤 곳이 있나요?\n",
      "헌법은 어떻게 결정하는 것일까?\n",
      "장형은 어떻게 독립투쟁을 했을까?\n",
      "F-35가 승인되고 오늘날까지 사용된 과정은 무엇인가?\n",
      "네덜란드가 1621년에 무역을 하기 위해 세운 것은 뭐야?\n",
      "우분투 스튜디오의 릴리스 10.10버전은 언제 배포 시작했을까?\n",
      "존 히컨루퍼가 태어난 연도는 언제인가?\n",
      "규슈 자동차도가 장대터널로 통과하는 지역은 어디야?\n",
      "케미컬 플랜트존은 어떤 게임방식을 가지고 있을까?\n",
      "서인천 고등학교의 1985년 3월 신입생은 몇명이었는가?\n",
      "1808년 미국 대통령 선거 중 후보선출에서 가장 많은 득표수를 얻어 대통령 후보가 된 사람은 누구인가?\n",
      "현대제철의 현재 우리나라에 존재하는 사업장들의 구성상황은?\n",
      "상업은행 구의동 지점에 제작된 내외벽 벽화는 몇년도에 제작되었는가?\n",
      "궐련은 어떤 잎을 원통처럼 만 거야?\n",
      "백승환이 2018년 출연한 OCN 드라마의 제목은 무엇인가?\n",
      "법조인 김상기의 생애는 어떠한가?\n",
      "초과이익공유제 논란 당시의 지식경제부 장관은 누구야?\n",
      "사진술에서 필터의 용도에 따른 분류는 어떻게 되는가?\n",
      "임진왜란의 영천성 전투 당시 박진은 어떤 활약을 했을까?\n",
      "통영에 위치한 미륵산의 높이는 몇 미터인가?\n",
      "삼성전기 배드민턴단은 언제 만들어진거야?\n",
      "엄지원은 어떤 영화들에 출연했을까?\n",
      "삼국 시대에 문학은 어떻게 전래되었을까?\n",
      "로마 가톨릭교회에서는 파문을 몇 가지로 분류했을까?\n",
      "1966년에 열린 FIFA 월드컵은 어떤 곳에서 개최했을까요?\n",
      "양반이지만 벼슬 자리에 오르지 못하고 놀고 있는 사람을 일컬어 무엇이라고 합니까?\n",
      "다모 산성에 있는 천수 또는 망루는 몇층이야?\n",
      "나선 은하에서 산개성단이 자주 발견되는 곳은 어디일까?\n",
      "엑소시스트는 사람이 무엇에 씌였을 때 하는 의식이야?\n",
      "오자와 이치로씨는 몇년 몇월 며칠에 서울 국민대학교를 방문하였는가?\n",
      "은영선은 어떤 기업의 사내방송 영화음악실을 진행하고 있을까?\n",
      "AC 재팬에서 주제를 정하는 기준은 무엇일까?\n",
      "2016년 새누리당 경선에서 여론조사 결과 2위였는데 1위라는 발언을 했던 정치인은 누구야?\n",
      "시안 셴양 국제공항의 연혁은 어떻게 되는가?\n",
      "2015년 2월 9일에 방송된 호구의 사랑 1화는 시청률 조사에서 종합 몇 위를 하였는가?\n",
      "재일한국인 성선임이 2006년 출연한 영화로 개봉 첫주 일본 박스 오피스 7위를 차지한 작품의 제목은 무엇일까?\n",
      "쿠푸의 피라미드 이전에는 주로 어디에 피라미드를 세웠는가?\n",
      "히또쯔바시 대장을 앞세워 쿠데타를 일으킨 아라끼 마사야스 중장의 보직은 무엇이었을까?\n",
      "송백헌이 한국문인총연합회 초대 회장으로서 활동하며 창간한 회지는 무엇인가요?\n",
      "춘천의 고속버스터미널이 이전된 것은 몇 년도일까?\n",
      "앰버 허드가 2005년에 출연했으며 판매원 역할을 맡았던 드라마 시리즈의 제목은?\n",
      "2009년 찬란한 유산 1회의 방송일은 언제일까?\n",
      "2009년 1월 20일 용산 참사에서 발생한 사망자는 몇명인가?\n",
      "후한 때 원소가 죽은 년도는?\n",
      "일리네어 레코즈가 첫 레이블 앨범을 발표한 날짜는 언제인가?\n",
      "이원근이 출연한 영화는 뭐가 있을까?\n",
      "1992년도 빙그레 이글스의 투수는 누구인가?\n",
      "응우옌후에의 어린시절은 어땠는가?\n",
      "2001년 5월 9일부터 2002년 7월 18일까지 한국방송공사에서 방영한 특별기획 드라마이며, 김기복이 유춘만 역을 맡은 드라마의 제목은 무엇인가?\n",
      "베르누이는 로그나선을 뭐라고 불렀어?\n",
      "카시니 간극은 누구에 의해 발견되었을까?\n",
      "2015년 아프리카 네이션스컵 시드 1,2번 배정 결과는 어떻게 될까\n",
      "홍커우 의거 직후의 체포 장면을 담은 사진 속의 인물이 윤봉길이 아님을 주장한 교수의 이름은 무엇인가?\n",
      "김구 선생의 회고 내용은 무엇일까?\n",
      "공병우는 무슨 이유로 스스로 사망했다고 선언했어?\n",
      "김은성 아나운서가 2018년부터 지금까지 진행하는 뉴스 프로그램은?\n",
      "사첼 페이지의 본래 이름은 무엇입니까?\n",
      "빨간맛 이라는 곡은 어떤내용과 음악적기술이 담겨져있을까?\n",
      "김훈이 1986년 재직하고 있던 신문사는 어디인가?\n",
      "2018년 화롄 지진이 일어났을 때 최대 진도가 4급이었던 지역은 어디인가?\n",
      "조선시대 전기의 왕자, 서예가, 정치가로 조선3대 국왕 태종의 둘째 아들이었으며 조선의 억불 정책으로부터 불교를 옹호, 보호하는 역할을 했던 이 사람은?\n",
      "5.17 쿠데타 때 가장 적은 구성을 이룬 정당의 이름은?\n",
      "«비디오 블로그»는 무엇일까?\n",
      "된장 군과 낫토 짱의 결혼 전쟁 1회는 언제 방송했을까?\n",
      "오송생명과학단지의 예정된 완공 연도는?\n",
      "중국 훈련기에는 어떤 것들이 있어?\n",
      "태산군주는 극성팬들의 문제에 대해서 어떤 입장을 보였을까?\n",
      "2010년 동계 올림픽의 성화가 채화된 것은 언제인가?\n",
      "만화 스쿨럼블의 주요 줄거리는?\n",
      "트리니티 블러드 속의 교황청(바티칸)은 어떤 단체인가요? \n",
      "드라마 온에어에서 모델이자 승아의 영어선생님으로 등장하는 에이든 리역을 맡은 배우는 누구인가요?\n",
      "이재곤이 1군으로 활동을 시작한 해는 언제야?\n",
      "프로게이머 임재덕의 군 제대 후 성적은 어땠을까?\n",
      "2012년 올림픽 여자 유도 체급별 경기 결과는 어떻게 나왔어?\n",
      "이하늘이 sbs 라디오에 출연한 날이 언제야?\n",
      "영화 '박물관이 살아있다!'에서 주인공 '래리 델리'역을 맡은 배우의 이름은 무엇인가?\n",
      "음모를 꾸몄던 윌리엄의 계획은 어떻게 진행되었을까?\n",
      "대한민국 제헌 국회의원 선거에서 제주도 북제주군 을선거구의 개표결과는 어땠는가?\n",
      "영진전문대학교의 인문사회계열 전공을 나열하면?\n",
      "ZIP 파일형식은 어떻게 만들어졌는가?\n",
      "청우당은 몇 년도에 최초로 창당됐는가?\n",
      "1989년에 범용 문자 집합을 만들기 시작했던 기구의 이름은 무엇일까?\n",
      "메이시스가 경영자 매수를 하기까지의 역사는 어떻게 되는가?\n",
      "\n",
      "1899년부터 1935년까지 기치조지 역에서 승하차한 연도별 일평균 인원은 얼마일까요?\n",
      "이스라엘 방위군의 역사는 어떻게 되는가?\n",
      "홍대입구역으로 역명이 정해진 날짜는 언제인가요?\n",
      "원숭이는 가족무리, 여러수컷무리, 한수컷무리식으로 이루어져 있는데요,이들 각 무리의 구성은 어떻게되며, 원숭이의 천적은 누구입니까?\n",
      "미국 육군이 930에서 1390Km까지 날아가는 탄도 미사일을 연구하기 시작한 년도는?\n",
      "17-18시즌 때 FC SKA 하바롭스크의 감독은 누구였는가?\n",
      "김도우의 본래 주종목은 무엇이었는가?\n",
      "민방위대 '하얀 헬멧'에서 책임자를 맡고 있는 사람의 이름은 뭐야?\n",
      "법정리별 증평읍의 행정구역의 현황은 어떠한가요?\n",
      "고려시대에 문무관료를 제외한 광범위한 층을 전체적으로 관리하기 위해 만든 계층은 무엇일까?\n",
      "시나브리아가 바르셀로나 유소년팀에 들어갈 때의 나이는?\n",
      "확률 과정 이론의 발달이 중단된 이유는 어떤 사건 때문인가?\n",
      "1976년 오조네 역에 나고야 최초로 도입된 것은 무엇일까?\n",
      "김어준의 팟케스트 방송 제목은 무엇일까?\n",
      "솔라나스의 암살미수 사건 이후 워홀과는 어떤 관계가 있었을까?\n",
      "가스 피스톤 방식 중 총대 중앙에서 총알이 고압의 가스를 받아 발사되는 방식을 뭐라고 불러?\n",
      "Kar98k는 언제까지 생산되었을까?\n",
      "화가 김기창이 태어난 고향은 어디인가?\n",
      "전기화학의 시작이라고 할 수 있는 사람은 누구야?\n",
      "클램윈의 데이터베이스는 약 몇개인가?\n",
      "2021년을 맞이했다고 가정하면 경로의 날은 몇 월 며칠일까?\n",
      "1950년 ~ 1951년 퍼시픽 리그의 경기방식 횟수•시간 제한의 대한 내용은 무엇일까?\n",
      "마이클 패러대이가 왕립 협회의 조수로 고용되면서 그의 삶에는 어떤 일들이 있었을까?\n",
      "우키타 히데이에는 패전 이후 어떤 삶을 살았어?\n",
      "이브의 사랑에서 극 중 진정한으로 특별 출연한 배우는 누구인가?\n",
      "대한민국 제 10대 국회의원 선거 경남지역에 출마한 구태회 후보의 소속정당은 어디인가?\n",
      "1936년 동계올림픽에서 리히텐슈타인의 남자 알파인 스키 경기 결과는 어땠을까?\n",
      "파이프 오르간의 송풍부에서 현재 풀무를 작동 시키는 방법은 무엇일까?\n",
      "슈퍼로봇대전 시리즈의 슈퍼로봇대전 A 포터블은 언제 출시되었을까?\n",
      "천호역 주변 시설은 무엇이 있는가?\n",
      "철도 차량의 구조에 해당하는 요소는 무엇입니까? \n",
      "란싼 왕국의 역사는 어떻게 되는가?\n",
      "기상청에서는 이안류 예측 정보를 am 9시부터 다음날 pm 6시 사이에 총 몇 단계에 걸쳐 제공하는가?\n",
      "플로지스톤설이 폐기될 때까지의 과정은?\n",
      "계룡역에서부터 신탄진역으로 이어지는 노선을 위한 총 공사비용은 얼마인가?\n",
      "방응모의 출가와 복귀는 어떻게 이루어졌는가?\n",
      "빅 히어로가 영감을 받은 원작만화의 이름은?\n",
      "어린이들에게 인기를 얻었던 다오배찌 붐힐대소동의 HD제작을 맡았던건 누구일까?\n",
      "웸블리 아레나는 누구의 기획에 따라 지어졌어?\n",
      "블레이드 러너의 감독판은 몇 년도에 나왔을까?\n",
      "2010년 동계 올림픽 스피드스케이팅 종목별 남자 획득 메달 현황은 어떠한가요?\n",
      "골프선수 박성현 선수가 KLPGA 투어에서 우승한 대회는?\n",
      "오즈 야스지로가 쇼치쿠 촬영소에서 일을 시작한 것은 몇 살때였는가?\n",
      "6세기에 속말말갈을 지배한 나라는?\n",
      "인렬왕후의 탄생일은?\n",
      "삼국전쟁때문에 파라과이 인구 비율이 얼마나 희생됐어?\n",
      "2006년 기아 CDO의 이름은?\n",
      "펜싱 종목 중 하계 올림픽에서 1996-2016년까지 총 6번의 경기가 치뤄진 종목은 무엇인가?\n",
      "모리 코고로가 코난 엄마에게 받은 양육비는 얼마일까?\n",
      "1975년에 도둑들이 쾰른 대성당에서 뭘 가져갔어?\n",
      "만화 클라나드가 처음 연재된 해는 언제야?\n",
      "리암은 Wonderwall에 대해 뭐라고 표현하였는가\n",
      "강민호가 롯데에서 옮긴 팀은 어디일까?\n",
      "1416년경 코펜하겐은 어떤 국가의 수도로 지정되었는가?\n",
      "코리아 외국인 학교의 방과 후 활동은 무엇이 있는가?\n",
      "데드맨 원더랜드에 나오는 등장인물 중 레치드 에그의 성우를 맡은 사람은 누구인가?\n",
      "1979년 조세현의 나남 사진전이 개최된 장소는 어디인가?\n",
      "MBC충북 청주방송국은 시사교양, 연예오락 프로그램이 어떻게 편성되어 있을까?\n",
      "알파드의 질량은 우리 태양의 질량의 몇 배정도 되니?\n",
      "2014년 K리그 챌린지에는 어떤 팀들이 참가하였나요? \n",
      "고구려 시대의 주요 교육기관으로, 지방에서 청소년들을 주로 교육했던 이 기관의 이름은? \n",
      "캔자스주에서 주로 만드는 제품은 뭘까?\n",
      "2012년 하계 올림픽 괌 수영 선수단의 경기 결과는 어땠어?\n",
      "케리 그랜트가 1935년에 출연한 영화 제목이 뭐야?\n",
      "드라마 홈랜드 시즌2에 나오는 CIA국장의 이름은 뭐야?\n",
      "Bravo라는 이름을 가진 종업원의 기술은?\n",
      "매기 질런홀의 경력은 어떻게 되는가?\n",
      "중국역사박물관의 전신은 언제 설립되었는가?\n",
      "그레그 매덕스는 현재 어떤 국가의 코치일까?\n",
      "공로명씨가 주소련 대사를 맡은 연도는?\n",
      "그룹 노을의 리더는 누구인가?\n",
      "2014년은 하루에 평균적으로 몇 명이 빈고혼조 역을 이용했을까?\n",
      "프로야구 선수 주효상이 리그 데뷔 이후 처음으로 선발 출전한 날은 언제일까요?\n",
      "호흡식가, 벽곡 등의 다양한 종류가 있으며 음식물을 섭취하지 않고 생명을 유지하는 행위를 무엇이라고 하는가?\n",
      "지엠피는 어떤 기업이고 평가는 어떨까?\n",
      "응소행위가 시효중단 사유가 되기 위한 요건은 무엇인가?\n",
      "사람들은 김상기에대해서 어떻게 평가해왔을까?\n",
      "별내동의 이름을 딴 고등학교는 무엇인가요?\n",
      "일본이 AFC 아시안컵 우승을 한 년도는 언제인가?\n",
      "아시아흑곰의 분포지역에 따른 아종은?\n",
      "1984년 1월 7일 방송된 토요명화의 제목은?\n",
      "보평고등학교가 개교했을 당시의 교장은 누구였을까?\n",
      "김동준의 통산 기록 중 가장 많은 실점을 기록한 해는 언제인가?\n",
      "무한대를 본 남자에서 맡은 배역은?\n",
      "소행성 3127이 바그라티온으로 망명된 해는 언제야?\n",
      "AFC 챔피언스리그 2015의 8강전에서 알힐랄은 어떤 결과를 얻었을까?\n",
      "MBC 스포츠 플러스 소속 아나운서는 누가 있는가?\n",
      "구글크롬의 주소명령체계 목록은 무엇이 있는가?\n",
      "이승원이 온게임넷에서 맡은 첫 프로그램은 무엇인가?\n",
      "다카라즈카 가극단원이 2년간 교육을 받도록 된 학교이름이 뭐지?\n",
      "바이스만이 주장한 생식질 연속설은 어떠한 진화 이론이었나?\n",
      "제6사단은 온정리 전투시 온정리에 도착하기전 마지막으로 어디에 들렸을까?\n",
      "DGIF는 어떤 학술대회일까?\n",
      "조지 스타인브레너가 구단주를 아들에게 넘긴게 언제인가요?\n",
      "범고래가 사육되는 과정에서 사람을 공격한 사례는?\n",
      "소녀혁명 우테나에서 카오루 미키 역을 맡은 성우는 누구인가?\n",
      "기스키역의 1999년도 1일 평균 이용객은 몇명일까?\n",
      "현리 전투에서 3군단이 포위당했을 때의 군단장은 누구였을까?\n",
      "형사소송법의 법원에 해당하는 대법원 규칙 중 제일 첫번째 항목은 무엇인가요?\n",
      "운송물의 처분의무의 내용은 무엇입니까?\n",
      "양창섭은 2018 시즌에 야구 선수로써 어떤 경력을 쌓았고 어떤 문제들이 있었습니까?\n",
      "석남사 석탑이 조성된 것으로 추측되는 시대는 언제야?\n",
      "양정례의 출신 대학과 학과는 무엇인가?\n",
      "이성이 행정고시에 합격한 해는 언제인가?\n",
      "BNK48의 Beginner는 언제 발매했을까요?\n",
      "KTF EVER컵 온게임넷 프로리그의 정규 리그 순위는 어떨까?\n",
      "설리 알리 문타리가 처음 선수생활을 시작한 가나의 축구 구단팀 이름은 무엇일까?\n",
      "고동진선수가 한화 입단후 2013년 까지 기록한 통산홈런수는?\n",
      "터키 항공이 설립된 도시는 어디야?\n",
      "창의군을 만들고 한성탈환작전을 기획한 이은찬 대장은 어디에서 순국하셨어?\n",
      "'다만 널 사랑하고 있어'에서 여자 주인공을 맡았던 배우의 이름은?\n",
      "두 개의 전하에 이름을 붙인 과학자의 이름은?\n",
      "LL 쿨 J의 데뷔앨범이 발매된 년도는 언제야?\n",
      "프리큐어 시리즈는 아사히 방송에 몇년도부터 방송되었는가?\n",
      "삼성그룹의 의료산업 네트워크에 속한 기업은 어느 곳인가?\n",
      "이 멋진 세계에 축복을! 이라는 작품 속 주인공의 이름은 무엇일까?\n",
      "KSTAR의 연혁은 어떻게 되는가?\n",
      "토마토를 재료로 하는 잠발라야의 이름 중, 그 색에서 유래한 이름은 무엇인가?\n",
      "탁지부는 어떤 기관에 관한 사항일까?\n",
      "맹자가 주장하는 \"의(義)\"의 기초는 무슨설인가요?\n",
      "랠프 번치의 학창 시절은 어땠을까?\n",
      "조폐국에서 수집용으로 판매하는 주화는 어떤거지?\n",
      "요동은 발해멸망 이후 어느 나라의 영토가 되었을까?\n",
      "생물들은 각각 암모니아를 어떤 형태로 배출해?\n",
      "공격자가 쓴 내용을 사용자가 읽게 되면 어떻게 될까?\n",
      "21세기에 새롭게 나타난 생명과학의 분야들에는 어떤 것들이 있는가?\n",
      "수원에 있는 우체국으로는 어떤 곳들이 있을까?\n",
      "정관용은 어느 지역에서 태어났는가?\n",
      "나가토에서 코난은 누가 죽은 뒤에 아카츠키를 탈퇴했어?\n",
      "강원도 고성군 오대면이 거진면으로 이름이 바뀐 것은 몇 년도인가?\n",
      "국적은 무엇과 함께 존재하는 것일까?\n",
      "호시노 겐이 출현한 드라마는 뭐가 있을까?\n",
      "2000년 이전에 사용하던 소프트웨어 체제는?\n",
      "대한민국 국회의 구성원은 누구일까?\n",
      "고려 공민왕때 있던 사헌부를 조선의 어떤 왕이 계승해서 설치했어?\n",
      "조로리는 어떤 동물인가?\n",
      "마오쩌둥이 태어난 곳은 어디인가?\n",
      "2013년부터 2018년까지의 K리그 수상자는 누구일까?\n",
      "안정훈이 배우로 데뷔한 연도는 언제인가?\n",
      "마룬 5가 피처링한 곡에는 무엇이 있을까?\n",
      "내 딸 꽃님이에서 양수철 역의 까메오를 맏은 배우는 누구일까?\n",
      "오이디푸스 콤플렉스에 생기는 측면은 몇가지일까?\n",
      "유진오가 \"우리는 반드시 승리한다\"라는 주제로 언제 강연했을까?\n",
      "리디아 고의 프로 리그 우승 당시의 리그별 성적은 어땠을까?\n",
      "제27차 총회를 한 년도는?\n",
      "표기하고 쓸기 기법이란 무엇이며 단점에는 어떤 것이 있을까?\n",
      "공격적 인사관리에는 어떤 전술이 있을까?\n",
      "산화 붕소 또는 탄화 붕소가 잘 쓰이지 않는 이유는 무엇일까?\n",
      "하세가와 요시미치가 중좌로 승진한 연도는 언제야?\n",
      "법률에 따라 강릉시의 행정 구역이 어떻게 변했습니까?\n",
      "문학동네 제 18회 어린이 문학상을 수상한 작가는 누구인가요?\n",
      "스타드 드 프랑스의 2003년 피파 컨페더레이션스컵 주요 경기 내용은?\n",
      "멀티미디어라는 말이 해석의 방향에 따라 사용되거나 사용되지 않는 예시에는 무엇이 있을까?\n",
      "이세좌의 생애는 어떻게 되는가?\n",
      "목포경찰서 관할지구대인 삼학파출소의 주소는 어디일까?\n",
      "브라운 대학교의 제18대 총장은 누구인가?\n",
      "윈도우 미디어 센터를 사용할 때 시작 메뉴의 어떤 항목을 선택하면 노래를 재생할 수 있는가?\n",
      "2005년 트리스탄다쿠냐 제도에 공항을 건설할 계획을 세웠으나 중단된 나라는 어디인가?\n",
      "박일은 토이스토리에서 어떤 캐릭터의 성우를 했을까?\n",
      "칸타브리아 지방의 가장 건조한 월은 언제일까?\n",
      "아진산업의 연혁 변천사는?\n",
      "2003년 FIFA에서 개최한 세계 청소년 축구대회의 조별리그 중 A조의 경기결과는 어떻게 되었나요?\n",
      "경기도의회의 의원들을 뽑는 사람은 누구야?\n",
      "골반염을 방지하기 위한 방법에는 어떤 것이 있는가?\n",
      "모든 것은 마음이 만들어낸 것이라는 견해는 무엇인가?\n",
      "1896년 하계 올림픽 수영 남자 1200m 자유형의 경기 결과 중 18:22:2의 기록을 기록한 선수는 누구인가?\n",
      "방송 신통방통을 방영한 채널의 이름은 무엇입니까?\n",
      "박성균과 염보성의 상성은 어떻습니까?\n",
      "인피니트M 3세대(Y50)이 한국으로 정식 수입 시작하기 시작한 연도는 언제인가?\n",
      "토레스가 리버풀과 새 계약을 맺은 날짜는 언제인가?\n",
      "이천종합버스터미널의 수도권 방면 행선지는?\n",
      "페루자는 역사에서 어떤 이름으로 처음 등장하였는가?\n",
      "머리쓰개 착용 허용에 대한 터키 의회의 법률 개정은 어떤 반응을 불러일으켰습니까? \n",
      "백혈구의 감별 계산을 위해 최소 몇 개 이상의 백혈구를 검사할까요?\n",
      "땅돼지의 혀의 길이는 얼마야?\n",
      "동아일보 해직 기자들이 모여 1988년 새로 창간한 신문은 무엇일까?\n",
      "조선총독부령 제111호에 의해 이천의 호면은 어떤 면으로 개편되었을까?\n",
      "휴먼다큐 사람이 좋다는 현재 언제 방송을 시작하는가?\n",
      "사무라이와 무사를 같은 것으로 보는 공식이 형성 된 원인은 무엇인가?\n",
      "파울로 로시는 몇 년도에 이탈리아 국가대표팀으로 선발되었습니까?\n",
      "유플레이에서 서비스 중인 게임은?\n",
      "2016년 있었던 제23호 태풍의 이름은 어디에서 제출한 것일까?\n",
      "빅 캐즈가 WWE 계약 방출 통보를 받은 것은 언제입니까?\n",
      "신라는 사비성을 언제 함락시켰을까?\n",
      "에버턴 FC의 역사 중 1998-99 시즌에 에버턴 FC가 새 감독으로 임명한 사람은 누구인가?\n",
      "김포국제공항에서 광릉내를 운행하는 버스의 배차간격은 몇분일까?\n",
      "포켓몬스터에서 나오는 망나뇽의 다양한 스킬은?\n",
      "프로그래머가 사용하는 코드에서 무엇을 이용해 주석을 구분하는가?\n",
      "장문석 선수가 2005년에 소속되어있던 팀은 어디일까?\n",
      "장성 서씨의 시조가 가진 효심을 보여주는 일화는 무엇입니까? \n",
      "매슈 다다리오의 연도별 수상 및 수상후보 목록은 어떠했나요?\n",
      "상당부원군 한명회와 황려부부인 민씨 사이에서 출생한 막내딸인 한씨는 1467년에 어떤 사람과 혼인을 올렸을까?\n",
      "엘리자베스 올슨은 2013년에 무슨 후보로 뽑혔어?\n",
      "견당사 제도는 언제 폐지되었어?\n",
      "이란이 지방색이 강한 이유는 무엇인가?\n",
      "아이팟 모델 목록 중 아이팟 미니 1세대의 용량은 몇 GB인가?\n",
      "LATAM 칠레의 설립자는 누구입니까?\n",
      "혁오 출연 버라이어티 쇼는 무엇인가요?\n",
      "찰리야 부탁해에서 주인공 테디 덩컨을 연기한 배우의 이름은?\n",
      "우마카이는 어떤 의미를 담고 있어?\n",
      "진주시 시내버스는 어떤 설비가 돼있는가?\n",
      "김규식의 아들 이름은?\n",
      "목암생명과학연구소의 3대 소장의 이름은?\n",
      "플레이보이 잡지에서 비키니를 처음 선보였던 때는 몇년도 인가?\n",
      "롯데글로벌지스는 어떤 역사를 가진 기업이야?\n",
      "대뇌, 간뇌, 중뇌, 소뇌, 연수의 발달 정도는 무엇에 따라 차이가 있을까?\n",
      "엠페도 클레스가 제시한 네가지 만물의 근원은?\n",
      "밀레니엄 개발목표에서 초등과 중등교육에 대한 성별 불균형을 몇년도까지 없애기로 목표했는가?\n",
      "예문관 정1품 관직 영사의 정원은 몇명인가?\n",
      "도쿄 스미다구의 지역명 중 한자 여덟 팔 자가 포함되는 지역명은 무엇인가?\n",
      "화이트가 로어노크 섬에 상륙한 해는 어느 해인가?\n",
      "뷰티르산은 암세포에서 어떤 효과가 있나요?\n",
      "암보이나 사건 때문에 어떤 결과가 생겼어?\n",
      "플라시도 도밍고의 약력은 어떻게 되는가?\n",
      "작가 김순옥이 쓴 드라마는 뭐가 있을까?\n",
      "농암 이현보가 태어난 해는 언제야\n",
      "뇌척수액을 수집하기 위해 사용되는 도구의 이름은 무엇인가?\n",
      "NEXTSTEP 0.9버전은 오직 무엇만 지원하는가?\n",
      "늑대의 생김새는 어떨까?\n",
      "이종석이 2005년도에 신 한류스타 선발대회 시상식에서 수상한 부문은?\n",
      "유아기때의 인성 형성 과정에서 인간관계를 통해 받는 영향은 어떻게 되나요?\n",
      "예종석씨가 한국비영리학회 이사를 맡게 된 것은 언제부터인가?\n",
      "막돼먹은 영애씨 17에서 2019년 2월 8일에 방송된 제1회의 전국 AGB 시청률은?\n",
      "K리그 2000 정규 리그의 순위별 팀들의 시합 성적과 참가자격 및 강등 내용은 어떠한가요?\n",
      "천상지희의 멤버 선데이의 생일은 몇 월 며칠일까?\n",
      "수도원의 기원은 어디에서 시작되었나요?\n",
      "손영목 작가의 작품 중 2009년에 KBS1에서 방영된 대하드라마 제목은?\n",
      "2010년 MSL 32강에서 김명운을 이긴 프로게이머는 누구야?\n",
      "드뷔시의 전주곡 제 1권의 첫번째 곡은 무엇일까?\n",
      "이시애의 난 당시 사옹원별좌이면서 이시애의 처조카인 사람은 누구야? \n",
      "2차원 이외의 요소를 고려할 때의 날개를 무엇이라고 부를까?\n",
      "갓 태어난 검독수리가 나는 법을 배우고 직접 사냥을 할 수 있게 되기까지는 몇 일이 걸립니까?\n",
      "알폰소 2세가 왕이 된 년도는?\n",
      "음악가 안토니오 비발디의 인생은 어떠했는가?\n",
      "탤런트 장희진이 2011년 출연한 KBS 드라마로 고구려의 제 19대 군주의 이름이기도 한 이 작품의 제목은?\n",
      "1991년 FIFA 세계청소년 축구 선수권대회에서 조별리그A조의 경기결과는 어떻게 되었을까?\n",
      "라응찬 회장이 공식적으로 물러난 후 누가 직무를 대신하였나?\n",
      "델리스파이스의 대표곡이 뭐야?\n",
      "긴조 다쓰히코가 프로 입단 후 2003년에서 2005년까지의 활약상은 어떠한가?\n",
      "SKY 프로리그 2004 1라운드의 경기 결과는 어땠을까?\n",
      "00-01시즌 카롤리나 코스트너의 주니어 세계선수권의 기록은?\n",
      "불의 잔 등장씬에서 소리의 요정의 이름은 뭘까?\n",
      "블랙번이 필 존스 이적에 대해 맨체스터 유나이티드에 요구한 금액은?\n",
      "1626년 가족의 잇따른 사망 이후 센히메가 불교에 입문하면서 얻은 법명은?\n",
      "홍윤성의 청년 시절은 어떠했는가?\n",
      "메구리가 2007년에 계약한 연예기획사 이름은 뭐야?\n",
      "제 23대 이경옥 교장이 광주무진중학교에 취임한 날짜는 언제일까?\n",
      "2008년 AV 그랑프리의 패키지 부문의 입상작들은 어떤 것들이 있는가?\n",
      "실성 마립간의 키는 몇이었을까?\n",
      "엔딩크레딧이란 곡의 발매날짜는 어떻게 될까?\n",
      "스키니진을 착용하면 나타날 수 있는 효과가 뭐야?\n",
      "버마의 왕으로, 1557년에 타이-샨족 국가들을 모두 정복한 것으로 알려진 인물은?\n",
      "아시아나항공이 지분율100%를 가지고 있는 저비용항공사는 어디일까?\n",
      "명륜역 1호선의 2002년 승차량은?\n",
      "어드밴스트 마이크로 디바이시스가 처음 설립된 해에 ceo로 고용된 사람은 누구였을까?\n",
      "고전 통계역할을 최초로 정립한 사람은 누구야?\n",
      "중력 상수 측정법은 어떻게 되는가?\n",
      "피해를 당한 농민들은 누구를 중심으로해서 보상을 요구했나요?\n",
      "노래가 나온지 14년 후, 봉선화는 어떻게 사랑을 받았는가?\n",
      "유진이 어렸을 때 한국을 떠나 이사간 나라는?\n",
      "상명대 출신 감독의 이름은?\n",
      "2009년 와글와글 꼬꼬맘은 어떤 화들을 방송했을까?\n",
      "프리메라리그 소속인 발렌시아의 홈구장 명칭은?\n",
      "서주 역대 군주의 시호와 이름은?\n",
      "김동률의 전람회에서의 경력에는 무엇이 있을까?\n",
      "서초역 2호선 2000년 승차객수는 얼마인가요?\n",
      "선종의 부왕은 몇년도에 돌아가셨는가?\n",
      "나고야성은 공사가 시작된지 8개월 만에 완성이 되었는데, 이 공사가 완성된 해는 언제인가?\n",
      "강만수는 어느 대학교를 나왔을까?\n",
      "니혼 대학에서 이백미터 시위가 일어난 계기와 결과는?\n",
      "6•25 당시 중공군의 개입 과정은 어땠을까?\n",
      "이진삼이 졸업한 고등학교는 어디인가?\n",
      "B1레벨 CELF는 필요 교육 시간이 얼마나 될까?\n",
      "괴산군의 행정 구역 중 유일한 읍의 인구수는 무엇일까?\n",
      "배우 박솔미는 어느 시상식에서 여우조연상을 탔을까?\n",
      "예맨은 왜 둘로 나누어졌어?\n",
      "변태왕자와 웃지 않는 고양이의 각 권이 국가별로 처음 발행된 날짜는 언제인가요?\n",
      "키는 현재 어떤 브랜드의 광고 모델인가?\n",
      "이라크 축구 국가대표팀이 1985년 팬아랍 게임에서 획득한 메달의 종류는 무엇인가? \n",
      "오페라 개발 단계에 따른 세 가지 채널은 각각 무엇인가?\n",
      "오쓰 사건의 배경에 대한 설이 뭐가 있어?\n",
      "대한민국 5인조 걸그룹 '퀸비즈'의 앨범은 무엇이 있을까?\n",
      "성호사설에서 이익이 생명에 대해 피력한 의견이 무엇일까?\n",
      "쁠래이꾸의 2월 최고기온기록은 몇 도인가?\n",
      "일본에서 사형 판결이 확정되면 판결과 관련된 서류들은 어디로 보내질까?\n",
      "김대오가 타 언론사와 상이한 모습을 비추기 위해 한 노력은 어떤 것이 있을까요?\n",
      "조유리의 성장과정은?\n",
      "황금자칼은 어떻게 진화되어 왔을까?\n",
      "pwf의 자세한 일정은 어디에서 확인할 수 있는가?\n",
      "2005년 인천 유나이티드의 주장은 누구인가?\n",
      "시암은 언제 미국과 외교 관계를 시작하게 되었을까?\n",
      "밀 Mi-24는 어떻게 설계되었을까?\n",
      "장 피아제의 주요 서적들은 무엇이 있을까?\n",
      "옵티머스g프로가 일본에 출시된 년도는?\n",
      "오스트리아는 어떤 근대 역사를 가진 국가야?\n",
      "구산역의 2003년 6호선승하차 승객 수는?\n",
      "허리케인 샌디가 2012년 킹스턴에 도착했을당시 풍속은 어느정도 였는가?\n",
      "충주에 농공은행이 설립된 년도는 언제야?\n",
      "이민혁이 작사 및 작곡한 앨범에는 어떤것들이 있을까?\n",
      "헤르메스주의에 대한 내용은 무엇인가?\n",
      "\"금욕주의와 철야기도를 포함해서 어떤 종류의 고행도 구원에 이를 수 없다\"고 말한 인물은 누구인가?\n",
      "리투아니아 축구 대표팀의 FIFA 월드컵 예선 역대 성적은 어떻게 될까?\n",
      "사람들이 사회를 만들면서 시작된 것은 무엇인가?\n",
      "박준혁은 2010년 드래프트를 통하여 어떤 팀에 입단하였는가?\n",
      "넨도에는 어떤 디자이너가 일하고 있을까?\n",
      "쌍용 코란도C의 전장은 몇 mm인가?\n",
      "1960년 올림픽은 어느 도시에서 개최되었는가?\n",
      "이쿠타 에리카의 '내가 있는 장소' '당신을 위해서 연주하고 싶어' 가 수록된 작품명은 무엇인가?\n",
      "신풍괴도 쟌느의 주인공 마론의 라이벌로 이야기에 갈등을 유발한 캐릭터는 누구일까?\n",
      "계약 만료 후의 이득에 대한 보상청구를 규정하고 있는 조항은 몇항인가?\n",
      "윤딴딴이 발매한 디지털 싱글 앨범은 어떨까?\n",
      "TDI사의 벡터에는 어떤 독특한 방식을 사용했을까?\n",
      "2016년에 방송된 드라마 한 번 더 해피엔딩의 제1회 TNmS 대한민국(전국) 시청률은 몇퍼센트인가?\n",
      "목포종합버스터미널의 고속버스 운행정보는 어떻게 되는가?\n",
      "이희우를 등단시킨 소설은 뭐야?\n",
      "바이마르 공화국의 수립은 어떻게 이루어졌나?\n",
      "인천국제공항과 대구서부간 시외버스를 운행하는 운수업체는?\n",
      "서남동이 태어난 곳은 팔도 중 어디에 속하는가?\n",
      "해씨 부인은 누구와 혼인하였는가?\n",
      "수도권 EBS FM을 송출하는 KBS 본사 송신소는 어디일까?\n",
      "김성호의 2012년 평균자책점은 몇 점일까?\n",
      "베토벤의 교향곡 10번은 어떻게 구성되어 있을까?\n",
      "영축산의 여러가지 이름을 영축산으로 확정지은 것은 언제인가?\n",
      "스페인의 필리프가 왕국을 통합하기 위해 발행한 법령은 뭐야?\n",
      "강경화는 어떤 삶을 살았을까?\n",
      "가수 세정이 제1회 더 서울어워즈에서 상을 수상한 부문은 무엇인가?\n",
      "2012년 4월 발매 된 EXO의 데뷔 미니 앨범의 타이틀은 무엇입니까?\n",
      "노부나가의 야망 장성록 중 어떤 문제를 수정한 1.01패치가 나왔는데 무슨 문제였나?\n",
      "'지극히 경건한 요청'이라는 교서를 발표한 년월일은?\n",
      "지방도 제918호선 중 영양군 영양읍 동부리에서 농협사거리까지의 도로명은 무엇일까요?\n",
      "오종은 소림사에서 누구와 무예를 교류했는가?\n",
      "이진이가 2015년에 출연한 예능은 무엇입니까?\n",
      "라스 울리히의 할머니의 성함은?\n",
      "국가정보자원관리원에 속해있는 과들 중에서 방대한 양의 데이터 분석을 담당하는 과는 어디인가?\n",
      "대한민국의 역대 농림축산식품부 차관들중 농수산부 차관들은?\n",
      "LOL 월드 챔피언십 시즌3 8강전에서 팀 OMG를 상대로 승리를 거둔 팀은 어디일까?\n",
      "2011년 국가영어능력평가시험 중 전국 44개의 주요도시에서 치른 성인용 1급 예비시험의 날짜는 언제인가?\n",
      "무주우체국이 관할하는 우체국에는 어떤곳들이 있을까?\n",
      "장어류에는 어떤 것들이 있어?\n",
      "김사랑은 1938년에 이광수의 <무명>을 번역하여 <모던일본>에 실었고, 이로 제 1회의 이 상을 수상하였다. 어떤 상일까?\n",
      "소설가 전혜린이 번역한 적이 있는 헤르만 헤세의 작품으로 주인공 에밀 싱클레어의 자전적 고백으로 이루어진 이 작품의 제목은?\n",
      "STU48의 연구생 멤버는 어떻게 구성되어 있나요?\n",
      "판금갑을 사라지게 만든 무기는 뭐야?\n",
      "리보솜의 지름은 어느정도야?\n",
      "한국판 블랙프라이데이 행사에 참여한 업체의 제품을 구매하면 카드사로부터 몇 개월의 무이자할부 혜택을 제공받을 수 있는가?\n",
      "일본 프로야구선수 알렉스 라미레스의 연봉은 어떻게 변했는가?\n",
      "캄보디아가 프랑스로부터 첫 독립을 선언한 것은 언제일까?\n",
      "에버의 S 계열 제품은 무엇이 있을까?\n",
      "2010년도 K리그에서 누적 관중이 가장 많았던 구단은?\n",
      "노폐물로 취급되었던 귀두지의 순기능은 무엇일까요?\n",
      "젊은 남자와 여자 간 공감하는 데 있어 차이가 있다고 말한 스탠포드 대학교수는 누구야?\n",
      "공산주의의 문제점 중 경제적 문제에는 어떤 것이 있을까?\n",
      "지렁이 가 환경에 주는 이로움은 무엇일까?\n",
      "노르웨이의 전통으로 오크통에 실린 채로 가로질렀다 오는 전통을 무엇이라 부를까?\n",
      "대왕암공원은 어떤 관광지인가?\n",
      "법률유보의 원칙에서 국민의 기본권과 관련된 사항은 입법자가 결정해야 한다는 의미를 가진 용어가 뭐지?\n",
      "FXII212슈퍼크루저모델은 오디오에 USB단자가 사용할수 있게 나온것은 언제부터 일까?\n",
      "아우구스투스의 집권시절의 행보는 어땠는가?\n",
      "페르디난트1세는 어떻게 해서 왕이 되었을까?\n",
      "대한민국에서 중앙소방본부 소방조정관을 역임한 사람들은 누구인가요?\n",
      "백합속 씨앗의 발아 온도는 몇도 전후야?\n",
      "구공에 대한 설명은 무엇인가?\n",
      "구본창이 1993년 출판한 책의 이름은 무엇일까?\n",
      "사람들은 무엇을 이유로 주님 승천 대축일과 성령 강림 대축일이 각각 다른 날짜에 이뤄지는 관습을 비판하였을까?\n",
      "현재 울산광역시 중구의 명칭은 어떻게 변화해왔나요?\n",
      "미국에서 동성결혼 제도가 최초 도입된 것은 언제야?\n",
      "이광식을 서경한 조선시대 정부 조직이름은 뭐야?\n",
      "계훈제가 서울대 문리대 학생회장 시절 주도한 미 군정 서울대 국립화에 반대하는 운동은 무엇이었을까?\n",
      "도카이도 신칸센에서는 노조미가 어떻게 운행되고 있을까?\n",
      "은하에서 분자운은 무엇의 일부인가?\n",
      "미라주 2000의 개발 진행 기간은?\n",
      "영화 줄리 & 줄리아에서 주인공인 줄리아 차일드 역할을 맡은 여배우의 이름은?\n",
      "김준연이 공산당의 자금 조달에 대해 비판하는 의견을 게재한 신문은 무엇일까?\n",
      "문선민의 선수 경력 중 문선민이 축구 국가대표팀에 처음 발탁된 해는 언제인가?\n",
      "팬아메리칸 게임 비치발리볼의 2003년 개최지의 이름은?\n",
      "1949년 12월, 대한민국의 홍익인간 교육 이념을 공표한 것은 법률 제 몇 조입니까?\n",
      "2016년 8월 류승우는 어디로 임대되었는가?\n",
      "단종 시기의 충정공 박심문 선생의 호는 뭐야?\n",
      "발뼈는 몇 개가 있을까?\n",
      "화순군의 읍면동별 행정구역 정보는 어떠한가요?\n",
      "싱가포르 축구 국가대표팀은 FIFA 월드컵 본선과 예선에서 어떤 성적을 거둬왔을까?\n",
      "여성주의교육의 이론적 배경은 어떻게 나타나는가?\n",
      "조지 클루니의 배우 데뷔작은 무엇일까?\n",
      "'노을빛으로 물드는 언덕'의 등장인물 중 스기시마 세이지로 역을 맡은 성우는 누구야?\n",
      "운현궁 안의 노락당은 어떤 모습의 건물이야?\n",
      "라투아니아 기사단장의 이름은?\n",
      "혈액응고 장애는 수액의 종류 중 어떤 용액에서 발생하는가?\n",
      "박미경이 1985년 제6회 강변가요제에서 부른 노래는 무엇인가?\n",
      "박보경 아나운서는 프리랜서 이전 어떤 일을 했을까?\n",
      "고발기의 생애는 어떠했는가?\n",
      "일본에 불교가 어떻게 들어오게 되었을까?\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000) :\n",
    "    print(df['data'][i]['qas'][0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-db3d34eb4350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m999\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "df['data'][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
